---
title: "ROI on Hand Picked Stocks 2007-2020"
author: "Janis Corona"
date: 'February and March 2020'
output:
  word_document: default
  html_document: default
---

This is a project that is for now analyzing some hand picked stock to see if a program can be written based on the analysis of how certain stocks perform from 2007-2020. It looks at cyclical patterns of highs and lows, adds in the DOW highs and lows, the unemployment highs and lows, then mean and median values of daily changes various date fields for day of the week and month. The idea is to get the best performing stocks, analyze them with subsets of the worst performing stocks, get the specific features of each stock to describe it as a profit or loss forecasted stock to invest in based on its current stats, and more. 

It will then add in the public sentiments for the lows and highs or local minima and maxima of the stock in the best performing set to predict the best time to buy and best to sell respectively, so that you could buy at a low cost and sell at a high cost and keep trading to increase profits of the portfolio.

Modifications made, with the SCE.PB not having all numeric values, it was the only one in the set of 53 that had factor values for the number of factors it had. This script attempts early on to fix some errors stemming from this early error that found displacement of plots shown earlier, and rearranging of columns when adding other fields. 

```{r, echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
library(lubridate)
library(tidyr)
library(ggplot2)
library(dplyr)
library(grid)
library(gridExtra)
library(egg)
library(gtable)
library(e1071)
library(caret)
library(randomForest)
library(MASS)
library(gbm)

```



```{r}
portfolio <- read.csv('all_portfolio_prices.csv', sep=',',header=TRUE, na.strings=c('',' '),
                      row.names=1)
```


```{r}
portfolio$Date <- row.names(portfolio)
```

```{r}
Vol <- grep('Volume', colnames(portfolio))
close <- grep('Close',colnames(portfolio))
Close <- portfolio[,close]
Volume <- portfolio[,Vol]
colnames(Close)

```

```{r, error=FALSE, message=FALSE, warning=FALSE} 
Close$GNBT.Close <- as.numeric(paste(Close$GNBT.Close))
Close$FCAU.Close <- as.numeric(paste(Close$FCAU.Close))
Close$QSR.Close <- as.numeric(paste(Close$QSR.Close))
Close$GRPN.Close <- as.numeric(paste(Close$GRPN.Close))
Close$SCE.PB.Close <- as.numeric(paste(Close$SCE.PB.Close))
Close$GM.Close <- as.numeric(paste(Close$GM.Close))
Close$ASCCY.Close <- as.numeric(paste(Close$ASCCY.Close))
Close$CSSEP.Close <- as.numeric(paste(Close$CSSEP.Close))
Close$AMC.Close <- as.numeric(paste(Close$AMC.Close))
Close$TMUS.Close <- as.numeric(paste(Close$TMUS.Close))
Close$PBYI.Close <- as.numeric(paste(Close$PBYI.Close))
Close$SDC.Close <- as.numeric(paste(Close$SDC.Close))
Close$YELP.Close <- as.numeric(paste(Close$YELP.Close))


```

```{r}
colSums(is.na(Close))
```

```{r}
colnames(Close)
```


Remove NAs from the data.
```{r}

Close_noNAs <- Close[,-c(9,13,17,18,19,25,27,32,34,46,50,61,65)]
other13_dailyClose <-Close[,c(9,13,17,18,19,25,27,32,34,46,50,61,65)]
Volume_noNAs <- Volume[,-c(9,13,17,18,19,25,27,32,34,46,50,61,65)]
other13_dailyVolumne <- Volume[,c(9,13,17,18,19,25,27,32,34,46,50,61,65)]


```

Add in a value of the portfolio column for each day's closing price of all stock that don't have NAs.
```{r, error=FALSE, message=FALSE, warning=FALSE}
Close_noNAs$DailyValue <- rowSums(Close_noNAs,na.rm=TRUE)

```

Add in a daily change column of the portfolio closing prices.
```{r}
dayVal <- as.data.frame(Close_noNAs$DailyValue)
colnames(dayVal) <- 'previousDayValue'
zero <- as.data.frame(as.numeric(dayVal$previousDayValue[1]))
colnames(zero) <- 'previousDayValue'
prevDay <- rbind(zero,dayVal)
Close_noNAs$prevDay <- prevDay[1:length(prevDay$previousDayValue)-1,1]
dailyChange <- as.data.frame(Close_noNAs$DailyValue-Close_noNAs$prevDay)
colnames(dailyChange) <- 'dailyValueChange'

Close1 <- cbind(Close_noNAs,dailyChange)
```

Add a column that gives the return in dollars on initial dollars invested.
```{r}
Close1$ROI_dollars <- Close1$DailyValue-Close1$DailyValue[1]
```

Add some date fields to look at the values by date, day of the week, month, and year in analyzing this data.
```{r}
Close1$Date <- as.Date.character(row.names(Close1))
```

```{r}
Close1$DayOfWeek <- weekdays(as.Date(Close1$Date))
```

```{r}
month <- month(as.Date(Close1$Date))
Month <- month.abb[month]
Close1$Month <- Month
```


Add in the year of the Date column.
```{r}
Year <- year(as.Date(Close1$Date))

Close1$Year <- Year

Close1$MonthYear <- paste(Close1$Month, Close1$Year, sep='-')
Close1$MonthYear <- as.factor(Close1$MonthYear)
```



Add in some [unemployment](https://data.bls.gov/pdq/SurveyOutputServlet) information as a column to see how the portfolio is doing by date.
```{r}
ue <- read.delim('BLS_unemploymentRates2007-2020.txt', sep=',',header=TRUE, 
                 na.strings=c('',' '))
UE <- ue[,-14]#remove the empty 'Annual' column
```

Use tidyr to gather the month fields with their respective unemployment rates per month.
```{r}
gatherMonths <- gather(UE, 'UE_Month', 'UE_monthlyRate',2:13)

gatherMonths$MonthYear <- paste(gatherMonths$UE_Month, gatherMonths$Year, sep='-')
gatherMonths$MonthYear <- as.factor(gatherMonths$MonthYear)
```


```{r}
UE2 <- gatherMonths[,3:4]
Close2 <- merge(Close1, UE2, by.x='MonthYear', by.y='MonthYear')
colnames(Close2)[55:58] <- paste('portfolio',colnames(Close2)[55:58], sep='_')

Close2 <- Close2[order(Close2$portfolio_Date), ]
row.names(Close2) <- Close2$portfolio_Date
```


```{r}
write.csv(Close2, 'ROI_UE_2007_2020_v2.csv', row.names=FALSE)
```


Lets add in the volume of trades per day from the Volume_noNAs data set. But lets add in some fields for total portfolio trades per day, 
```{r}
Volume1 <- Volume_noNAs
Volume1$portfolio_DailyVolume <- rowSums(Volume1, na.rm=TRUE)

dayVol <- as.data.frame(Volume1$portfolio_DailyVolume)
colnames(dayVol) <- 'portfolio_previousDayVolume'
zero <- as.data.frame(as.numeric(dayVol$portfolio_previousDayVolume[1]))
colnames(zero) <- 'portfolio_previousDayVolume'
prevDay1 <- rbind(zero,dayVol)
Volume1$portfolio_prevDayVolume <-
  prevDay1[1:(length(prevDay1$portfolio_previousDayVolume)-1),1]

dailyVolumeChange <- as.data.frame(Volume1$portfolio_DailyVolume-Volume1$portfolio_prevDayVolume)
colnames(dailyVolumeChange) <- 'portfolio_dailyVolumeChange'

Volume2 <- cbind(Volume1,dailyVolumeChange)
Volume2$portfolio_VolumeRatioDaily2Initial <- Volume2$portfolio_DailyVolume/Volume2$portfolio_prevDayVolume[1]

Volume2$Date <- as.Date(row.names(Volume2))
```


```{r}
stocks <- cbind(Close2, Volume2)

Stocks <- stocks[,c(2:53,63:114,1,54:62,115:119)]
colnames(Stocks)
```

Add a value of stock daily to the initial value as a ratio.
```{r}
Stocks$portfolio_ValueRatioDaily2Initial <-
  Stocks$DailyValue/Stocks$DailyValue[1]

```

Add a field that multiplies the daily value and daily volume ratios compared to the initial value and volume by the unemployment rate.
```{r}
Stocks$portfolio_DailyRatios_X_UE <-
  Stocks$portfolio_ValueRatioDaily2Initial*Stocks$portfolio_VolumeRatioDaily2Initial*Stocks$UE_monthlyRate

```

Add an exponential calculation field based on the unemployment rate for rate, and using t=1/12 for 12 months, and a binary value of 1 or 2 where the daily change is positive is assigned a 1 and a negative is a 2. This will make those values decreasing daily have a lower poisson and those values increasing a higher poisson value. This is a modified poisson used for probability of an outcome occuring with a constant rate. Added to rank daily changes based on unemployment rate of each month.
```{r}
Stocks <- Stocks[complete.cases(Stocks$UE_monthlyRate),]
Stocks$dayOfMonth <- day(Stocks$Date)
dayOfMonth <- day(Stocks$Date)
ue1 <- Stocks$UE_monthlyRate

incrDecr <- ifelse(Stocks$portfolio_dailyValueChange>0,1,2)

Stocks$portfolio_poisson <- round((exp(-(ue1*1/12))*(ue1*1/12)^incrDecr)/(factorial(incrDecr)),5)

summary(Stocks$portfolio_poisson)
```


```{r}

write.csv(Stocks, 'StocksStats_v2.csv', row.names=TRUE)

```


Make a daily ROI dollars column for each of the stocks in this set.
```{r}
stocks1 <- Stocks[,1:52]
colnames(stocks1)
```

```{r}
stocks1$TGT_ROI_dollars <- stocks1$TGT.Close-stocks1$TGT.Close[1]
stocks1$FTR_ROI_dollars <- stocks1$FTR.Close-stocks1$FTR.Close[1]
stocks1$UBSI_ROI_dollars <- stocks1$UBSI.Close-stocks1$UBSI.Close[1]
stocks1$HD_ROI_dollars <- stocks1$HD.Close-stocks1$HD.Close[1]
stocks1$JPM_ROI_dollars <- stocks1$JPM.Close-stocks1$JPM.Close[1]

stocks1$XOM_ROI_dollars <- stocks1$XOM.Close-stocks1$XOM.Close[1]
stocks1$CVX_ROI_dollars <- stocks1$CVX.Close-stocks1$CVX.Close[1]
stocks1$NSANY_ROI_dollars <- stocks1$NSANY.Close-stocks1$NSANY.Close[1]
stocks1$MGM_ROI_dollars <- stocks1$MGM.Close-stocks1$MGM.Close[1]
stocks1$TEVA_ROI_dollars <- stocks1$TEVA.Close-stocks1$TEVA.Close[1]

stocks1$HST_ROI_dollars <- stocks1$HST.Close-stocks1$HST.Close[1]
stocks1$WFC_ROI_dollars <- stocks1$WFC.Close-stocks1$WFC.Close[1]
stocks1$WWE_ROI_dollars <- stocks1$WWE.Close-stocks1$WWE.Close[1]
stocks1$INO_ROI_dollars <- stocks1$INO.Close-stocks1$INO.Close[1]

stocks1$FFIN_ROI_dollars <- stocks1$FFIN.Close-stocks1$FFIN.Close[1]
stocks1$GOOG_ROI_dollars <- stocks1$GOOG.Close-stocks1$GOOG.Close[1]
stocks1$WM_ROI_dollars <- stocks1$WM.Close-stocks1$WM.Close[1]
stocks1$ONCY_ROI_dollars <- stocks1$ONCY.Close-stocks1$ONCY.Close[1]
stocks1$S_ROI_dollars <- stocks1$S.Close-stocks1$S.Close[1]

stocks1$F_ROI_dollars <- stocks1$F.Close-stocks1$F.Close[1]
stocks1$ARWR_ROI_dollars <- stocks1$ARWR.Close-stocks1$ARWR.Close[1]
stocks1$COST_ROI_dollars <- stocks1$COST.Close-stocks1$COST.Close[1]
stocks1$AAL_ROI_dollars <- stocks1$AAL.Close-stocks1$AAL.Close[1]
stocks1$JWN_ROI_dollars <- stocks1$JWN.Close-stocks1$JWN.Close[1]

stocks1$NUS_ROI_dollars <- stocks1$NUS.Close-stocks1$NUS.Close[1]
stocks1$HMC_ROI_dollars <- stocks1$HMC.Close-stocks1$HMC.Close[1]
stocks1$AMZN_ROI_dollars <- stocks1$AMZN.Close-stocks1$AMZN.Close[1]
stocks1$T_ROI_dollars <- stocks1$T.Close-stocks1$T.Close[1]
stocks1$HRB_ROI_dollars <- stocks1$HRB.Close-stocks1$HRB.Close[1]
stocks1$RRGB_ROI_dollars <- stocks1$RRGB.Close-stocks1$RRGB.Close[1]

stocks1$ADDYY_ROI_dollars <- stocks1$ADDYY.Close-stocks1$ADDYY.Close[1]
stocks1$PCG_ROI_dollars <- stocks1$PCG.Close-stocks1$PCG.Close[1]
stocks1$ROST_ROI_dollars <- stocks1$ROST.Close-stocks1$ROST.Close[1]
stocks1$JNJ_ROI_dollars <- stocks1$JNJ.Close-stocks1$JNJ.Close[1]
stocks1$NFLX_ROI_dollars <- stocks1$NFLX.Close-stocks1$NFLX.Close[1]
stocks1$M_ROI_dollars <- stocks1$M.Close-stocks1$M.Close[1]

stocks1$KSS_ROI_dollars <- stocks1$KSS.Close-stocks1$KSS.Close[1]
stocks1$DLTR_ROI_dollars <- stocks1$DLTR.Close-stocks1$DLTR.Close[1]
stocks1$WMT_ROI_dollars <- stocks1$WMT.Close-stocks1$WMT.Close[1]
stocks1$C_ROI_dollars <- stocks1$C.Close-stocks1$C.Close[1]
stocks1$AAP_ROI_dollars <- stocks1$AAP.Close-stocks1$AAP.Close[1]
stocks1$JBLU_ROI_dollars <- stocks1$JBLU.Close-stocks1$JBLU.Close[1]

stocks1$MSFT_ROI_dollars <- stocks1$MSFT.Close-stocks1$MSFT.Close[1]
stocks1$KGJI_ROI_dollars <- stocks1$KGJI.Close-stocks1$KGJI.Close[1]
stocks1$EPD_ROI_dollars <- stocks1$EPD.Close-stocks1$EPD.Close[1]
stocks1$TJX_ROI_dollars <- stocks1$TJX.Close-stocks1$TJX.Close[1]
stocks1$HOFT_ROI_dollars <- stocks1$HOFT.Close-stocks1$HOFT.Close[1]

stocks1$LUV_ROI_dollars <- stocks1$LUV.Close-stocks1$LUV.Close[1]
stocks1$NKE_ROI_dollars <- stocks1$NKE.Close-stocks1$NKE.Close[1]
stocks1$TM_ROI_dollars <- stocks1$TM.Close-stocks1$TM.Close[1]
stocks1$VZ_ROI_dollars <- stocks1$VZ.Close-stocks1$VZ.Close[1]
stocks1$SIG_ROI_dollars <- stocks1$SIG.Close-stocks1$SIG.Close[1]


```



These are the values of the stock the previous day that will be subtracted from each day to get the daily change from the day before in dollars.
```{r}

TGTa <- c(0,stocks1$TGT.Close[1:(length(stocks1$TGT.Close)-1)])
FTRa <- c(0, stocks1$FTR.Close[1:(length(stocks1$TGT.Close)-1)])
UBSIa <- c(0,stocks1$UBSI.Close[1:(length(stocks1$TGT.Close)-1)])
HDa <- c(0,stocks1$HD.Close[1:(length(stocks1$TGT.Close)-1)])
JPMa <- c(0,stocks1$JPM.Close[1:(length(stocks1$TGT.Close)-1)])
XOMa <- c(0,stocks1$XOM.Close[1:(length(stocks1$TGT.Close)-1)])
CVXa <- c(0,stocks1$CVX.Close[1:(length(stocks1$TGT.Close)-1)])
NSANYa <- c(0,stocks1$NSANY.Close[1:(length(stocks1$TGT.Close)-1)])
MGMa <- c(0,stocks1$MGM.Close[1:(length(stocks1$TGT.Close)-1)])
TEVAa <- c(0, stocks1$TEVA.Close[1:(length(stocks1$TGT.Close)-1)])
HSTa <- c(0, stocks1$HST.Close[1:(length(stocks1$TGT.Close)-1)])
WFCa <- c(0, stocks1$WFC.Close[1:(length(stocks1$TGT.Close)-1)])
WWEa <- c(0, stocks1$WWE.Close[1:(length(stocks1$TGT.Close)-1)])
INOa <- c(0,stocks1$INO.Close[1:(length(stocks1$TGT.Close)-1)])
FFINa <- c(0,stocks1$FFIN.Close[1:(length(stocks1$TGT.Close)-1)])
GOOGa <- c(0,stocks1$GOOG.Close[1:(length(stocks1$TGT.Close)-1)])
WMa <- c(0,stocks1$WM.Close[1:(length(stocks1$TGT.Close)-1)])
ONCYa <- c(0,stocks1$ONCY.Close[1:(length(stocks1$TGT.Close)-1)])
Sa <- c(0,stocks1$S.Close[1:(length(stocks1$TGT.Close)-1)])
Fa <- c(0,stocks1$F.Close[1:(length(stocks1$TGT.Close)-1)])
ARWRa <- c(0,stocks1$ARWR.Close[1:(length(stocks1$TGT.Close)-1)])
COSTa <- c(0,stocks1$COST.Close[1:(length(stocks1$TGT.Close)-1)])
AALa <- c(0,stocks1$AAL.Close[1:(length(stocks1$TGT.Close)-1)])
JWNa <- c(0,stocks1$JWN.Close[1:(length(stocks1$TGT.Close)-1)])
NUSa <- c(0,stocks1$NUS.Close[1:(length(stocks1$TGT.Close)-1)])
ADDYYa <- c(0,stocks1$ADDYY.Close[1:(length(stocks1$TGT.Close)-1)])
KSSa <- c(0,stocks1$KSS.Close[1:(length(stocks1$TGT.Close)-1)])
MSFTa <- c(0,stocks1$MSFT.Close[1:(length(stocks1$TGT.Close)-1)])
LUVa <- c(0,stocks1$LUV.Close[1:(length(stocks1$TGT.Close)-1)])
HMCa <- c(0,stocks1$HMC.Close[1:(length(stocks1$TGT.Close)-1)])
PCGa <- c(0,stocks1$PCG.Close[1:(length(stocks1$TGT.Close)-1)])
DLTRa <- c(0,stocks1$DLTR.Close[1:(length(stocks1$TGT.Close)-1)])
KGJIa <- c(0,stocks1$KGJI.Close[1:(length(stocks1$TGT.Close)-1)])
NKEa <- c(0,stocks1$NKE.Close[1:(length(stocks1$TGT.Close)-1)])
AMZNa <- c(0,stocks1$AMZN.Close[1:(length(stocks1$TGT.Close)-1)])
ROSTa <- c(0,stocks1$ROST.Close[1:(length(stocks1$TGT.Close)-1)])
WMTa <- c(0,stocks1$WMT.Close[1:(length(stocks1$TGT.Close)-1)])
TJXa <- c(0,stocks1$TJX.Close[1:(length(stocks1$TGT.Close)-1)])
TMa <- c(0,stocks1$TM.Close[1:(length(stocks1$TGT.Close)-1)])
Ta <- c(0,stocks1$T.Close[1:(length(stocks1$TGT.Close)-1)])
JNJa <- c(0,stocks1$JNJ.Close[1:(length(stocks1$TGT.Close)-1)])
Ca <- c(0,stocks1$C.Close[1:(length(stocks1$TGT.Close)-1)])
EPDa <- c(0,stocks1$EPD.Close[1:(length(stocks1$TGT.Close)-1)])
VZa <- c(0,stocks1$VZ.Close[1:(length(stocks1$TGT.Close)-1)])
HRBa <- c(0,stocks1$HRB.Close[1:(length(stocks1$TGT.Close)-1)])
NFLXa <- c(0,stocks1$NFLX.Close[1:(length(stocks1$TGT.Close)-1)])
AAPa <- c(0,stocks1$AAP.Close[1:(length(stocks1$TGT.Close)-1)])
HOFTa <- c(0,stocks1$HOFT.Close[1:(length(stocks1$TGT.Close)-1)])
SIGa <- c(0,stocks1$SIG.Close[1:(length(stocks1$TGT.Close)-1)])
RRGBa <- c(0,stocks1$RRGB.Close[1:(length(stocks1$TGT.Close)-1)])
Ma <- c(0,stocks1$M.Close[1:(length(stocks1$TGT.Close)-1)])
JBLUa <- c(0,stocks1$JBLU.Close[1:(length(stocks1$TGT.Close)-1)])

```

This creates the DailyChange per stock columns.
```{r}
stocks1$TGT_dailyChange <- stocks1$TGT.Close-TGTa
stocks1$FTR_dailyChange <- stocks1$FTR.Close-FTRa
stocks1$UBSI_dailyChange <- stocks1$UBSI.Close-UBSIa
stocks1$HD_dailyChange <- stocks1$HD.Close-HDa
stocks1$JPM_dailyChange <- stocks1$JPM.Close-JPMa

stocks1$XOM_dailyChange <- stocks1$XOM.Close-XOMa
stocks1$CVX_dailyChange <- stocks1$CVX.Close-CVXa
stocks1$NSANY_dailyChange <- stocks1$NSANY.Close-NSANYa
stocks1$MGM_dailyChange <- stocks1$MGM.Close-MGMa
stocks1$TEVA_dailyChange <- stocks1$TEVA.Close-TEVAa

stocks1$HST_dailyChange <- stocks1$HST.Close-HSTa
stocks1$WFC_dailyChange <- stocks1$WFC.Close-WFCa
stocks1$WWE_dailyChange <- stocks1$WWE.Close-WWEa
stocks1$INO_dailyChange <- stocks1$INO.Close-INOa

stocks1$FFIN_dailyChange <- stocks1$FFIN.Close-FFINa
stocks1$GOOG_dailyChange <- stocks1$GOOG.Close-GOOGa
stocks1$WM_dailyChange <- stocks1$WM.Close-WMa
stocks1$ONCY_dailyChange <- stocks1$ONCY.Close-ONCYa
stocks1$S_dailyChange <- stocks1$S.Close-Sa

stocks1$F_dailyChange <- stocks1$F.Close-Fa
stocks1$ARWR_dailyChange <- stocks1$ARWR.Close-ARWRa
stocks1$COST_dailyChange <- stocks1$COST.Close-COSTa
stocks1$AAL_dailyChange <- stocks1$AAL.Close-AALa
stocks1$JWN_dailyChange <- stocks1$JWN.Close-JWNa

stocks1$NUS_dailyChange <- stocks1$NUS.Close-NUSa
stocks1$HMC_dailyChange <- stocks1$HMC.Close-HMCa
stocks1$AMZN_dailyChange <- stocks1$AMZN.Close-AMZNa
stocks1$T_dailyChange <- stocks1$T.Close-Ta
stocks1$HRB_dailyChange <- stocks1$HRB.Close-HRBa
stocks1$RRGB_dailyChange <- stocks1$RRGB.Close-RRGBa

stocks1$ADDYY_dailyChange <- stocks1$ADDYY.Close-ADDYYa
stocks1$PCG_dailyChange <- stocks1$PCG.Close-PCGa
stocks1$ROST_dailyChange <- stocks1$ROST.Close-ROSTa
stocks1$JNJ_dailyChange <- stocks1$JNJ.Close-JNJa
stocks1$NFLX_dailyChange <- stocks1$NFLX.Close-NFLXa
stocks1$M_dailyChange <- stocks1$M.Close-Ma

stocks1$KSS_dailyChange <- stocks1$KSS.Close-KSSa
stocks1$DLTR_dailyChange <- stocks1$DLTR.Close-DLTRa
stocks1$WMT_dailyChange <- stocks1$WMT.Close-WMTa
stocks1$C_dailyChange <- stocks1$C.Close-Ca
stocks1$AAP_dailyChange <- stocks1$AAP.Close-AAPa
stocks1$JBLU_dailyChange <- stocks1$JBLU.Close-JBLUa

stocks1$MSFT_dailyChange <- stocks1$MSFT.Close-MSFTa
stocks1$KGJI_dailyChange <- stocks1$KGJI.Close-KGJIa
stocks1$EPD_dailyChange <- stocks1$EPD.Close-EPDa
stocks1$TJX_dailyChange <- stocks1$TJX.Close-TJXa
stocks1$HOFT_dailyChange <- stocks1$HOFT.Close-HOFTa

stocks1$LUV_dailyChange <- stocks1$LUV.Close-LUVa
stocks1$NKE_dailyChange <- stocks1$NKE.Close-NKEa
stocks1$TM_dailyChange <- stocks1$TM.Close-TMa
stocks1$VZ_dailyChange <- stocks1$VZ.Close-VZa
stocks1$SIG_dailyChange <- stocks1$SIG.Close-SIGa

```


Combine the stocks1 stats of ROI and daily change in dollars per stock to the stocks stats data table.
```{r}
stocks2 <- stocks1[,-c(1:52)]
StocksSTATS <- cbind(Stocks,stocks2)
```


All the columns we now have are:
```{r}
StocksSTATS <- StocksSTATS[,c(1:104,124:227,105:123)]
colnames(StocksSTATS)

```


```{r}
write.csv(StocksSTATS, 'STOCKS_STATS_v2.csv', row.names=TRUE)
```

***


***


***

Lets use the StocksSTATS table with the 230 columns of ROI for each stock from the start in 2007 throughout 2020 and the daily changes for each stock for the same time span. We could add cumulative sum columns to each stock or just plot the daily changes for each of the 52 stocks and see if we notice any patterns and compare the the final recording ROI from the initial investment. Maybe see if some of these stocks are good to jump on, like a wave to increase value of the portfolio, or drop the stock at some point to keep the portfolio from dropping in value.
```{r}
dailyChange <- grep('dailyChange',colnames(StocksSTATS))
DailyChanges <- StocksSTATS[,c(dailyChange,215:218,223)]
summary(DailyChanges)
```

```{r}
dailyChangesColSums <- as.data.frame(colMeans(DailyChanges[1:52]), dims=1)
colnames(dailyChangesColSums) <- 'avgDailyChange_2007_2020'
row.names(dailyChangesColSums) <- gsub('_dailyChange','',row.names(dailyChangesColSums))
head(dailyChangesColSums,5)
```

The DOW Industrial Jones average was also downloaded from [Yahoo Finance](https://finance.yahoo.com/quote/%5EDJI/history/) to see a bigger picture of these daily changes by adding in the change in the DOW. We will upload it to our data and put the daily change values into a new column with the Close of the DOW daily.
```{r}
dow <- read.csv('DOW.csv', sep=',', header=T, na.strings=c('',' '))
head(dow)
```

Lets keep the date, close, and volume columns.
```{r}
dow1 <- dow[,c(1,5,7)]
colnames(dow1) <- c('Date','DOW_Daily_Close','DOW_Daily_Volume')
head(dow1)
```

Now add in a daily change column to the dow1 table.
```{r}
dow_a <- dow1$DOW_Daily_Close
dow_b <- c(0,dow_a)
dow_c <- dow_b[1:(length(dow_b)-1)]
dow1$DOW_Daily_Change <- dow1$DOW_Daily_Close-dow_c
head(dow1)
```

Lets attach the daily change of the DOW to the table of daily changes per stock we made earlier and compare.
```{r}
dow1$Date <- as.Date(dow1$Date)
DailyChanges2 <- merge(DailyChanges, dow1, by.x='Date', by.y='Date')
colnames(DailyChanges2)
```

Lets add an indicator for increasing or decreasing unemployment rate per month.
```{r}
DailyChanges2 <- DailyChanges2[order(DailyChanges2$Date),]
DailyChanges2$lastMonth_UE_rate <-
  c(DailyChanges2$UE_monthlyRate[1],
    DailyChanges2$UE_monthlyRate[1:length(DailyChanges2$UE_monthlyRate)-1])

DailyChanges2$increasingMonthly_UE_rate <- ifelse((DailyChanges2$UE_monthlyRate-DailyChanges2$lastMonth_UE_rate) ==1, 1, 0)

```

Save this file to csv.
```{r}
write.csv(DailyChanges2, 'DailyChanges_UE_DOW_07_20_v2.csv', row.names=FALSE)

```

Lets see a summary of our date with summaries when the unemployment rate increased the next month and the DOW daily changes increased the next day and separately a subset of the DOW decreasing daily.This will see if the DOW is affected by the increasing unemployment rate or not. And also show which stocks are increasing when the DOW is decreasing and unemployment rate increasing to indicate great public sentiment for those stocks during poor public sentiment about the state of the economy.
```{r}
dow_up_ue_up <- subset(DailyChanges2, DailyChanges2$increasingMonthly_UE_rate==1 & 
                         DailyChanges2$DOW_Daily_Change >= 0)

dow_down_ue_up <- subset(DailyChanges2, DailyChanges2$increasingMonthly_UE_rate==1 & 
                         DailyChanges2$DOW_Daily_Change < 0)


```

Summary of the DOW up and unemployment up:
```{r}
summary(dow_up_ue_up)

```




Summary of the DOW down and unemployment down:
```{r}
summary(dow_down_ue_up)

```


From the above subset of stock daily changes during a time of increasing monthly unemployment rate and decreasing DOW daily value, there are only three stocks that all had increasing daily median and mean values for those time periods: TEVA, WMT, and AAP. There are some stocks that only had median increasing values: HD, XOM, FFIN, GOOG, COST, AMZN, ADDY, PCG, ROST, JNJ, NFLX, DLTR, TJX, and NKE. One stock only had an increasing daily change mean value but not median value: HRB.


Lets look at these stocks that increased during decreasing public outlook on economy assumed from decreasing DOW value (losses in investments/future/retirement) and increasing unemployment (more people not working) from month before.
```{r}
stockNames <- read.csv('yahooStockBasket.csv', header=T, sep=',', na.strings=c('',' '))
stockNames$stock <- gsub('-','.', stockNames$stock)
stockNames$stock <- gsub('.PB',' ', stockNames$stock)

stocksGood <- subset(stockNames, stockNames$stock == 'TEVA' |
                       stockNames$stock == 'WMT'|
                       stockNames$stock == 'AAP'|
                       stockNames$stock == 'HD'|
                       stockNames$stock == 'XOM'|
                       stockNames$stock == 'FFIN'|
                       stockNames$stock == 'GOOG'|
                       stockNames$stock == 'COST'|
                       stockNames$stock == 'AMZN'|
                       stockNames$stock == 'ADDY'|
                       stockNames$stock == 'PCG'|
                       stockNames$stock == 'ROST'|
                       stockNames$stock == 'JNJ'|
                       stockNames$stock == 'NFLX'|
                       stockNames$stock == 'DLTR'|
                       stockNames$stock == 'TJX'|
                       stockNames$stock == 'NKE'|
                       stockNames$stock == 'HRB')
stocksGood$stockInfo

```



Split the summaries of each table to show those that have mean positive values.
```{r, message=FALSE, error=FALSE, warning=FALSE}
S <- as.data.frame(summary(dow_up_ue_up))
S1 <- as.data.frame(summary(dow_down_ue_up))
S <- S[-(1:6),-1]
S1 <- S1[-(1:6),-1]

S$Freq <- as.character(S$Freq)
S1$Freq <- as.character(S1$Freq)

s_a <- strsplit(S$Freq, ':')
s_b <- strsplit(S1$Freq, ':')

S$Stat <- lapply(s_a, '[',1)
S1$Stat <- lapply(s_b, '[',1)

S$Stat <- as.vector(S$Stat)

S$StatValue <- as.numeric(lapply(s_a, '[',2))
S1$StatValue <- as.numeric(lapply(s_b, '[',2))

S_mean <- S[grep('Mean', S$Stat),]
S1_mean <- S1[grep('Mean', S1$Stat),]

Dow_up_ue_up_meanPos <- subset(S_mean, S_mean$StatValue >= 0)
Dow_down_ue_up_meanPos <- subset(S1_mean, S1_mean$StatValue >= 0)

Dow_up_ue_up_meanPos <- Dow_up_ue_up_meanPos[grep('dailyChange', Dow_up_ue_up_meanPos$Var2),]
Dow_down_ue_up_meanPos <- Dow_down_ue_up_meanPos[grep('dailyChange',
                                                      Dow_down_ue_up_meanPos$Var2),]
colnames(Dow_up_ue_up_meanPos)[1] <- 'DOW_up_UE_up'
colnames(Dow_down_ue_up_meanPos)[1] <- 'DOW_down_UE_down'

S_Median <- S[grep('Median', S$Stat),]
S1_Median <- S1[grep('Median', S1$Stat),]

Dow_up_ue_up_MedianPos <- subset(S_Median, S_Median$StatValue >= 0)
Dow_down_ue_up_MedianPos <- subset(S1_Median, S1_Median$StatValue >= 0)

Dow_up_ue_up_MedianPos <- Dow_up_ue_up_MedianPos[grep('dailyChange', Dow_up_ue_up_MedianPos$Var2),]
Dow_down_ue_up_MedianPos <- Dow_down_ue_up_MedianPos[grep('dailyChange',
                                                      Dow_down_ue_up_MedianPos$Var2),]
colnames(Dow_up_ue_up_MedianPos)[1] <- 'DOW_up_UE_up'
colnames(Dow_down_ue_up_MedianPos)[1] <- 'DOW_down_UE_down'

```

Write those tables to csv to use as needed. We should test how well the same amount invested in the original 52 stocks over the span from 2007-2020 did to the same amount of money using different weights on those stocks whose value of daily changes was positive for the median and mean values separately when the DOW was up and unemployment was up and also when the DOW was down and unemployment was up. The Stat column is a list and won't print to csv without removing it, and the Freq column also has the statistic being evaluated.
```{r}
write.csv(Dow_up_ue_up_meanPos[,-3], 'Dow_up_ue_up_meanPos_v2.csv', row.names=FALSE)
write.csv(Dow_down_ue_up_meanPos[,-3],'Dow_down_ue_up_meanPos_v2.csv', row.names=FALSE)
write.csv(Dow_up_ue_up_MedianPos[,-3],'Dow_up_ue_up_MedianPos_v2.csv', row.names=FALSE)
write.csv(Dow_down_ue_up_MedianPos[,-3],'Dow_down_ue_up_MedianPos_v2.csv', row.names=FALSE)
```

Now, will make a vector of those stocks that have positive medians and means when the DOW is up or down when unemployment is up.
```{r}
Dow_up_med <- as.data.frame(Dow_up_ue_up_MedianPos$DOW_up_UE_up)
DOW_up_mean <- as.data.frame(Dow_up_ue_up_meanPos$DOW_up_UE_up)
DOW_down_med <- as.data.frame(Dow_down_ue_up_MedianPos$DOW_down_UE_down)
DOW_down_mean <- as.data.frame(Dow_down_ue_up_meanPos$DOW_down_UE_down)

colnames(Dow_up_med) <- 'Dow_up_median'
colnames(DOW_up_mean) <- 'DOW_up_mean'
colnames(DOW_down_med) <- 'DOW_down_median'
colnames(DOW_down_mean) <- 'DOW_down_mean'

DOW_up_mean$DOW_up_mean <- gsub('_dailyChange','', DOW_up_mean$DOW_up_mean)
DOW_down_mean$DOW_down_mean <- gsub('_dailyChange', '', DOW_down_mean$DOW_down_mean)
Dow_up_med$Dow_up_median <- gsub('_dailyChange', '', Dow_up_med$Dow_up_median)
DOW_down_med$DOW_down_median <- gsub('_dailyChange', '', DOW_down_med$DOW_down_median)
```


Lets add the values to these subsets of all 52 original stocks.
```{r}
StockValues <- Close2
StockValues <- StockValues[,-c(1,55:58,60:63)]

colnames(StockValues) <- gsub('.Close','', colnames(StockValues))
StockValues$total <- rowSums(StockValues[1:52])
StockValues$Date <- row.names(StockValues)
portfolio52 <- StockValues[order(StockValues$Date,decreasing=FALSE),]

portfolio52 <- portfolio52[c(1,length(StockValues$TGT)),]
portfolio52

```

The profit is taken from the DailyValue of the portfolio52 table.
```{r}
profit_all <- 7300-2698
profit_all
```
With all 52 stocks from January 1, 2007 throughout February 14, 2020, the portfoliio initially cost 2978 USD and was valued at 8193 USD at the end of that time span. Lets see how much the portfolio is worth when using only the stocks in our subsets of stocks that had positive values when the DOW was up or down but unemployment was increasing. The profit earned was 5215 USD with this portfolio.

```{r}
p52 <- gather(StockValues, 'stock','stockValue', 1:52)

```


The positive median value stock when the DOW was up and unemployment was up.
```{r}
p1 <- merge(Dow_up_med,p52, by.x='Dow_up_median','stock')
P1 <- p1 %>% group_by(Date) %>% summarise_at(vars(stockValue), sum)
P1[c(1,length(P1$Date)),]
```

The initial stock value for the portfolio of stock that had a positive median value when the DOW was up and unemployment was up started at 2698 USD and ended with a value of 7300 USD. Lets weight this portfolio so that we can see the profits in dollars if the initial investment was the same amount as the investment of all 52 stocks.
```{r}
P1_i <- P1$stockValue[1]
P1_l <- P1$stockValue[length(P1$stockValue)]
P1_i
P1_l
profit1 <- P1_l-P1_i
profit1

r1 <- P1_l/P1_i
r1

p52i <- portfolio52$total[1]
p52i

finalValue_P1 <- p52i*r1
finalValue_P1

total_P1_profit <- finalValue_P1 - p52i
total_P1_profit

unique(p1$Dow_up_median)
```

***

The positive median value stock when the DOW was down and unemployment was up.
```{r}
p2 <- merge(DOW_down_med,p52, by.x='DOW_down_median','stock')
P2 <- p2 %>% group_by(Date) %>% summarise_at(vars(stockValue), sum)
P2[c(1,length(P2$Date)),]

```


```{r}
P2_i <- P2$stockValue[1]
P2_l <- P2$stockValue[length(P2$Date)]
P2_i
P2_l

profit2 <- P2_l-P2_i
profit2

r2 <- P2_l/P2_i
r2

p52i <- portfolio52$total[1]
p52i

total_P2_Value <- p52i*r2 
total_P2_Value

total_P2_profit <- total_P2_Value - p52i
total_P2_profit

unique(p2$DOW_down_median)
```

The portfolio of stock that had positive median values of daily change when the DOW was down and unemployment was higher than the month before is shown above. There are 17 stocks in this portfolio. The initial value was 741 USD with a final value of 5658 USD and a profit of 4917 USD earned as is. If the same amount was invested in just these stocks as was invested in the entire portfolio of 52 stocks of 2978 USD, then the ratio of final/initial value would be used on adding additional stocks in this portfolio at a ratio of 7.64. The total end value would be 22747 USD with profits earned of 19769 USD.

***

The positive mean value stock when the DOW was up and unemployment was up.
```{r}
p3 <- merge(DOW_down_mean,p52, by.x='DOW_down_mean','stock')
P3 <- p3 %>% group_by(Date) %>% summarise_at(vars(stockValue), sum)
P3[c(1,length(P3$Date)),]


```

```{r}
P3_i <- P3$stockValue[1]
P3_l <- P3$stockValue[length(P3$Date)]
P3_i
P3_l

profit3 <- P3_l-P3_i
profit3

r3 <- P3_l/P3_i
r3

p52i <- portfolio52$total[1]
p52i

total_P3_Value <- (p52i)*r3 
total_P3_Value

total_P3_profit <- total_P3_Value - p52i
total_P3_profit

unique(p3$DOW_down_mean)
```

The above portfolio shows those stocks who had a positive mean value of daily changes when the DOW was down and unemployment was increased more than the month before. There are only four stock in this portfolio. The initial value was 138 USD and the final value was 286 USD. The profits in dollars was 149 USD as is. The ratio of final/initial value is 2.08. When investing the same amount of 2978 USD as was used in the portfolio of 52 stock, the dollars earned were 6192 USD, with profit earned in dollars of 3213 USD.

***

The positive mean value stock when the DOW was down and unemployment was up.
```{r}
p4 <- merge(DOW_up_mean,p52, by.x='DOW_up_mean','stock')
P4 <- p4 %>% group_by(Date) %>% summarise_at(vars(stockValue), sum)
P4[c(1,length(P4$Date)),]

```

```{r}
P4_i <- P4$stockValue[1]
P4_l <- P4$stockValue[length(P4$Date)]
P4_i
P4_l

profit4 <- P4_l-P4_i
profit4

r4 <- P4_l/P4_i
r4

p52i <- portfolio52$total[1]
p52i

total_P4_Value <- p52i*r4 
total_P4_Value

total_P4_profit <- total_P4_Value - p52i
total_P4_profit

unique(p4$DOW_up_mean)
```

The above shows those stock in the portfolio that had a positive mean daily change when the DOW was up and unemployment was up. There are 20 stocks in this portfolio. The initial value of this portfolio was 1588 USD and the final value was less at 1476 USD. The loss was 112 USD with a final/initial ratio of 0.93. When investing the same amount as the initial portfolio of 2978 USD, the final portfolio value is a loss of 210 USD. 


Lets make a data table of this information.
```{r}
du1 <- as.data.frame( c(P1_i, P2_i,P3_i,P4_i))
du2 <- as.data.frame( c(P1_l,P2_l,P3_l,P4_l)) 
du3 <- as.data.frame(c(length(unique(p1$Dow_up_median)),length(unique(p2$DOW_down_median)),
         length(unique(p3$DOW_down_mean)), length(unique(p4$DOW_up_mean))))
du4 <- as.data.frame( c(profit1, profit2, profit3, profit4))

colnames(du1) <- 'initialValue'
colnames(du2) <- 'finalValue'
colnames(du3) <- 'numberStocksInPortfolio'
colnames(du4) <- 'profitInitialValue'

du5 <- as.data.frame(c(p52i,p52i,p52i,p52i))
colnames(du5) <- 'ifInitialInvestmentAsAll52Made'

du6 <- as.data.frame(c(finalValue_P1, total_P2_Value,total_P3_Value,total_P4_Value))
colnames(du6) <- 'finalValueIfSame52StockInvestment'

du7 <- as.data.frame(c(total_P1_profit, total_P2_profit, total_P3_profit, total_P4_profit))
colnames(du7) <- 'totalProfitSame52StockInvestment'

du8 <- as.data.frame(c(r1,r2,r3,r4))
colnames(du8) <- 'ratioFinal_2_Initial'

DOW_UE <- cbind(du1,du2,du8,du4,du3,du5,du6,du7)
row.names(DOW_UE) <- c('Dow_up_median','DOW_down_median','DOW_down_mean','DOW_up_mean')

write.csv(DOW_UE, 'DOW_UE.csv', row.names=TRUE)

DOW_UE
```


In summary of evaluating the stocks that had positive mean and median values when the unemployment rate was more than the previous month, but the DOW was either increasing or decreasing on that day from the previous day, the best portfolio of stocks was the one with the highest profit. The return on investment ratio was 7.63 for this portfolio, with an initial investment of 741 USD it returned 5658 USD, but when the same investment amount was distributed to this portfolio as the entire portfolio of 52 stocks of 2978 USD, the profits made were 19769 USD from 2007 through 2020.

The portfolio of stock that performed the worst with a loss of 111 USD on an initial investment of 1588 USD and a final to initial value ratio of 0.93 was the portfolio of stock that had a positive daily change mean value when the DOW was up and unemployment rate up. When this portfolio had the 2978 USD invested in it as the original portfolio of 52 stocks it saw a loss of 210 USD from 2007-2020.

The portfolio of stocks all having a positive median value of daily changes did much better than the positive mean value stock portfolios when the DOW was up or down and unemployment rate increased from the previous month from 2007-2020.

***

The question arises when asked on how to distribute the remaining dollars of the initial investment of the original portfolio of all 52 stocks, when that value you want to invest is 2978 USD but the portfolio of single stocks have a set value of 138-1588 USD for the four portfolios.

We would use an even weighted distribution if we could buy partial stocks, but it is likely we will not be able to. If it is the case that we could distribute the weights of the remaining balance to buy partial stocks then you would take that remaining balance and divide by the number of stock in the portfolio. We could do that now to see how much each of the weights are in investment dollars of each stock.
```{r}
DOW_UE$EvenRemainingWeightsUSD <- (DOW_UE$ifInitialInvestmentAsAll52Made-DOW_UE$initialValue)/
  (DOW_UE$numberStocksInPortfolio)
DOW_UE$EvenWeightsUSD <- (DOW_UE$ifInitialInvestmentAsAll52Made)/(DOW_UE$numberStocksInPortfolio)
DOW_UE[,c(1,5,9,10)]
```

The above table shows even weights after one stock of each is bought and the remaining money from 2978 USD is dispursed equally to each stock in the portfolio in the 'EvenRemainingWeightsUSD' column. The value of the even weights on the amount of dollars to invest in each stock from the total 2978 USD is in the 'EvenWeightUSD' column. 

If you are not allowed to buy partial stocks, then you would have to rank the stocks in each portfolio so that more money is spent on the forecasted higher yielding stock.

***

So, we found a subset of stock in the portfolio that did outstanding, and we want to buy those stocks to make a profit, but we also want to look at the characteristics of those stocks and see what features they have or properties in the data that could make any other stock fit a description of a 'good stock to buy' category. Some features that come to mind are, are they all increasing, are they cyclical, how many local maxima and local minima each of these stocks have, what the sentiment in the internet search engines provide for these stocks, do they market, are they politically motivated such as Nike with the footbal player protesting police abuse of black males, are they part of larger business mergers such as talks of Tmobile getting bought out by Sprint, or how Frontier bought a portion of Verizon, and so on. 

Also, we want to look at this as a careless surfer looking for intervals of small waves to buy close to the local minima on these stocks, ride it out and sell it close to its local maxima to simulate how exploiting the stocks in the short run can lead to more profits. We could all do this and just like this line of code is in 1920s, a depression could follow if we all did this. Like a huge crash. But we're all blind, arrogant data scientists in charge of our own way of thinking and we want to see what happens. So lets do it. Did I lose you on the analogy? Which one? Its ok, you'll find yourself for the next part of this data exploration.


***

Lets look at our 17 stocks belonging to the best subset and see what qualities each stock has by first adding a feature column on the stock brand with an internet search and looking at the local minima and maxima of each stock.
```{r}
set17 <- merge(DOW_down_med, stockNames, by.x='DOW_down_median', by.y='stock')
set17
```

Lets search these companies and add in a feature that gives the number of results for each company.
```{r}
set17$numberSearchReturnMillions <- round(c(0.446, 1.99,541, 0.780, 0.379, 0.0465, 3.51, 0.410, 45.1, 
                                      4.46, 4.28, 0.00417, 4.11, 0.00392, 2.59, 1.7, 1.14),4)

```


```{r}
closing17 <- Close2[,-c(1,55:58,60)]
colnames(closing17) <- gsub('.Close','',colnames(closing17))
colnames(closing17) <- gsub('.PB','', colnames(closing17))
close17 <- gather(closing17, 'stock','stockValue',1:52)
Close17 <- merge(DOW_down_med, close17, by.x='DOW_down_median', by.y='stock')
Close17 <- Close17[order(Close17$Date),]

dow17 <- dow[,-c(2:4,6,7)]
dow17$Date <- as.Date(dow17$Date)
colnames(dow17)[2] <- 'DOW_Close'
Close17_dow <- merge(Close17, dow17, by.x='Date', by.y='Date')
```


```{r}
aap <- subset(Close17_dow, Close17_dow$DOW_down_median=='AAP' )
aap1 <- subset(aap, aap$Year==2017|
                aap$Year==2018|
                aap$Year==2019)

ggplot(data = aap, aes(x=Year, y=stockValue)) +
  geom_line()+
  scale_y_continuous()+
  scale_fill_brewer(palette="paired") +
  theme(legend.position="bottom")+
  ggtitle('AAP Value 2007-2020')+
  ylab('Dollars')
```
The above shows that AAP had a huge drop in 2017 at a local minimum, the other minimum is in 2008 and is the global minimum for this stock. The next chart shows the years 2017-2020 to zoom in on this loss.

```{r}
annotation1 <- data.frame(
   x = c(as.Date('2017-11-01'),as.Date('2018-04-04'),as.Date('2019-09-04')),
   y = c(100,95,120),
   label = c("Nov 2017", "May 2018","Aug 2019"))

gg1 <- ggplot(data = aap1, aes(x=Date, y=stockValue)) +
       geom_line()+
       scale_y_continuous()+
       scale_fill_brewer(palette="paired") +
       theme(legend.position="bottom")+
       ggtitle('AAP 2017-2020')+
         geom_text(data=annotation1, aes( x=x, y=y, label=label),                 , 
           color="red", 
           size=2.5 , angle=90 , fontface="bold")+
       ylab('Stock Value Dollars')
gg1
```

The chart above shows that AAP had a decreasing year in 2017 down to its minimum value in the fourth quarter of the year, then increased throughout 2018 until 2019. There was also another local minima in the third quarter of 2019 for AAP before it began increasing. Something could have happened in the first quarter of 2017 to cause it to decrease and another thing in 2018. We could check the internet for articles around that time. Lets look at the summary stats for this table.

```{r}
summary(aap1)

```

The above summary statistics show a low unemployment rate for this period of time spanning three years from 2017 to 2020 with unemployment ranging from 3.5 to 4.7. The DOW had closing values ranging from 19732 USD to 28645 USD. Lets plot this date range for the DOW and see if they move together.


```{r}

annotation2 <- data.frame(
   x = c(as.Date('2017-11-01'),as.Date('2018-04-04'),as.Date('2019-09-04')),
   y = c(21000,22000,24000),
   label = c("Nov 2017", "May 2018","Aug 2019"))

gg2 <- ggplot(data = aap1, aes(x=Date, y=DOW_Close)) +
       geom_line()+
       scale_y_continuous()+
       scale_fill_brewer(palette="paired") +
       theme(legend.position="bottom")+
       ggtitle('DOW 2017-2020')+
       ylab('DOW Value Dollars')+
       geom_text(data=annotation2, aes( x=x, y=y, label=label),                 , 
           color="red", 
           size=2.5 , angle=90 , fontface="bold")
gg2
```

The above chart shows the increasing values of the DOW the same years as the AAP saw a decreasing year in 2017 to its local minimum in the fourth quarter of 2017, and then an increase until 2019 when it stabilized around the same value till 2020. But the DOW increased the time that AAP was decreasing and saw a local minima in the end of 2018 right when AAP reached a smaller local minima and also in the third quarter when AAP also had a local minima.

Lets look at these charts on top of each other.
```{r}
grid.arrange(gg1, gg2, nrow = 2)

```



Lets see what happened in 2017 for AAP and in 2018 to cause it to decrease then increase respectively... just declining sales, plans to expand and open more stores, and public outcry on the sales declines of Advance Auto Parts. So, this could mean that because the DOW was doing great and increasing, investors thought to take their money out of the after market car parts stores, or maybe they thought they were hurting because of Amazon Prime taking their business. Those are some possibilities. When looking at stocks in the [DOW Jones industrial average](https://www.buyupside.com/sample_portfolios/djindustrialsstocks.php), AAP isn't listed as one of these stocks, so it could be that people took their money out of the after markets car parts stock as it was declining and put it into any of the stocks that belong to the DOW, because it increased in value in 2017 while AAP decreased, then they both moved together around and after 2018.


```{r}
aaplog <- aap
aaplog$logAAP <- log1p(aaplog$stockValue)
aaplog$logDOW <- log1p(aaplog$DOW_Close)

g1 <- ggplot(data = aaplog, aes(x=Year, y=logAAP)) +
      geom_line()+
      scale_y_continuous(limits=c(3,7))+
      scale_fill_brewer(palette="paired") +
      theme(legend.position="bottom")+
      geom_vline(xintercept=c(2008,2017), linetype='dashed', color='red')+
      ggtitle('log AAP 2007-2020')+
      ylab('Stock Value Dollars')

g2 <- ggplot(data = aaplog, aes(x=Year, y=logDOW)) +
      geom_line()+
      scale_y_continuous(limits=c(5,12))+
      scale_fill_brewer(palette="paired") +
      theme(legend.position="bottom")+
      geom_vline(xintercept=c(2008,2017), linetype='dashed', color='red')+
      ggtitle('log DOW 2007-2020')+
      ylab('Stock Value Dollars')

grid.arrange(g1, g2, nrow = 2)

```

The above chart shows the log scale of the value + 1 so that there aren't any natural log errors in scaling. There is also an added few lines to show the years of 2008 and 2017 when AAP had decreasing years in stock value.

***

Lets look at the DOW over the years with the other 16 stocks in this portfolio of stocks that proved most profitable when the DOW was down and unemployment was up using the set of stocks with positive median values under those constraints.
```{r}
dROI17 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(stockValue), mean)
colnames(dROI17)[2] <- 'avgStockValue'

start17 <- subset(Close17_dow, Close17_dow$Date=='2007-01-03')
final17 <- subset(Close17_dow, Close17_dow$Date=='2020-02-14')

start17 <- start17[order(start17$DOW_down_median),]
final17 <- final17[order(final17$DOW_down_median),]
dROI17 <- dROI17[order(dROI17$DOW_down_median),]

DOW_ROI <- as.data.frame(final17$DOW_Close/start17$DOW_Close)
colnames(DOW_ROI) <- 'DOW_ROI'

colnames(start17)[6] <- 'startValue'
colnames(final17)[6] <- 'finalValue'

dROI17$startValue <- start17$startValue
dROI17$finalValue <- final17$finalValue
dROI17$DOW_ROI <- DOW_ROI$DOW_ROI
dROI17$stock_ROI <- dROI17$finalValue/dROI17$startValue
dROI17
```

Netflix killed the return on investment with more than 100 fold profits. Lets look at Netflix to see the highs and lows of this stock since 2007 and through till 2020.
```{r}
nflx <- subset(Close17_dow, Close17_dow$DOW_down_median=='NFLX')
nflx1 <- subset(nflx, nflx$Year > 2011 & nflx$Year < 2014)
nflx2 <- subset(nflx, nflx$Year > 2016 & nflx$Year < 2018)
nflx3 <- subset(nflx, nflx$Year > 2018 & nflx$Year < 2020)

gg3 <- ggplot(data = nflx, aes(x=Date, y=stockValue)) +
       geom_line()+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('NFLX 2007-2020')+
       ylab('Stock Value Dollars')
gg4 <- ggplot(data = nflx1, aes(x=Date, y=stockValue)) +
       geom_line()+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('NFLX 2011-2014')+
       ylab('Stock Value Dollars')
gg5 <- ggplot(data = nflx2, aes(x=Date, y=stockValue)) +
       geom_line()+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('NFLX 2016-2018')+
       ylab('Stock Value Dollars')
gg6 <- ggplot(data = nflx3, aes(x=Date, y=stockValue)) +
       geom_line()+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('NFLX 2018-2020')+
       ylab('Stock Value Dollars')

grid.arrange(gg3, gg4, gg5,gg6, nrow = 2)

```

Netflix was certainly a great stock to invest in at around 3 USD in 2007 and at around 325 USD in 2020. We see that Netflix was on the up and up almost its entire course growing to more than 100 times its initial starting value in 2007. There were some lows such as in 2012 there was small dip in the curve, then in July and August-September 2017, and also in the third quarter of 2019. But it still performed amazingly. The stock dreams of riches are made of and conartists use to get more money from people on risky start up penny stocks. But lets put out all we know about Netflix.

- Netflix was first heard from the author of this tutorial in 2003 when some roommate of a guy the author dated bragged about how awesome Netflix is to cost $7/month and you can rent new movies mailed to your home for no additional charge. This roommate also bought a flat screen tv for 7000 USD before they became ubiquitously priced from 200-500 USD five years later.

- The minimum wage for workers around CA in this time period was also about the cost of the Netflix monthly membership. Many tv shows started being options to rent from sources such as premium cable tv shows like Dexter around 2007 or so.

- I pulled the cord on cable due to high costs and got a Netflix membership for around 8-10 USD in about 2014. Which was also around the price of minimum wage at that time.

- cell phones became very great and needed personal items with fast wifi and internet streamings still at a cost that beat cable tv and home phone lines at this same time period.

- Netflix got more innovative, they started adding more Netflix produced shows in 2016 that made memes on instagram and facebook, the top social media platforms of the time in the 2010s like with 'Orange is the New Black' ( I couldn't watch, but saw many memes on).

So, given what you know and what you scanned above, isn't it no surprise that a stock that out competes alternative forms of entertainment, is low cost in price and able to be taken mobile or use anywhere and at any time for next to nothing in cost as an hour of a consumer's 160-200 hour work month if working minimum wage and full time. Maybe its time to add another feature, like federal minimum wage rates to this data. We will in fact do this later, but for now we will add another feature that compares the ROI ration to that of the DOW Jones industrial average, and try to pull the most striking features out of that group. 
```{r}
dROI17$stockBeatsDOW <- ifelse(dROI17$stock_ROI > dROI17$DOW_ROI, 'Yes', 'No')
dROI17[,c(1,7)]
```

Looking at the above chart of the stocks that beat the DOW in return on investment ratios of final stock value to initial stock value (2007-2020), Exxon Mobil, Johnson & Johnson, Teva Pharmaceuticals Industries, and Pacific Gas and Electric lossed money or had lower returns than that of the DOW. Of note, the pharmaceuticals might make you go on a wild tangent to know which company is supplying us with flu vaccines annually. If so, [Sanofi (SNY)](https://finance.yahoo.com/quote/SNY/) is the US's largest supplier and they aren't in this analysis. But it would be interesting to see when they make the most money, considering we have a CoV-19 flu contagion globally as of Feb. 2020. While, it is safe to say the companies that low income consumers love  or live by did well, such as: Walmart, Adidas, Nike, Home Depot, Netflix, Amazon, Advance Auto Parts, TJ Maxx, Ross, Dollar Tree, and Costco. Costco is more of a middle class or small business store because you have to have cash, or used to have cash or money in your checking account to buy their goods and services with your atm card. They may have changed this. First Financial bank also did well, and it was selected because it was one of the banks available when hand picking these stocks. I don't use it and don't know anyone who does, and that is because I am on the West Coast, and this bank originates out of the East Coast. This could be an indicator that the East Coast is picking up in business and getting more home loans, business loans, etc. Than the more West Coast known banks like Citi, Chase, Bank of America, JP Morgan Chase. As these other banks did not perform well for median positive daily changes in stock prices during increasing unemployment and decreasing DOW values.

Lets plot those four stocks in this portfolio that did worse than the DOW.
```{r}
low4 <- subset(Close17_dow, Close17_dow$DOW_down_median == 'JNJ'|
                  Close17_dow$DOW_down_median == 'PCG'|
                  Close17_dow$DOW_down_median == 'TEVA'|
                  Close17_dow$DOW_down_median == 'XOM')
gg7 <- ggplot(data = low4, aes(x=Date, y=stockValue, group=DOW_down_median)) +
       geom_line(aes(color=DOW_down_median))+
       scale_y_continuous()+
       scale_fill_brewer(palette="Spectral") +

       theme(legend.position="bottom")+
       ggtitle('Lowest Stock ROI 2007-2020')+
       ylab('Stock Value Dollars')
gg8 <- ggplot(data = low4, aes(x=Date, y=DOW_Close)) +
       geom_line()+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('DOW Value 2007-2020')+
       ylab('DOW Value Dollars')

grid.arrange(gg7,gg8, nrow = 2)
```

From the above charts, It looks like Johnson & Johnson has started to move upward with the DOW starting around 2013. The TEVA stock seems to be negatively correlated with the DOW and Exxon Mobil was positively correlated with the DOW from 2007 to about 2015, then started moving in the opposite direction after 2015. Exxon supplies fuels to automobiles, while PCG supplies electricity to hybrid and electric vehicles in certain US regions. Yet, both started moving opposite directions with the DOW after 2015.

Lets now compare Costco and Walmart to each other and the DOW.
```{r}
wal_Cost <- subset(Close17_dow, Close17_dow$DOW_down_median=='WMT' | 
                     Close17_dow$DOW_down_median=='COST')

gg9 <- ggplot(data = wal_Cost, aes(x=Date, y=stockValue, group=DOW_down_median)) +
       geom_line(aes(color=DOW_down_median))+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('Walmart and Costco Value 2007-2020')+
       ylab('Stock Value Dollars')

grid.arrange(gg9,gg8, nrow = 2)

```

It is interesting to note that Costco and the DOW seem to be identical curves for the direction they move while Walmart seems also be increasing when the DOW does but at a much lower rate over time.


Lets now compare TJ Maxx, Ross, Nike, and Adidas to the DOW.
```{r}
Retail <- subset(Close17_dow, Close17_dow$DOW_down_median == 'TJX' |
                   Close17_dow$DOW_down_median == 'ROST' )

Shoes <- subset(Close17_dow, Close17_dow$DOW_down_median == 'NKE' |
                   Close17_dow$DOW_down_median == 'ADDYY' )


gg10 <- ggplot(data = Retail, aes(x=Date, y=stockValue, group=DOW_down_median)) +
       geom_line(aes(color=DOW_down_median))+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('Ross, & TJ Maxx Value 2007-2020')+
       ylab('Stock Value Dollars')

gg11 <- ggplot(data = Shoes, aes(x=Date, y=stockValue, group=DOW_down_median)) +
       geom_line(aes(color=DOW_down_median))+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('Adidas & Nike Value 2007-2020')+
       ylab('Stock Value Dollars')

grid.arrange(gg10, gg11, gg8, gg8, nrow =2)
```

The DOW is plotted below each of the two plots of either Ross & TJ Maxx, or Adidas & Nike.
Both Ross and Adidas did better than TJ Maxx and Nike. Except, that Nike did do better than Adidas between 2015 and 2016.

Now, lets look at Dollar Tree and Amazon compared to each other and the DOW in this time span.
```{r}
DLRv <- subset(Close17_dow, Close17_dow$DOW_down_median == 'DLTR' )
AMZNv <- subset(Close17_dow, Close17_dow$DOW_down_median == 'AMZN' )


gg12 <- ggplot(data = DLRv, aes(x=Date, y=stockValue, group=DOW_down_median)) +
       geom_line(aes(color=DOW_down_median))+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('Dollar Tree Value 2007-2020')+
       ylab('Stock Value Dollars')

gg13 <- ggplot(data = AMZNv, aes(x=Date, y=stockValue, group=DOW_down_median)) +
       geom_line(aes(color=DOW_down_median))+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('Amazon Value 2007-2020')+
       ylab('Stock Value Dollars')

grid.arrange(gg12, gg13, gg8, gg8, nrow =2)
```


The above charts show Dollar Tree compared to Amazon and both compared to the DOW between 2007 and 2020. The Dollar Tree seems to be cyclical but overall increasing, while Amazon was a steady increase over the years except in 2018 where it had a decrease.

```{r}
AMZNv2 <- subset(Close17_dow, Close17_dow$Year > 2017 &
                   Close17_dow$DOW_down_median == 'AMZN')

gg14 <- ggplot(data = AMZNv2, aes(x=Date, y=stockValue)) +
       geom_line()+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('Amazon Value 2018-2020')+
       ylab('Stock Value Dollars')
gg14

```

We see a drop in value of Amazon after September 2018 until about January 2019 when it increases until just before the end of the 2nd quarter in 2019 then it drops in the 1st quarter staying low before increasing to a global maximum in January 2020.

Lets look at Home Depot and Advance Auto parts now.
```{r}
HDv <- subset(Close17_dow, Close17_dow$DOW_down_median=='HD' |
                Close17_dow$DOW_down_median=='AAP')

gg15 <- ggplot(data = HDv, aes(x=Date, y=stockValue, group=DOW_down_median)) +
       geom_line(aes(color=DOW_down_median))+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('Home Depot & Advance Auto Parts 2007-2020')+
       ylab('Stock Value Dollars')

grid.arrange(gg15, gg8, nrow =2)

```

The charts above show that Home Depot and the DOW move together by increasing the time span from 2007-2020. Advance Auto Parts showed it had been increasing from 2007-2016, but then declined to a local minimum in the middle of 2017 where it then increased and remained a steady value up to 2020.

Lets also look at Google and First Financial Bankshares.
```{r}
ffin <- subset(Close17_dow, Close17_dow$DOW_down_median=='FFIN')
goog <- subset(Close17_dow, Close17_dow$DOW_down_median=='GOOG')

gg16 <- ggplot(data=ffin, aes(x=as.factor(Date), y=stockValue, group=DOW_down_median))+
        geom_line(aes(color=DOW_down_median))+
        geom_smooth(method = "lm")+
        annotate("rect", xmin = "2018-07-01", xmax = "2019-03-31", ymin = 25, ymax = 35,
        alpha = .4)+
        scale_x_discrete(breaks=c("2010-01-04","2015-01-02","2018-01-05",
                                  "2019-01-03"),
                         labels=c("2010","2015", "2018","2019"))+
        scale_y_continuous()+
        theme(legend.position="bottom")+
        ggtitle('First Financial Bankshares 2007-2020')+
        ylab('Stock Value Dollars')
        
gg17 <- ggplot(data = goog, aes(x=Date, y=stockValue, group=DOW_down_median)) +
       geom_line(aes(color=DOW_down_median))+
       geom_smooth(method = "lm")+
       scale_y_continuous()+
       theme(legend.position="bottom")+
       ggtitle('Google 2007-2020')+
       ylab('Stock Value Dollars')

grid.arrange(gg16, gg17,nrow =2)

```

The above chart shows Google and First Financial Bankshares from 2007-2020. First Financial has many highs and lows between 2015-2020 but is overall increasing, while Google is steadily increasing up till 2017 when it has a few highs and lows until 2020. Both have increased overall as indicated by the linear trendlines added to the two linear plots above for Google and First Financial Bankshares.

We know that some of these plots have time periods that are cyclical, but so far we know that overall, if we want to earn the most on our portfolios we would like to buy low and sell high. These stocks are increasing to rates higher than when they start a cyclical pattern. Lets examine the First Financial Bankshares stock when it sees these cyclical patterns further for some strategy development. There are three peaks or highs for FFIN after about 2017, so lets plot this.
```{r}
ffin2 <- subset(ffin, ffin$Year==2018 & ffin$Month=='Jul'|
                  ffin$Year==2018 & ffin$Month=='Aug'|
                  ffin$Year==2018 & ffin$Month=='Sep'|
                  ffin$Year==2018 & ffin$Month=='Oct'|
                  ffin$Year==2018 & ffin$Month=='Nov'|
                  ffin$Year==2018 & ffin$Month=='Dec'|
                  ffin$Year==2019 & ffin$Month=='Jan'|
                  ffin$Year==2019 & ffin$Month=='Feb'|
                  ffin$Year==2019 & ffin$Month=='Mar')
                
                  

t <- seq(0,15,0.1)
y <- sin(t)
ty <- qplot(t,y, geom='path', xlab='time', ylab='Sin(x)')

gg18 <- ggplot(data=ffin2, aes(x=Date, y=stockValue, group=DOW_down_median))+
        geom_line(aes(color=DOW_down_median))+
        geom_smooth(method = "lm")+
        scale_y_continuous()+
        theme(legend.position="bottom")+
        ggtitle('FFIN 3 Quarters 2018-2019')+
        ylab('Stock Value Dollars')

grid.arrange(gg16,gg18,gg8, ty,nrow=2)
```

The above chart shows the sine curve to illustrate the highs and lows of the daily value changes for the First Financial Bankshares linear plot. If the curve was distorted at certain time intervals startind in the 3rd quarter of 2018 and ending before the 2nd quarter of 2019, this sine curve would show the three waves this stock saw. We are interested in buying at the beginning of the 3rd quarter when the price is low, then selling before the start of the 4th quarter when the stock is high, then buying again when it sees a dip in price after about the 1st month of the 4th quarter, then selling in the middle of the 4th quarter when high, buying at the end of the 4th quarter when low, and selling when high in the middle of the 1st quarter of 2019, and buying when low at the end of the 1st quarter, to maximize profits. 


***

These quick analysis of the stock that did well when the DOW was decreasing and unemployment was increasing was interesting to look at. But now, lets look at these stocks and find out if we can indicate when a stock is good by setting a threshold for the number of minimums the stock has and if it decreases by more than its value in the last quarter and also the last two quarters then compare this to the local maxima where it increases to more than a set threshold than it was valued at in the last quarter and also the last two quarters. Count the number of times this happens and compare to the data on the stock ROI. This will require adding in more columns to calculate the daily change compared to a median value of the stock in each quarter. We have the years, the months, and the stock values in the table we are currently using.

We can do this by using time lags with the dplyr package. We should already have this package loaded. We have been using for median and mean calculations when grouping by stock.
The data set we should use could be this one, Close17_dow, or we could spread out the stock names back to being columns and add the stock lags for each stock for 7 days, 30 days, 90 days, and 180 days. Don't get too excited, we have 52 stocks to do this for, or we could just do it with these 17 stocks that made the most profit from having positive median values when unemployment was increasing and the DOW was decreasing. I vote we do the 17.
***

We are going to create time lags of 7,30,60,90, 120, 150, and 180 days to see if there are any rolling stock values that could indicate when to buy or sell and pin point are threshold values and possibly work this into an automated program later with continuous uploads of these stocks in monitoring our portfolio of stock.
```{r}
Close17_dow <- Close17_dow[with(Close17_dow, order(DOW_down_median, Date)),]

Laap <- subset(Close17_dow, Close17_dow$DOW_down_median=='AAP')
Laddyy <- subset(Close17_dow, Close17_dow$DOW_down_median=='ADDYY')
Lamzn <- subset(Close17_dow, Close17_dow$DOW_down_median=='AMZN')
Lcost <- subset(Close17_dow, Close17_dow$DOW_down_median=='COST')
Ldltr <- subset(Close17_dow, Close17_dow$DOW_down_median=='DLTR')
Lffin <- subset(Close17_dow, Close17_dow$DOW_down_median=='FFIN')
Lgoog <- subset(Close17_dow, Close17_dow$DOW_down_median=='GOOG')
Lhd <- subset(Close17_dow, Close17_dow$DOW_down_median=='HD')
Ljnj <- subset(Close17_dow, Close17_dow$DOW_down_median=='JNJ')
Lnflx <- subset(Close17_dow, Close17_dow$DOW_down_median=='NFLX')
Lnke <- subset(Close17_dow, Close17_dow$DOW_down_median=='NKE')
Lpcg <- subset(Close17_dow, Close17_dow$DOW_down_median=='PCG')
Lrost <- subset(Close17_dow, Close17_dow$DOW_down_median=='ROST')
Lteva <- subset(Close17_dow, Close17_dow$DOW_down_median=='TEVA')
Ltjx <- subset(Close17_dow, Close17_dow$DOW_down_median=='TJX')
Lwmt <- subset(Close17_dow, Close17_dow$DOW_down_median=='WMT')
Lxom <- subset(Close17_dow, Close17_dow$DOW_down_median=='XOM')

aapL7 <- lag(Laap$stockValue,7)
addyyL7 <- lag(Laddyy$stockValue,7)
amznL7 <- lag(Lamzn$stockValue,7)
costL7 <- lag(Lcost$stockValue,7)
dltrL7 <- lag(Ldltr$stockValue,7)
ffinL7 <- lag(Lffin$stockValue,7)
googL7 <- lag(Lgoog$stockValue,7)
hdL7 <- lag(Lhd$stockValue,7)
jnjL7 <- lag(Ljnj$stockValue,7)
nflxL7 <- lag(Lnflx$stockValue,7)
nkeL7 <- lag(Lnke$stockValue,7)
pcgL7 <- lag(Lpcg$stockValue,7)
rostL7 <- lag(Lrost$stockValue,7)
tevaL7 <- lag(Lteva$stockValue,7)
tjxL7 <- lag(Ltjx$stockValue,7)
wmtL7 <- lag(Lwmt$stockValue,7)
xomL7 <- lag(Lxom$stockValue,7)

Close17_dow$lag7 <- c(aapL7,addyyL7,amznL7,costL7,dltrL7,ffinL7,googL7,
                                  hdL7,jnjL7,nflxL7,nkeL7,pcgL7,rostL7,tevaL7,
                                  tjxL7,wmtL7,xomL7)

aapL30 <- lag(Laap$stockValue,30)
addyyL30 <- lag(Laddyy$stockValue,30)
amznL30 <- lag(Lamzn$stockValue,30)
costL30 <- lag(Lcost$stockValue,30)
dltrL30 <- lag(Ldltr$stockValue,30)
ffinL30 <- lag(Lffin$stockValue,30)
googL30 <- lag(Lgoog$stockValue,30)
hdL30 <- lag(Lhd$stockValue,30)
jnjL30 <- lag(Ljnj$stockValue,30)
nflxL30 <- lag(Lnflx$stockValue,30)
nkeL30 <- lag(Lnke$stockValue,30)
pcgL30 <- lag(Lpcg$stockValue,30)
rostL30 <- lag(Lrost$stockValue,30)
tevaL30 <- lag(Lteva$stockValue,30)
tjxL30 <- lag(Ltjx$stockValue,30)
wmtL30 <- lag(Lwmt$stockValue,30)
xomL30 <- lag(Lxom$stockValue,30)

Close17_dow$lag30 <- c(aapL30,addyyL30,amznL30,costL30,dltrL30,ffinL30,googL30,
                                  hdL30,jnjL30,nflxL30,nkeL30,pcgL30,rostL30,tevaL30,
                                  tjxL30,wmtL30,xomL30)


aapL60 <- lag(Laap$stockValue,60)
addyyL60 <- lag(Laddyy$stockValue,60)
amznL60 <- lag(Lamzn$stockValue,60)
costL60 <- lag(Lcost$stockValue,60)
dltrL60 <- lag(Ldltr$stockValue,60)
ffinL60 <- lag(Lffin$stockValue,60)
googL60 <- lag(Lgoog$stockValue,60)
hdL60 <- lag(Lhd$stockValue,60)
jnjL60 <- lag(Ljnj$stockValue,60)
nflxL60 <- lag(Lnflx$stockValue,60)
nkeL60 <- lag(Lnke$stockValue,60)
pcgL60 <- lag(Lpcg$stockValue,60)
rostL60 <- lag(Lrost$stockValue,60)
tevaL60 <- lag(Lteva$stockValue,60)
tjxL60 <- lag(Ltjx$stockValue,60)
wmtL60 <- lag(Lwmt$stockValue,60)
xomL60 <- lag(Lxom$stockValue,60)

Close17_dow$lag60 <- c(aapL60,addyyL60,amznL60,costL60,dltrL60,ffinL60,googL60,
                                  hdL60,jnjL60,nflxL60,nkeL60,pcgL60,rostL60,tevaL60,
                                  tjxL60,wmtL60,xomL60)

aapL90 <- lag(Laap$stockValue,90)
addyyL90 <- lag(Laddyy$stockValue,90)
amznL90 <- lag(Lamzn$stockValue,90)
costL90 <- lag(Lcost$stockValue,90)
dltrL90 <- lag(Ldltr$stockValue,90)
ffinL90 <- lag(Lffin$stockValue,90)
googL90 <- lag(Lgoog$stockValue,90)
hdL90 <- lag(Lhd$stockValue,90)
jnjL90 <- lag(Ljnj$stockValue,90)
nflxL90 <- lag(Lnflx$stockValue,90)
nkeL90 <- lag(Lnke$stockValue,90)
pcgL90 <- lag(Lpcg$stockValue,90)
rostL90 <- lag(Lrost$stockValue,90)
tevaL90 <- lag(Lteva$stockValue,90)
tjxL90 <- lag(Ltjx$stockValue,90)
wmtL90 <- lag(Lwmt$stockValue,90)
xomL90 <- lag(Lxom$stockValue,90)

Close17_dow$lag90 <- c(aapL90,addyyL90,amznL90,costL90,dltrL90,ffinL90,googL90,
                                  hdL90,jnjL90,nflxL90,nkeL90,pcgL90,rostL90,tevaL90,
                                  tjxL90,wmtL90,xomL90)

aapL120 <- lag(Laap$stockValue,120)
addyyL120 <- lag(Laddyy$stockValue,120)
amznL120 <- lag(Lamzn$stockValue,120)
costL120 <- lag(Lcost$stockValue,120)
dltrL120 <- lag(Ldltr$stockValue,120)
ffinL120 <- lag(Lffin$stockValue,120)
googL120 <- lag(Lgoog$stockValue,120)
hdL120 <- lag(Lhd$stockValue,120)
jnjL120 <- lag(Ljnj$stockValue,120)
nflxL120 <- lag(Lnflx$stockValue,120)
nkeL120 <- lag(Lnke$stockValue,120)
pcgL120 <- lag(Lpcg$stockValue,120)
rostL120 <- lag(Lrost$stockValue,120)
tevaL120 <- lag(Lteva$stockValue,120)
tjxL120 <- lag(Ltjx$stockValue,120)
wmtL120 <- lag(Lwmt$stockValue,120)
xomL120 <- lag(Lxom$stockValue,120)

Close17_dow$lag120 <- c(aapL120,addyyL120,amznL120,costL120,dltrL120,ffinL120,googL120,
                                  hdL120,jnjL120,nflxL120,nkeL120,pcgL120,rostL120,tevaL120,
                                  tjxL120,wmtL120,xomL120)

aapL150 <- lag(Laap$stockValue,150)
addyyL150 <- lag(Laddyy$stockValue,150)
amznL150 <- lag(Lamzn$stockValue,150)
costL150 <- lag(Lcost$stockValue,150)
dltrL150 <- lag(Ldltr$stockValue,150)
ffinL150 <- lag(Lffin$stockValue,150)
googL150 <- lag(Lgoog$stockValue,150)
hdL150 <- lag(Lhd$stockValue,150)
jnjL150 <- lag(Ljnj$stockValue,150)
nflxL150 <- lag(Lnflx$stockValue,150)
nkeL150 <- lag(Lnke$stockValue,150)
pcgL150 <- lag(Lpcg$stockValue,150)
rostL150 <- lag(Lrost$stockValue,150)
tevaL150 <- lag(Lteva$stockValue,150)
tjxL150 <- lag(Ltjx$stockValue,150)
wmtL150 <- lag(Lwmt$stockValue,150)
xomL150 <- lag(Lxom$stockValue,150)

Close17_dow$lag150 <- c(aapL150,addyyL150,amznL150,costL150,dltrL150,ffinL150,googL150,
                                  hdL150,jnjL150,nflxL150,nkeL150,pcgL150,rostL150,tevaL150,
                                  tjxL150,wmtL150,xomL150)

aapL180 <- lag(Laap$stockValue,180)
addyyL180 <- lag(Laddyy$stockValue,180)
amznL180 <- lag(Lamzn$stockValue,180)
costL180 <- lag(Lcost$stockValue,180)
dltrL180 <- lag(Ldltr$stockValue,180)
ffinL180 <- lag(Lffin$stockValue,180)
googL180 <- lag(Lgoog$stockValue,180)
hdL180 <- lag(Lhd$stockValue,180)
jnjL180 <- lag(Ljnj$stockValue,180)
nflxL180 <- lag(Lnflx$stockValue,180)
nkeL180 <- lag(Lnke$stockValue,180)
pcgL180 <- lag(Lpcg$stockValue,180)
rostL180 <- lag(Lrost$stockValue,180)
tevaL180 <- lag(Lteva$stockValue,180)
tjxL180 <- lag(Ltjx$stockValue,180)
wmtL180 <- lag(Lwmt$stockValue,180)
xomL180 <- lag(Lxom$stockValue,180)

Close17_dow$lag180 <- c(aapL180,addyyL180,amznL180,costL180,dltrL180,ffinL180,googL180,
                                  hdL180,jnjL180,nflxL180,nkeL180,pcgL180,rostL180,tevaL180,
                                  tjxL180,wmtL180,xomL180)
```

Save this new table by writing it to csv file. Then we will see how many times each stock is lower than 7,30,60,90,120,150, and 180 days prior in stock value prices for each stock. See if we can use this to automate a data set that selects the stock as good or bad to buy, or good or bad to buy/sell. We could also use this information to create a machine learning data set that will use this information for those stocks that are good/bad at certain points in time to predict what its price will be or if it will return a profit. We already know four of these stocks didn't return a profit, but they are in this portfolio of 17 stocks whose median values were positive when the DOW was decreasing and unemployment was increasing. The other 13 stocks returned a profit, and some substantially such as Netflix with 100 fold increased value, and Amazon with 55 fold increased value. 
```{r}
write.csv(Close17_dow, 'Close17_dow_lags.csv', row.names=FALSE)
```

```{r}
head(Close17_dow,10)
```

```{r}
tail(Close17_dow,10)
```


Now create the ratios of current day's stock value to the lag day stock value. This will allow us to see how these stocks compare to previous days, and get median and average fold change values or ratios. 
```{r}
Close17_dow$today2lag7 <- Close17_dow$lag7/Close17_dow$stockValue
Close17_dow$today2lag30 <- Close17_dow$lag30/Close17_dow$stockValue
Close17_dow$today2lag60 <- Close17_dow$lag60/Close17_dow$stockValue
Close17_dow$today2lag90 <- Close17_dow$lag90/Close17_dow$stockValue
Close17_dow$today2lag120 <- Close17_dow$lag120/Close17_dow$stockValue
Close17_dow$today2lag150 <- Close17_dow$lag150/Close17_dow$stockValue
Close17_dow$today2lag180 <- Close17_dow$lag180/Close17_dow$stockValue

```


Group by the stock names in this table and add a median value for each lag value.
```{r}
median17today2lag7 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag7), median, na.rm=T)
median17today2lag30 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag30), median, na.rm=T)
median17today2lag60 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag60), median, na.rm=T)
median17today2lag90 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag90), median, na.rm=T)
median17today2lag120 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag120), median, na.rm=T)
median17today2lag150 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag150), median, na.rm=T)
median17today2lag180 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag180), median, na.rm=T)

mediantoday2lags <- cbind(median17today2lag7, median17today2lag30[2], median17today2lag60[2], median17today2lag90[2],
                    median17today2lag120[2], median17today2lag150[2], median17today2lag180[2])
colnames(mediantoday2lags)[2:8] <- paste('median',colnames(mediantoday2lags)[2:8], sep='')
Close17_dow1 <- merge(Close17_dow, mediantoday2lags, by.x='DOW_down_median', by.y='DOW_down_median')
```


Group by the stock name and now add a mean value. This will be to gather our threshold values to possibly indicate when its good to buy or sell. We will compare this later to the true outcome of each stock.
```{r}
meantoday2lag7 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag7),mean, na.rm=T)
meantoday2lag30 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag30),mean, na.rm=T)
meantoday2lag60 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag60),mean, na.rm=T)
meantoday2lag90 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag90),mean, na.rm=T)
meantoday2lag120 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag120),mean, na.rm=T)
meantoday2lag150 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag150),mean, na.rm=T)
meantoday2lag180 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag180),mean, na.rm=T)

meantoday2lags <- cbind(meantoday2lag7, meantoday2lag30[2], meantoday2lag60[2], meantoday2lag90[2],
                    meantoday2lag120[2], meantoday2lag150[2], meantoday2lag180[2])
colnames(meantoday2lags)[2:8] <- paste('mean',colnames(meantoday2lags)[2:8], sep='')
Close17_dow2 <- merge(Close17_dow1, meantoday2lags, by.x='DOW_down_median', by.y='DOW_down_median')


```

We should also get the min to know our local minimas in each today2lag.
```{r}
minimumtoday2lag7 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag7),min, na.rm=T)
minimumtoday2lag30 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag30),min, na.rm=T)
minimumtoday2lag60 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag60),min, na.rm=T)
minimumtoday2lag90 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag90),min, na.rm=T)
minimumtoday2lag120 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag120),min, na.rm=T)
minimumtoday2lag150 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag150),min, na.rm=T)
minimumtoday2lag180 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag180),min, na.rm=T)

minimumtoday2lags <- cbind(minimumtoday2lag7, minimumtoday2lag30[2], minimumtoday2lag60[2], minimumtoday2lag90[2],
                    minimumtoday2lag120[2], minimumtoday2lag150[2], minimumtoday2lag180[2])
colnames(minimumtoday2lags)[2:8] <- paste('minimum',colnames(minimumtoday2lags)[2:8], sep='')
Close17_dow3 <- merge(Close17_dow2, minimumtoday2lags, by.x='DOW_down_median', by.y='DOW_down_median')


```


Lets also add our local maximas by getting the max values for each of these today2lags.
```{r}
maximumtoday2lag7 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag7),max, na.rm=T)
maximumtoday2lag30 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag30),max, na.rm=T)
maximumtoday2lag60 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag60),max, na.rm=T)
maximumtoday2lag90 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag90),max, na.rm=T)
maximumtoday2lag120 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag120),max, na.rm=T)
maximumtoday2lag150 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag150),max, na.rm=T)
maximumtoday2lag180 <- Close17_dow %>% group_by(DOW_down_median) %>%
  summarise_at(vars(today2lag180),max, na.rm=T)

maximumtoday2lags <- cbind(maximumtoday2lag7, maximumtoday2lag30[2], maximumtoday2lag60[2], maximumtoday2lag90[2],
                    maximumtoday2lag120[2], maximumtoday2lag150[2], maximumtoday2lag180[2])
colnames(maximumtoday2lags)[2:8] <- paste('maximum',colnames(maximumtoday2lags)[2:8], sep='')
Close17_dow4 <- merge(Close17_dow3, maximumtoday2lags, by.x='DOW_down_median', by.y='DOW_down_median')


```


Write to file
```{r}
write.csv(Close17_dow4, 'Close17_dow4_lagStats.csv', row.names=FALSE)
```

Smaller file of the above, you can rbind() the two together, after importing them if needed.
```{r}
Close17_dow4_a <- Close17_dow4[1:28500,]
Close17_dow4_b <- Close17_dow4[28501:56151,]
write.csv(Close17_dow4_a, 'Close17_dow4_lagStats_parta.csv', row.names=TRUE)
write.csv(Close17_dow4_b, 'Close17_dow4_lagStats_partb.csv', row.names=TRUE)
```

The fields for the median and mean ratios of todays value to the value 7,30,60,90,120,150, and 180 days prior give some useful information. The minimum and maximum fields give the minimum and maximum ratio values for each group and could also provide some useful information. 

Lets get the median values of the 17 stock in terms of each median lag and mean lag ratio. Then compare. But lets get a summary of those fields first to see the quantiles, that could help us decide which stocks to categorize based on its behavior in time.
```{r}
summary(Close17_dow4[22:35])

```

Lets recall which stocks were not returning profits and those that were. There were three stocks that didn't return profits(XOM, TEVA, and PCG), and 14 that did. But only those three and one other stock didn't beat the DOW (JNJ). The table with this information is dROI17.
```{r}
dROI17
```


Lets get the median value of the stock_ROI from the dROI17 table.
```{r}
medianStockROI <- median(dROI17$stock_ROI)
medianStockROI

listROI_middle <- dROI17[order(dROI17$stock_ROI)[7:11],]
listROI_middle$DOW_down_median
```


The above shows us the median value of the return on investment on these 17 stocks is 6.02 or 600% from 2007-2020. The stocks in the middle of this list closest to the median value are the two before the middle and after the middle: FFIN, HD, COST, ADDYY, and GOOG.

```{r}
listROI_middle
```

Lets make count variables of these stock and get the values and counts for each time the stock went above or below its price 7, 30, 60, 90, 120, 150, and 180 days prior, and the same for the counts each stock was above those prices. Lets just use the Close17_dow, instead of the added median, mean, min, and max lag value ratios.
```{r}
FFIN <- subset(Close17_dow, Close17_dow$DOW_down_median=='FFIN')

ffin7 <- ifelse(FFIN$today2lag7>1, 1,0)
ffin30 <- ifelse(FFIN$today2lag30>1,1,0)
ffin60 <- ifelse(FFIN$today2lag60>1,1,0)
ffin90 <- ifelse(FFIN$today2lag90>1,1,0)
ffin120 <- ifelse(FFIN$today2lag120>1,1,0)
ffin150 <- ifelse(FFIN$today2lag150>1,1,0)
ffin180 <- ifelse(FFIN$today2lag180>1,1,0)

neg7 <- sum(ffin7==0, na.rm=T)
pos7 <- sum(ffin7==1, na.rm=T)

neg30 <- sum(ffin30==0, na.rm=T)
pos30 <- sum(ffin30==1, na.rm=T)

neg60 <- sum(ffin60==0, na.rm=T)
pos60 <- sum(ffin60==1, na.rm=T)

neg90 <- sum(ffin90==0, na.rm=T)
pos90 <- sum(ffin90==1, na.rm=T)

neg120 <- sum(ffin120==0, na.rm=T)
pos120 <- sum(ffin120==1, na.rm=T)

neg150 <- sum(ffin150==0, na.rm=T)
pos150 <- sum(ffin150==1, na.rm=T)

neg180 <- sum(ffin180==0, na.rm=T)
pos180 <- sum(ffin180==1, na.rm=T)

ffin_counts0 <- as.data.frame(c(neg7,neg30,neg60,neg90,neg120,neg150,neg180))
ffin_counts1  <- as.data.frame(c(pos7,pos30,pos60,pos90,pos120,pos150,pos180))
ffin_counts <- cbind(ffin_counts0, ffin_counts1)
row.names(ffin_counts) <- c('lag7','lag30','lag60','lag90','lag120','lag150','lag180')
colnames(ffin_counts) <- c('sum_neg_lags','sum_pos_lags')

ffin_counts
```

From the above chart on the number of days the current value was lower than 7, 30, 60, 90, 120, 150, or 180 days prior to todays's stock value, there were more in each lag than in those days the stocks was higher. There are the fewest number of days the stock increases from 180 days prior's stock value for FFIN stock shown above. This means you have more days to buy low and fewer to sell high. 

We should add a cumulative field or make a cumulative sum variable for each of these seven groups of lags in stock value. This way we can know how many cumulative days there are for each positive or negative value. Are there more frequent days that the stock stays lower in value to its lag price before increasing and how many days does the stock increase before starting to decrease.


```{r}
length(ffin7)

#rm nas or all nas as output from the today2lag7 stock ratio values
ffin7_a <- ffin7[-c(1:7)]

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for ffin7 <- <- ifelse(FFIN$today2lag7>1, 1,0)
ffin7_ab <- cumsum(ffin7_a)

ffin7_abc <- as.data.frame(as.factor(ffin7_ab))
colnames(ffin7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countFFIN <- ffin7_abc %>% group_by(cSum) %>% count(n=n())
countFFIN <- as.data.frame(countFFIN)
countFFIN <- countFFIN[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countFFIN$decr_Days <- countFFIN$n-1
countFFIN <- countFFIN[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countFFIN2 <- subset(countFFIN, countFFIN$decr_Days>0)
summary(countFFIN2$decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
decr_Days_grouped <- countFFIN2 %>% group_by(decr_Days) %>% count(n=n())
decr_Days_grouped <- decr_Days_grouped[,-3]
```


The above table countFFIN2 gives the number of days in a row the stock value decreased starting at the cSum variable value. 

The decr_Days_grouped table shows the number of days in a row the stock decreased from 2007-2020, and how many times the stock decreased that many days in a row.
```{r}
decr_Days_grouped
```

From the above chart on the FFIN stock from 2007-2020, it decreased for one day before increasing, exactly 96 times, and it had 10 consecutive days of decreasing exactly 12 times. 
```{r}

median(decr_Days_grouped$decr_Days)
```
The median number of days it decreased consecutively was 12. And the chart above shows it did this exactly three times from 2007-2020. Meaning there were three intervals where this stock, FFIN, decreased for 12 days before increasing. This could be a feature for evaluating whether to buy the stock once, it has decreased for 12 days. We will test it later.



Now, it would be nice to wrap a way around getting the number of consecutive days the FFIN stock value of each instance compared to the value seven days prior increased. So that we could compare number of days and sets of increasing days to that of the decreasing days. We should be able to do this by changing the original variable that assigned 1 to increasing and instead assigned 1 to decreasing to calculate the days increasing with the same method we used above.
```{r}

#assign a 1 to decreasing values
ffin7_b <- ifelse(FFIN$today2lag7>1, 0,1)

#rm NAs
ffin7_b1 <- ffin7_b[-c(1:7)] 

#counts the 
ffin7_b2 <- cumsum(ffin7_b1)

ffin7_b3 <- as.data.frame(as.factor(ffin7_b2))
colnames(ffin7_b3) <- 'cSum'

countFFIN1 <- ffin7_b3 %>% group_by(cSum) %>% count(n=n())
countFFIN1 <- as.data.frame(countFFIN1)
countFFIN1 <- countFFIN1[,-3]

countFFIN1$incr_Days <- countFFIN1$n-1
countFFIN1 <- countFFIN1[,-2]

countFFIN3 <- subset(countFFIN1, countFFIN1$incr_Days>0)
summary(countFFIN3$incr_Days)

incr_Days_grouped <- countFFIN3 %>% group_by(incr_Days) %>% count(n=n())
incr_Days_grouped <- incr_Days_grouped[,-3]
```

There were 26 consecutive days that the stock compared to seven days prior increased, and the median number of consecutive days the stock increased was 3 days in a row. The number of groups or times in this times series from 2007-2020 for FFIN that the stock increased consecutively is shown next.
```{r}
incr_Days_grouped
```

The above chart shows that the stock had 21 sets of consecutive days it increased. FFIN had 10 consecutive days it increased compared to the value 7 days ago, and this happened ten times from 2007-2020. 


```{r}
median(incr_Days_grouped$incr_Days)
```
The median number of consecutive days the FFIN stock increased is 11 days, and from the previous chart we know this happened six times from 2007-2020.


We can now do this for the other time lags and see if we gain any information by manually making rules to decide a stock's predictability as selling, buying, short and long term returns on investment as profitable, not profitable, or break even. This is just for this stock FFIN, we have to examine the other stock from this table of fold change in today/lag7 stock value for HD, GOOG, ADDYY, and COST stocks. This will grab the useful features of the median return stocks in this portfolio, then we will use the same method on the lowest return stocks and then again on the highest return stock.

***
***


Eventually, we will answer:

- how many times did this stock increase compared to the last 7, 30, 60, 90, 120, 150, and 180 days?

- how many times did this stock decrease compared to the last 7, 30, 60, 90, 120, 150, and 180 days?

- what is the median stock value fold change of todays/lagN (where N is one of above values)?

- how many times was this stock below their median value for each lag, and above it?

- what threshold appears to be the absolute minimum or range of decrease or increase in fold change before the stock increases or decreases?

- how many times was it below the DOW in fold change by lag? Does the DOW being down or up seem to affect how many consecutive days this stock is up or down?

- was the DOW high or low when the stock had their max number of consecutive days increasing or decreasing for each lag? Does the DOW seem to impact the number of consecutive days of increase or decrease of the stock? 

- what was the [federal minimum](https://bebusinessed.com/history/history-of-minimum-wage/) wage of this time period? Does it affect the number of consecutive days the stock increases/decreases? This will be added later if available for our time period.Since 2009 the above link says the minimum wage has been 7.25 USD, although we know some states have higher minimum wages. It was 5.85 USD in 2007 and 6.55 USD in 2008

- was unemployment increasing or decreasing when the stock increased, decreased, or had more consecutive days of increasing or decreasing value compared to each lag?

- more questions as they develop.

***
***

Lets look again at our 17 stock that were in the best performing subset with return on investment in dollars filtered by those that had positive median daily change stock values when the DOW was down and unemployment higher than the last month. This was in our dROI17 table.
```{r}

listROI <- dROI17[order(dROI17$stock_ROI),]

listROI_low <- listROI[1:6,]
listROI_middle <- listROI[7:11,]
listROI_high <- listROI[12:17,]

listROI
```

The low median return on investment ratios of final/start values:
```{r}
listROI_low
```


The middle median return on investment ratios of final/start values that we only evaluated a seven day lag with for number of increasing and decreasing days in this time span of 2007-2020:
```{r}
listROI_middle
```

The high median return on investment ratios of final/start values:
```{r}
listROI_high
```

Now we can add to these tables the number of increasing and decreasing days in this life cycle for each stock by their median number of increasing and decreasing days by lag 7. Lets do this only for lag 7. Later we will do this for lags 30-180 for each stock, to fill in some of those questions we wanted answers to for predicting the return on a stock based on those feature characteristics for each stock. We will know the return on investment and use the remaining stock in our 52 total stocks to categorize the return as low if at least the value of our median ROI of 6.02 as a ratio of final/start values. The other stocks above that value will be high. This will give two classes to predict if the stock will be a low or high stock return buy. For now, lets massage the data enough to get this additional data, then we can wrestle with it into our machine learning data model. 

***

We need to now get the number of days that each of the other stock increased and decreased as a median value and for the 7 day lag.Lets make this table with default values set before adding each result as we get it for each stock. Lets also add the 3rd quantile to these stock for the top 75% of cumulative sums value in comparing lag 7 fold change of today's stock value to 7 days ago.
```{r}
dROI17_lag7 <- dROI17
dROI17_lag7$medn_cSum_decr_L7 <- 'median cSum down L7'
dROI17_lag7$Q3_cSum_decr_L7 <- '3rd Qntl cSum down L7'
dROI17_lag7$max_cSum_decr_L7 <- 'max cSum down L7'
dROI17_lag7$medn_cSum_incr_L7 <- 'median cSum up L7'
dROI17_lag7$Q3_cSum_incr_L7 <- '3rd Qntl cSun up L7'
dROI17_lag7$max_cSum_incr_L7 <- 'max cSum up L7'
```

Lets run the FFIN (First Financial Bankshares) stock again, save the variables, grep it from the last table dROI17_lag7, fill in with our values, and find and replace the stock name with the new stock moving forward.
```{r}
FFIN <- subset(Close17_dow, Close17_dow$DOW_down_median=='FFIN')

#assign a 1 to increasing values
ffin7 <- ifelse(FFIN$today2lag7>1, 1,0)

ffin7_a <- na.omit(ffin7)

ffin7_ab <- cumsum(ffin7_a)

ffin7_abc <- as.data.frame(as.factor(ffin7_ab))
colnames(ffin7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countFFIN <- ffin7_abc %>% group_by(cSum) %>% count(n=n())
countFFIN <- as.data.frame(countFFIN)
countFFIN <- countFFIN[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countFFIN$decr_Days <- countFFIN$n-1
countFFIN <- countFFIN[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countFFIN1 <- subset(countFFIN, countFFIN$decr_Days>0)
summary(countFFIN1$decr_Days)

mxffin_d <- max(countFFIN1$decr_Days)
mdnffin_d <- median(countFFIN1$decr_Days)
q3ffin_d <- as.numeric(as.character(summary(countFFIN1$decr_Days)["3rd Qu."]))
```

```{r}
#assign a 1 to decreasing values
ffin7_b <- ifelse(FFIN$today2lag7>1, 0,1)

#rm NAs
ffin7_b1 <- na.omit(ffin7_b) 

#counts the 
ffin7_b2 <- cumsum(ffin7_b1)

ffin7_b3 <- as.data.frame(as.factor(ffin7_b2))
colnames(ffin7_b3) <- 'cSum'

countFFIN2 <- ffin7_b3 %>% group_by(cSum) %>% count(n=n())
countFFIN2 <- as.data.frame(countFFIN2)
countFFIN2 <- countFFIN2[,-3]

countFFIN2$incr_Days <- countFFIN2$n-1
countFFIN2 <- countFFIN2[,-2]

countFFIN3 <- subset(countFFIN2, countFFIN2$incr_Days>0)
summary(countFFIN3$incr_Days)

mxffin_i <- max(countFFIN3$incr_Days)
mdnffin_i <- median(countFFIN3$incr_Days)
q3ffin_i <- as.numeric(as.character(summary(countFFIN3$incr_Days)["3rd Qu."]))


```

Add these statistics to their respective stock instance in the dROI17_lag7 table.
```{r}
ffin_g <- grep('FFIN',dROI17_lag7$DOW_down_median)

dROI17_lag7[ffin_g,8:13] <- c(mdnffin_d,q3ffin_d,mxffin_d,mdnffin_i,q3ffin_i,mxffin_i)

```


GOOG (Google) stats:
```{r}
GOOG <- subset(Close17_dow, Close17_dow$DOW_down_median=='GOOG')

#assign a 1 to increasing values
goog7<- ifelse(GOOG$today2lag7>1, 1,0)

goog7_a <- na.omit(goog7)

goog7_ab <- cumsum(goog7_a)

goog7_abc <- as.data.frame(as.factor(goog7_ab))
colnames(goog7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countGOOG <- goog7_abc %>% group_by(cSum) %>% count(n=n())
countGOOG <- as.data.frame(countGOOG)
countGOOG <- countGOOG[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countGOOG$decr_Days <- countGOOG$n-1
countGOOG <- countGOOG[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countGOOG1 <- subset(countGOOG, countGOOG$decr_Days>0)
print('Decreasing Consecutive Days');summary(countGOOG1$decr_Days)
print('*****************************************************************')

mxgoog_d <- max(countGOOG1$decr_Days)
mdngoog_d <- median(countGOOG1$decr_Days)
q3goog_d <- as.numeric(as.character(summary(countGOOG1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
goog7_b <- ifelse(GOOG$today2lag7>1, 0,1)

goog7_b1 <- na.omit(goog7_b)

#counts the 
goog7_b2 <- cumsum(goog7_b1)

goog7_b3 <- as.data.frame(as.factor(goog7_b2))
colnames(goog7_b3) <- 'cSum'

countGOOG2 <- goog7_b3 %>% group_by(cSum) %>% count(n=n())
countGOOG2 <- as.data.frame(countGOOG2)
countGOOG2 <- countGOOG2[,-3]

countGOOG2$incr_Days <- countGOOG2$n-1
countGOOG2 <- countGOOG2[,-2]

countGOOG3 <- subset(countGOOG2, countGOOG2$incr_Days>0)
print('Increasing Consecutive Days');summary(countGOOG3$incr_Days)

mxgoog_i <- max(countGOOG3$incr_Days)
mdngoog_i <- median(countGOOG3$incr_Days)
q3goog_i <- as.numeric(as.character(summary(countGOOG3$incr_Days)["3rd Qu."]))


goog_g <- grep('GOOG',dROI17_lag7$DOW_down_median)

dROI17_lag7[goog_g,8:13] <- c(mdngoog_d,q3goog_d,mxgoog_d,mdngoog_i,q3goog_i,mxgoog_i)

```

HD-Home Depot:
```{r}
HD <- subset(Close17_dow, Close17_dow$DOW_down_median=='HD')

#assign a 1 to increasing values
hd7<- ifelse(HD$today2lag7>1, 1,0)

hd7_a <- na.omit(hd7)

hd7_ab <- cumsum(hd7_a)

hd7_abc <- as.data.frame(as.factor(hd7_ab))
colnames(hd7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countHD <- hd7_abc %>% group_by(cSum) %>% count(n=n())
countHD <- as.data.frame(countHD)
countHD <- countHD[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countHD$decr_Days <- countHD$n-1
countHD <- countHD[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countHD1 <- subset(countHD, countHD$decr_Days>0)
print('Decreasing Consecutive Days');summary(countHD1$decr_Days)
print('*****************************************************************')

mxhd_d <- max(countHD1$decr_Days)
mdnhd_d <- median(countHD1$decr_Days)
q3hd_d <- as.numeric(as.character(summary(countHD1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
hd7_b <- ifelse(HD$today2lag7>1, 0,1)

hd7_b1 <- na.omit(hd7_b)

#counts the 
hd7_b2 <- cumsum(hd7_b1)

hd7_b3 <- as.data.frame(as.factor(hd7_b2))
colnames(hd7_b3) <- 'cSum'

countHD2 <- hd7_b3 %>% group_by(cSum) %>% count(n=n())
countHD2 <- as.data.frame(countHD2)
countHD2 <- countHD2[,-3]

countHD2$incr_Days <- countHD2$n-1
countHD2 <- countHD2[,-2]

countHD3 <- subset(countHD2, countHD2$incr_Days>0)
print('Increasing Consecutive Days');summary(countHD3$incr_Days)

mxhd_i <- max(countHD3$incr_Days)
mdnhd_i <- median(countHD3$incr_Days)
q3hd_i <- as.numeric(as.character(summary(countHD3$incr_Days)["3rd Qu."]))


hd_g <- grep('HD',dROI17_lag7$DOW_down_median)

dROI17_lag7[hd_g,8:13] <- c(mdnhd_d,q3hd_d,mxhd_d,mdnhd_i,q3hd_i,mxhd_i)

```

JNJ, Johnson & Johnson:
```{r}
JNJ <- subset(Close17_dow, Close17_dow$DOW_down_median=='JNJ')

#assign a 1 to increasing values
jnj7<- ifelse(JNJ$today2lag7>1, 1,0)

jnj7_a <- na.omit(jnj7)

jnj7_ab <- cumsum(jnj7_a)

jnj7_abc <- as.data.frame(as.factor(jnj7_ab))
colnames(jnj7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countJNJ <- jnj7_abc %>% group_by(cSum) %>% count(n=n())
countJNJ <- as.data.frame(countJNJ)
countJNJ <- countJNJ[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countJNJ$decr_Days <- countJNJ$n-1
countJNJ <- countJNJ[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countJNJ1 <- subset(countJNJ, countJNJ$decr_Days>0)
print('Decreasing Consecutive Days');summary(countJNJ1$decr_Days)
print('*****************************************************************')

mxjnj_d <- max(countJNJ1$decr_Days)
mdnjnj_d <- median(countJNJ1$decr_Days)
q3jnj_d <- as.numeric(as.character(summary(countJNJ1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
jnj7_b <- ifelse(JNJ$today2lag7>1, 0,1)

jnj7_b1 <- na.omit(jnj7_b)

#counts the 
jnj7_b2 <- cumsum(jnj7_b1)

jnj7_b3 <- as.data.frame(as.factor(jnj7_b2))
colnames(jnj7_b3) <- 'cSum'

countJNJ2 <- jnj7_b3 %>% group_by(cSum) %>% count(n=n())
countJNJ2 <- as.data.frame(countJNJ2)
countJNJ2 <- countJNJ2[,-3]

countJNJ2$incr_Days <- countJNJ2$n-1
countJNJ2 <- countJNJ2[,-2]

countJNJ3 <- subset(countJNJ2, countJNJ2$incr_Days>0)
print('Increasing Consecutive Days');summary(countJNJ3$incr_Days)

mxjnj_i <- max(countJNJ3$incr_Days)
mdnjnj_i <- median(countJNJ3$incr_Days)
q3jnj_i <- as.numeric(as.character(summary(countJNJ3$incr_Days)["3rd Qu."]))


jnj_g <- grep('JNJ',dROI17_lag7$DOW_down_median)

dROI17_lag7[jnj_g,8:13] <- c(mdnjnj_d,q3jnj_d,mxjnj_d,mdnjnj_i,q3jnj_i,mxjnj_i)

```

NFLX, Netflix stats:
```{r}
NFLX <- subset(Close17_dow, Close17_dow$DOW_down_median=='NFLX')

#assign a 1 to increasing values
nflx7<- ifelse(NFLX$today2lag7>1, 1,0)

nflx7_a <- na.omit(nflx7)

nflx7_ab <- cumsum(nflx7_a)

nflx7_abc <- as.data.frame(as.factor(nflx7_ab))
colnames(nflx7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countNFLX <- nflx7_abc %>% group_by(cSum) %>% count(n=n())
countNFLX <- as.data.frame(countNFLX)
countNFLX <- countNFLX[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countNFLX$decr_Days <- countNFLX$n-1
countNFLX <- countNFLX[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countNFLX1 <- subset(countNFLX, countNFLX$decr_Days>0)
print('Decreasing Consecutive Days');summary(countNFLX1$decr_Days)
print('*****************************************************************')

mxnflx_d <- max(countNFLX1$decr_Days)
mdnnflx_d <- median(countNFLX1$decr_Days)
q3nflx_d <- as.numeric(as.character(summary(countNFLX1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
nflx7_b <- ifelse(NFLX$today2lag7>1, 0,1)

nflx7_b1 <- na.omit(nflx7_b)

#counts the 
nflx7_b2 <- cumsum(nflx7_b1)

nflx7_b3 <- as.data.frame(as.factor(nflx7_b2))
colnames(nflx7_b3) <- 'cSum'

countNFLX2 <- nflx7_b3 %>% group_by(cSum) %>% count(n=n())
countNFLX2 <- as.data.frame(countNFLX2)
countNFLX2 <- countNFLX2[,-3]

countNFLX2$incr_Days <- countNFLX2$n-1
countNFLX2 <- countNFLX2[,-2]

countNFLX3 <- subset(countNFLX2, countNFLX2$incr_Days>0)
print('Increasing Consecutive Days');summary(countNFLX3$incr_Days)

mxnflx_i <- max(countNFLX3$incr_Days)
mdnnflx_i <- median(countNFLX3$incr_Days)
q3nflx_i <- as.numeric(as.character(summary(countNFLX3$incr_Days)["3rd Qu."]))


nflx_g <- grep('NFLX',dROI17_lag7$DOW_down_median)

dROI17_lag7[nflx_g,8:13] <- c(mdnnflx_d,q3nflx_d,mxnflx_d,mdnnflx_i,q3nflx_i,mxnflx_i)

```


NKE, Nike stats:
```{r}
NKE <- subset(Close17_dow, Close17_dow$DOW_down_median=='NKE')

#assign a 1 to increasing values
nke7<- ifelse(NKE$today2lag7>1, 1,0)

nke7_a <- na.omit(nke7)

nke7_ab <- cumsum(nke7_a)

nke7_abc <- as.data.frame(as.factor(nke7_ab))
colnames(nke7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countNKE <- nke7_abc %>% group_by(cSum) %>% count(n=n())
countNKE <- as.data.frame(countNKE)
countNKE <- countNKE[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countNKE$decr_Days <- countNKE$n-1
countNKE <- countNKE[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countNKE1 <- subset(countNKE, countNKE$decr_Days>0)
print('Decreasing Consecutive Days');summary(countNKE1$decr_Days)
print('*****************************************************************')

mxnke_d <- max(countNKE1$decr_Days)
mdnnke_d <- median(countNKE1$decr_Days)
q3nke_d <- as.numeric(as.character(summary(countNKE1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
nke7_b <- ifelse(NKE$today2lag7>1, 0,1)

nke7_b1 <- na.omit(nke7_b)

#counts the 
nke7_b2 <- cumsum(nke7_b1)

nke7_b3 <- as.data.frame(as.factor(nke7_b2))
colnames(nke7_b3) <- 'cSum'

countNKE2 <- nke7_b3 %>% group_by(cSum) %>% count(n=n())
countNKE2 <- as.data.frame(countNKE2)
countNKE2 <- countNKE2[,-3]

countNKE2$incr_Days <- countNKE2$n-1
countNKE2 <- countNKE2[,-2]

countNKE3 <- subset(countNKE2, countNKE2$incr_Days>0)
print('Increasing Consecutive Days');summary(countNKE3$incr_Days)

mxnke_i <- max(countNKE3$incr_Days)
mdnnke_i <- median(countNKE3$incr_Days)
q3nke_i <- as.numeric(as.character(summary(countNKE3$incr_Days)["3rd Qu."]))


nke_g <- grep('NKE',dROI17_lag7$DOW_down_median)

dROI17_lag7[nke_g,8:13] <- c(mdnnke_d,q3nke_d,mxnke_d,mdnnke_i,q3nke_i,mxnke_i)

```

PCG, Pacific Gas and Electric stats:
```{r}
PCG <- subset(Close17_dow, Close17_dow$DOW_down_median=='PCG')

#assign a 1 to increasing values
pcg7<- ifelse(PCG$today2lag7>1, 1,0)

pcg7_a <- na.omit(pcg7)

pcg7_ab <- cumsum(pcg7_a)

pcg7_abc <- as.data.frame(as.factor(pcg7_ab))
colnames(pcg7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countPCG <- pcg7_abc %>% group_by(cSum) %>% count(n=n())
countPCG <- as.data.frame(countPCG)
countPCG <- countPCG[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countPCG$decr_Days <- countPCG$n-1
countPCG <- countPCG[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countPCG1 <- subset(countPCG, countPCG$decr_Days>0)
print('Decreasing Consecutive Days');summary(countPCG1$decr_Days)
print('*****************************************************************')

mxpcg_d <- max(countPCG1$decr_Days)
mdnpcg_d <- median(countPCG1$decr_Days)
q3pcg_d <- as.numeric(as.character(summary(countPCG1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
pcg7_b <- ifelse(PCG$today2lag7>1, 0,1)

pcg7_b1 <- na.omit(pcg7_b)

#counts the 
pcg7_b2 <- cumsum(pcg7_b1)

pcg7_b3 <- as.data.frame(as.factor(pcg7_b2))
colnames(pcg7_b3) <- 'cSum'

countPCG2 <- pcg7_b3 %>% group_by(cSum) %>% count(n=n())
countPCG2 <- as.data.frame(countPCG2)
countPCG2 <- countPCG2[,-3]

countPCG2$incr_Days <- countPCG2$n-1
countPCG2 <- countPCG2[,-2]

countPCG3 <- subset(countPCG2, countPCG2$incr_Days>0)
print('Increasing Consecutive Days');summary(countPCG3$incr_Days)

mxpcg_i <- max(countPCG3$incr_Days)
mdnpcg_i <- median(countPCG3$incr_Days)
q3pcg_i <- as.numeric(as.character(summary(countPCG3$incr_Days)["3rd Qu."]))


pcg_g <- grep('PCG',dROI17_lag7$DOW_down_median)

dROI17_lag7[pcg_g,8:13] <- c(mdnpcg_d,q3pcg_d,mxpcg_d,mdnpcg_i,q3pcg_i,mxpcg_i)

```


ROST, Ross stores stats:
```{r}
ROST <- subset(Close17_dow, Close17_dow$DOW_down_median=='ROST')

#assign a 1 to increasing values
rost7<- ifelse(ROST$today2lag7>1, 1,0)

rost7_a <- na.omit(rost7)

rost7_ab <- cumsum(rost7_a)

rost7_abc <- as.data.frame(as.factor(rost7_ab))
colnames(rost7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countROST <- rost7_abc %>% group_by(cSum) %>% count(n=n())
countROST <- as.data.frame(countROST)
countROST <- countROST[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countROST$decr_Days <- countROST$n-1
countROST <- countROST[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countROST1 <- subset(countROST, countROST$decr_Days>0)
print('Decreasing Consecutive Days');summary(countROST1$decr_Days)
print('*****************************************************************')

mxrost_d <- max(countROST1$decr_Days)
mdnrost_d <- median(countROST1$decr_Days)
q3rost_d <- as.numeric(as.character(summary(countROST1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
rost7_b <- ifelse(ROST$today2lag7>1, 0,1)

rost7_b1 <- na.omit(rost7_b)

#counts the 
rost7_b2 <- cumsum(rost7_b1)

rost7_b3 <- as.data.frame(as.factor(rost7_b2))
colnames(rost7_b3) <- 'cSum'

countROST2 <- rost7_b3 %>% group_by(cSum) %>% count(n=n())
countROST2 <- as.data.frame(countROST2)
countROST2 <- countROST2[,-3]

countROST2$incr_Days <- countROST2$n-1
countROST2 <- countROST2[,-2]

countROST3 <- subset(countROST2, countROST2$incr_Days>0)
print('Increasing Consecutive Days');summary(countROST3$incr_Days)

mxrost_i <- max(countROST3$incr_Days)
mdnrost_i <- median(countROST3$incr_Days)
q3rost_i <- as.numeric(as.character(summary(countROST3$incr_Days)["3rd Qu."]))


rost_g <- grep('ROST',dROI17_lag7$DOW_down_median)

dROI17_lag7[rost_g,8:13] <- c(mdnrost_d,q3rost_d,mxrost_d,mdnrost_i,q3rost_i,mxrost_i)

```


TEVA, TEVA Pharmaceuticals stats:
```{r}
TEVA <- subset(Close17_dow, Close17_dow$DOW_down_median=='TEVA')

#assign a 1 to increasing values
teva7<- ifelse(TEVA$today2lag7>1, 1,0)

teva7_a <- na.omit(teva7)

teva7_ab <- cumsum(teva7_a)

teva7_abc <- as.data.frame(as.factor(teva7_ab))
colnames(teva7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countTEVA <- teva7_abc %>% group_by(cSum) %>% count(n=n())
countTEVA <- as.data.frame(countTEVA)
countTEVA <- countTEVA[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countTEVA$decr_Days <- countTEVA$n-1
countTEVA <- countTEVA[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countTEVA1 <- subset(countTEVA, countTEVA$decr_Days>0)
print('Decreasing Consecutive Days');summary(countTEVA1$decr_Days)
print('*****************************************************************')

mxteva_d <- max(countTEVA1$decr_Days)
mdnteva_d <- median(countTEVA1$decr_Days)
q3teva_d <- as.numeric(as.character(summary(countTEVA1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
teva7_b <- ifelse(TEVA$today2lag7>1, 0,1)

teva7_b1 <- na.omit(teva7_b)

#counts the 
teva7_b2 <- cumsum(teva7_b1)

teva7_b3 <- as.data.frame(as.factor(teva7_b2))
colnames(teva7_b3) <- 'cSum'

countTEVA2 <- teva7_b3 %>% group_by(cSum) %>% count(n=n())
countTEVA2 <- as.data.frame(countTEVA2)
countTEVA2 <- countTEVA2[,-3]

countTEVA2$incr_Days <- countTEVA2$n-1
countTEVA2 <- countTEVA2[,-2]

countTEVA3 <- subset(countTEVA2, countTEVA2$incr_Days>0)
print('Increasing Consecutive Days');summary(countTEVA3$incr_Days)

mxteva_i <- max(countTEVA3$incr_Days)
mdnteva_i <- median(countTEVA3$incr_Days)
q3teva_i <- as.numeric(as.character(summary(countTEVA3$incr_Days)["3rd Qu."]))


teva_g <- grep('TEVA',dROI17_lag7$DOW_down_median)

dROI17_lag7[teva_g,8:13] <- c(mdnteva_d,q3teva_d,mxteva_d,mdnteva_i,q3teva_i,mxteva_i)

```

TJX, TJ Maxx stores stats:
```{r}
TJX <- subset(Close17_dow, Close17_dow$DOW_down_median=='TJX')

#assign a 1 to increasing values
tjx7<- ifelse(TJX$today2lag7>1, 1,0)

tjx7_a <- na.omit(tjx7)

tjx7_ab <- cumsum(tjx7_a)

tjx7_abc <- as.data.frame(as.factor(tjx7_ab))
colnames(tjx7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countTJX <- tjx7_abc %>% group_by(cSum) %>% count(n=n())
countTJX <- as.data.frame(countTJX)
countTJX <- countTJX[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countTJX$decr_Days <- countTJX$n-1
countTJX <- countTJX[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countTJX1 <- subset(countTJX, countTJX$decr_Days>0)
print('Decreasing Consecutive Days');summary(countTJX1$decr_Days)
print('*****************************************************************')

mxtjx_d <- max(countTJX1$decr_Days)
mdntjx_d <- median(countTJX1$decr_Days)
q3tjx_d <- as.numeric(as.character(summary(countTJX1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
tjx7_b <- ifelse(TJX$today2lag7>1, 0,1)

tjx7_b1 <- na.omit(tjx7_b)

#counts the 
tjx7_b2 <- cumsum(tjx7_b1)

tjx7_b3 <- as.data.frame(as.factor(tjx7_b2))
colnames(tjx7_b3) <- 'cSum'

countTJX2 <- tjx7_b3 %>% group_by(cSum) %>% count(n=n())
countTJX2 <- as.data.frame(countTJX2)
countTJX2 <- countTJX2[,-3]

countTJX2$incr_Days <- countTJX2$n-1
countTJX2 <- countTJX2[,-2]

countTJX3 <- subset(countTJX2, countTJX2$incr_Days>0)
print('Increasing Consecutive Days');summary(countTJX3$incr_Days)

mxtjx_i <- max(countTJX3$incr_Days)
mdntjx_i <- median(countTJX3$incr_Days)
q3tjx_i <- as.numeric(as.character(summary(countTJX3$incr_Days)["3rd Qu."]))


tjx_g <- grep('TJX',dROI17_lag7$DOW_down_median)

dROI17_lag7[tjx_g,8:13] <- c(mdntjx_d,q3tjx_d,mxtjx_d,mdntjx_i,q3tjx_i,mxtjx_i)

```


WMT, Walmart Stores:
```{r}
WMT <- subset(Close17_dow, Close17_dow$DOW_down_median=='WMT')

#assign a 1 to increasing values
wmt7<- ifelse(WMT$today2lag7>1, 1,0)

wmt7_a <- na.omit(wmt7)

wmt7_ab <- cumsum(wmt7_a)

wmt7_abc <- as.data.frame(as.factor(wmt7_ab))
colnames(wmt7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countWMT <- wmt7_abc %>% group_by(cSum) %>% count(n=n())
countWMT <- as.data.frame(countWMT)
countWMT <- countWMT[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countWMT$decr_Days <- countWMT$n-1
countWMT <- countWMT[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countWMT1 <- subset(countWMT, countWMT$decr_Days>0)
print('Decreasing Consecutive Days');summary(countWMT1$decr_Days)
print('*****************************************************************')

mxwmt_d <- max(countWMT1$decr_Days)
mdnwmt_d <- median(countWMT1$decr_Days)
q3wmt_d <- as.numeric(as.character(summary(countWMT1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
wmt7_b <- ifelse(WMT$today2lag7>1, 0,1)

wmt7_b1 <- na.omit(wmt7_b)

#counts the 
wmt7_b2 <- cumsum(wmt7_b1)

wmt7_b3 <- as.data.frame(as.factor(wmt7_b2))
colnames(wmt7_b3) <- 'cSum'

countWMT2 <- wmt7_b3 %>% group_by(cSum) %>% count(n=n())
countWMT2 <- as.data.frame(countWMT2)
countWMT2 <- countWMT2[,-3]

countWMT2$incr_Days <- countWMT2$n-1
countWMT2 <- countWMT2[,-2]

countWMT3 <- subset(countWMT2, countWMT2$incr_Days>0)
print('Increasing Consecutive Days');summary(countWMT3$incr_Days)

mxwmt_i <- max(countWMT3$incr_Days)
mdnwmt_i <- median(countWMT3$incr_Days)
q3wmt_i <- as.numeric(as.character(summary(countWMT3$incr_Days)["3rd Qu."]))


wmt_g <- grep('WMT',dROI17_lag7$DOW_down_median)

dROI17_lag7[wmt_g,8:13] <- c(mdnwmt_d,q3wmt_d,mxwmt_d,mdnwmt_i,q3wmt_i,mxwmt_i)

```


XOM, Exxon Mobile gas:
```{r}
XOM <- subset(Close17_dow, Close17_dow$DOW_down_median=='XOM')

#assign a 1 to increasing values
xom7<- ifelse(XOM$today2lag7>1, 1,0)

xom7_a <- na.omit(xom7)

xom7_ab <- cumsum(xom7_a)

xom7_abc <- as.data.frame(as.factor(xom7_ab))
colnames(xom7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countXOM <- xom7_abc %>% group_by(cSum) %>% count(n=n())
countXOM <- as.data.frame(countXOM)
countXOM <- countXOM[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countXOM$decr_Days <- countXOM$n-1
countXOM <- countXOM[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countXOM1 <- subset(countXOM, countXOM$decr_Days>0)
print('Decreasing Consecutive Days');summary(countXOM1$decr_Days)
print('*****************************************************************')

mxxom_d <- max(countXOM1$decr_Days)
mdnxom_d <- median(countXOM1$decr_Days)
q3xom_d <- as.numeric(as.character(summary(countXOM1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
xom7_b <- ifelse(XOM$today2lag7>1, 0,1)

xom7_b1 <- na.omit(xom7_b)

#counts the 
xom7_b2 <- cumsum(xom7_b1)

xom7_b3 <- as.data.frame(as.factor(xom7_b2))
colnames(xom7_b3) <- 'cSum'

countXOM2 <- xom7_b3 %>% group_by(cSum) %>% count(n=n())
countXOM2 <- as.data.frame(countXOM2)
countXOM2 <- countXOM2[,-3]

countXOM2$incr_Days <- countXOM2$n-1
countXOM2 <- countXOM2[,-2]

countXOM3 <- subset(countXOM2, countXOM2$incr_Days>0)
print('Increasing Consecutive Days');summary(countXOM3$incr_Days)

mxxom_i <- max(countXOM3$incr_Days)
mdnxom_i <- median(countXOM3$incr_Days)
q3xom_i <- as.numeric(as.character(summary(countXOM3$incr_Days)["3rd Qu."]))


xom_g <- grep('XOM',dROI17_lag7$DOW_down_median)

dROI17_lag7[xom_g,8:13] <- c(mdnxom_d,q3xom_d,mxxom_d,mdnxom_i,q3xom_i,mxxom_i)

```



AAP, Advance Auto Parts:
```{r}
AAP <- subset(Close17_dow, Close17_dow$DOW_down_median=='AAP')

#assign a 1 to increasing values
aap7<- ifelse(AAP$today2lag7>1, 1,0)

aap7_a <- na.omit(aap7)

aap7_ab <- cumsum(aap7_a)

aap7_abc <- as.data.frame(as.factor(aap7_ab))
colnames(aap7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countAAP <- aap7_abc %>% group_by(cSum) %>% count(n=n())
countAAP <- as.data.frame(countAAP)
countAAP <- countAAP[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countAAP$decr_Days <- countAAP$n-1
countAAP <- countAAP[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countAAP1 <- subset(countAAP, countAAP$decr_Days>0)
print('Decreasing Consecutive Days');summary(countAAP1$decr_Days)
print('*****************************************************************')

mxaap_d <- max(countAAP1$decr_Days)
mdnaap_d <- median(countAAP1$decr_Days)
q3aap_d <- as.numeric(as.character(summary(countAAP1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
aap7_b <- ifelse(AAP$today2lag7>1, 0,1)

aap7_b1 <- na.omit(aap7_b)

#counts the 
aap7_b2 <- cumsum(aap7_b1)

aap7_b3 <- as.data.frame(as.factor(aap7_b2))
colnames(aap7_b3) <- 'cSum'

countAAP2 <- aap7_b3 %>% group_by(cSum) %>% count(n=n())
countAAP2 <- as.data.frame(countAAP2)
countAAP2 <- countAAP2[,-3]

countAAP2$incr_Days <- countAAP2$n-1
countAAP2 <- countAAP2[,-2]

countAAP3 <- subset(countAAP2, countAAP2$incr_Days>0)
print('Increasing Consecutive Days');summary(countAAP3$incr_Days)

mxaap_i <- max(countAAP3$incr_Days)
mdnaap_i <- median(countAAP3$incr_Days)
q3aap_i <- as.numeric(as.character(summary(countAAP3$incr_Days)["3rd Qu."]))


aap_g <- grep('AAP',dROI17_lag7$DOW_down_median)

dROI17_lag7[aap_g,8:13] <- c(mdnaap_d,q3aap_d,mxaap_d,mdnaap_i,q3aap_i,mxaap_i)

```


ADDYY, Adidas Sports Attire and shoes:
```{r}
ADDYY <- subset(Close17_dow, Close17_dow$DOW_down_median=='ADDYY')

#assign a 1 to increasing values
addyy7<- ifelse(ADDYY$today2lag7>1, 1,0)

addyy7_a <- na.omit(addyy7)

addyy7_ab <- cumsum(addyy7_a)

addyy7_abc <- as.data.frame(as.factor(addyy7_ab))
colnames(addyy7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countADDYY <- addyy7_abc %>% group_by(cSum) %>% count(n=n())
countADDYY <- as.data.frame(countADDYY)
countADDYY <- countADDYY[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countADDYY$decr_Days <- countADDYY$n-1
countADDYY <- countADDYY[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countADDYY1 <- subset(countADDYY, countADDYY$decr_Days>0)
print('Decreasing Consecutive Days');summary(countADDYY1$decr_Days)
print('*****************************************************************')

mxaddyy_d <- max(countADDYY1$decr_Days)
mdnaddyy_d <- median(countADDYY1$decr_Days)
q3addyy_d <- as.numeric(as.character(summary(countADDYY1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
addyy7_b <- ifelse(ADDYY$today2lag7>1, 0,1)

addyy7_b1 <- na.omit(addyy7_b)

#counts the 
addyy7_b2 <- cumsum(addyy7_b1)

addyy7_b3 <- as.data.frame(as.factor(addyy7_b2))
colnames(addyy7_b3) <- 'cSum'

countADDYY2 <- addyy7_b3 %>% group_by(cSum) %>% count(n=n())
countADDYY2 <- as.data.frame(countADDYY2)
countADDYY2 <- countADDYY2[,-3]

countADDYY2$incr_Days <- countADDYY2$n-1
countADDYY2 <- countADDYY2[,-2]

countADDYY3 <- subset(countADDYY2, countADDYY2$incr_Days>0)
print('Increasing Consecutive Days');summary(countADDYY3$incr_Days)

mxaddyy_i <- max(countADDYY3$incr_Days)
mdnaddyy_i <- median(countADDYY3$incr_Days)
q3addyy_i <- as.numeric(as.character(summary(countADDYY3$incr_Days)["3rd Qu."]))


addyy_g <- grep('ADDYY',dROI17_lag7$DOW_down_median)

dROI17_lag7[addyy_g,8:13] <- c(mdnaddyy_d,q3addyy_d,mxaddyy_d,mdnaddyy_i,q3addyy_i,mxaddyy_i)

```


AMZN, Amazon:
```{r}
AMZN <- subset(Close17_dow, Close17_dow$DOW_down_median=='AMZN')

#assign a 1 to increasing values
amzn7<- ifelse(AMZN$today2lag7>1, 1,0)

amzn7_a <- na.omit(amzn7)

amzn7_ab <- cumsum(amzn7_a)

amzn7_abc <- as.data.frame(as.factor(amzn7_ab))
colnames(amzn7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countAMZN <- amzn7_abc %>% group_by(cSum) %>% count(n=n())
countAMZN <- as.data.frame(countAMZN)
countAMZN <- countAMZN[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countAMZN$decr_Days <- countAMZN$n-1
countAMZN <- countAMZN[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countAMZN1 <- subset(countAMZN, countAMZN$decr_Days>0)
print('Decreasing Consecutive Days');summary(countAMZN1$decr_Days)
print('*****************************************************************')

mxamzn_d <- max(countAMZN1$decr_Days)
mdnamzn_d <- median(countAMZN1$decr_Days)
q3amzn_d <- as.numeric(as.character(summary(countAMZN1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
amzn7_b <- ifelse(AMZN$today2lag7>1, 0,1)

amzn7_b1 <- na.omit(amzn7_b)

#counts the 
amzn7_b2 <- cumsum(amzn7_b1)

amzn7_b3 <- as.data.frame(as.factor(amzn7_b2))
colnames(amzn7_b3) <- 'cSum'

countAMZN2 <- amzn7_b3 %>% group_by(cSum) %>% count(n=n())
countAMZN2 <- as.data.frame(countAMZN2)
countAMZN2 <- countAMZN2[,-3]

countAMZN2$incr_Days <- countAMZN2$n-1
countAMZN2 <- countAMZN2[,-2]

countAMZN3 <- subset(countAMZN2, countAMZN2$incr_Days>0)
print('Increasing Consecutive Days');summary(countAMZN3$incr_Days)

mxamzn_i <- max(countAMZN3$incr_Days)
mdnamzn_i <- median(countAMZN3$incr_Days)
q3amzn_i <- as.numeric(as.character(summary(countAMZN3$incr_Days)["3rd Qu."]))


amzn_g <- grep('AMZN',dROI17_lag7$DOW_down_median)

dROI17_lag7[amzn_g,8:13] <- c(mdnamzn_d,q3amzn_d,mxamzn_d,mdnamzn_i,q3amzn_i,mxamzn_i)

```


COST, Costco Stores:
```{r}
COST <- subset(Close17_dow, Close17_dow$DOW_down_median=='COST')

#assign a 1 to increasing values
cost7<- ifelse(COST$today2lag7>1, 1,0)

cost7_a <- na.omit(cost7)

cost7_ab <- cumsum(cost7_a)

cost7_abc <- as.data.frame(as.factor(cost7_ab))
colnames(cost7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countCOST <- cost7_abc %>% group_by(cSum) %>% count(n=n())
countCOST <- as.data.frame(countCOST)
countCOST <- countCOST[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countCOST$decr_Days <- countCOST$n-1
countCOST <- countCOST[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countCOST1 <- subset(countCOST, countCOST$decr_Days>0)
print('Decreasing Consecutive Days');summary(countCOST1$decr_Days)
print('*****************************************************************')

mxcost_d <- max(countCOST1$decr_Days)
mdncost_d <- median(countCOST1$decr_Days)
q3cost_d <- as.numeric(as.character(summary(countCOST1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
cost7_b <- ifelse(COST$today2lag7>1, 0,1)

cost7_b1 <- na.omit(cost7_b)

#counts the 
cost7_b2 <- cumsum(cost7_b1)

cost7_b3 <- as.data.frame(as.factor(cost7_b2))
colnames(cost7_b3) <- 'cSum'

countCOST2 <- cost7_b3 %>% group_by(cSum) %>% count(n=n())
countCOST2 <- as.data.frame(countCOST2)
countCOST2 <- countCOST2[,-3]

countCOST2$incr_Days <- countCOST2$n-1
countCOST2 <- countCOST2[,-2]

countCOST3 <- subset(countCOST2, countCOST2$incr_Days>0)
print('Increasing Consecutive Days');summary(countCOST3$incr_Days)

mxcost_i <- max(countCOST3$incr_Days)
mdncost_i <- median(countCOST3$incr_Days)
q3cost_i <- as.numeric(as.character(summary(countCOST3$incr_Days)["3rd Qu."]))


cost_g <- grep('COST',dROI17_lag7$DOW_down_median)

dROI17_lag7[cost_g,8:13] <- c(mdncost_d,q3cost_d,mxcost_d,mdncost_i,q3cost_i,mxcost_i)

```


DLTR, Dollar Tree Stores:
```{r}
DLTR <- subset(Close17_dow, Close17_dow$DOW_down_median=='DLTR')

#assign a 1 to increasing values
dltr7<- ifelse(DLTR$today2lag7>1, 1,0)

dltr7_a <- na.omit(dltr7)

dltr7_ab <- cumsum(dltr7_a)

dltr7_abc <- as.data.frame(as.factor(dltr7_ab))
colnames(dltr7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countDLTR <- dltr7_abc %>% group_by(cSum) %>% count(n=n())
countDLTR <- as.data.frame(countDLTR)
countDLTR <- countDLTR[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countDLTR$decr_Days <- countDLTR$n-1
countDLTR <- countDLTR[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countDLTR1 <- subset(countDLTR, countDLTR$decr_Days>0)
print('Decreasing Consecutive Days');summary(countDLTR1$decr_Days)
print('*****************************************************************')

mxdltr_d <- max(countDLTR1$decr_Days)
mdndltr_d <- median(countDLTR1$decr_Days)
q3dltr_d <- as.numeric(as.character(summary(countDLTR1$decr_Days)["3rd Qu."]))

#assign a 1 to decreasing values
dltr7_b <- ifelse(DLTR$today2lag7>1, 0,1)

dltr7_b1 <- na.omit(dltr7_b)

#counts the 
dltr7_b2 <- cumsum(dltr7_b1)

dltr7_b3 <- as.data.frame(as.factor(dltr7_b2))
colnames(dltr7_b3) <- 'cSum'

countDLTR2 <- dltr7_b3 %>% group_by(cSum) %>% count(n=n())
countDLTR2 <- as.data.frame(countDLTR2)
countDLTR2 <- countDLTR2[,-3]

countDLTR2$incr_Days <- countDLTR2$n-1
countDLTR2 <- countDLTR2[,-2]

countDLTR3 <- subset(countDLTR2, countDLTR2$incr_Days>0)
print('Increasing Consecutive Days');summary(countDLTR3$incr_Days)

mxdltr_i <- max(countDLTR3$incr_Days)
mdndltr_i <- median(countDLTR3$incr_Days)
q3dltr_i <- as.numeric(as.character(summary(countDLTR3$incr_Days)["3rd Qu."]))


dltr_g <- grep('DLTR',dROI17_lag7$DOW_down_median)

dROI17_lag7[dltr_g,8:13] <- c(mdndltr_d,q3dltr_d,mxdltr_d,mdndltr_i,q3dltr_i,mxdltr_i)

```

Now that we have our cumulative number of days in lag7 stock value prices that the stock decreases or increases in our best performing stock portfolio of 17 stocks that had positive median stock values when the DOW was down and unemployment up, lets add a field to classify whether the stock is low or high based on the Costco stock ROI of 6.02, which was the median stock ROI of this portfolio.
```{r}
dROI17_lag7$ROI_Low_High <- ifelse(dROI17_lag7$stock_ROI <= 6.02, 'Low', 'High')
dROI17_lag7
```

The table we extracted these stock is from the Close2 table.
```{r}
colnames(Close2)

```


There are 36 more stock in our entire portfolio of stocks with values from 2007-2020 that we could also get these feature characteristics for. But for now lets just add a field to the table we derived these 17 stock from by stock closing value, take the overall return on investment for each of the remaining 36 stocks, and add in the ROI class of 'Low' or 'High' to that table. Then separate into training and testing sets and use machine learning to predict the outcome of the stock being low or high in ROI ratio of start value to final value of the stock according to the initial and final prices of each stock in our time series.

Lets keep only the date field and all the stocks in our Close2 table.
```{r}
Close52 <- Close2[,-c(1,55:58,60:63)]

colnames(Close52) <- gsub('.Close','', colnames(Close52))
colnames(Close52) <- gsub('.PB', '', colnames(Close52))
colnames(Close52)
```

Make a mini table of start and final values to get our ROI for each stock.
```{r}
Close52_roi <- subset(Close52, Close52$Date=='2007-01-03' |
                        Close52$Date=='2020-02-14')
Close52_roi_t <- as.data.frame(t(Close52_roi[1:52]))
Close52_roi_t$stock_ROI_2007_2020 <- round(Close52_roi_t$`2020-02-14`/Close52_roi_t$`2007-01-03`,2)
Close52_roi_t$ROI_Low_High_2007_2020 <- ifelse(Close52_roi_t$stock_ROI_2007_2020 <= 6.02, 'Low', 'High')
Close52_roi_t$stockName <- as.factor(row.names(Close52_roi_t))
Close52_b <- Close52_roi_t[,-c(1:2)]
Close52_g <- gather(Close52, 'stockName','stockDayValue',1:52)
Close52_g$stockName <- as.factor(Close52_g$stockName)

Close52_r <- merge(Close52_g, Close52_b, by.x='stockName', by.y='stockName')
```


We now have a table of the stock from 2007-2020, with the outcome class on the stock based on its daily value in this time period as 'Low' or 'High' ratio of start to final stock value. This measure or threshold was selected by picking the median ROI ratio of the best portfolio of stocks that included 17 of the stocks in our set. That threshold was 6.02 as the ROI of Costco from 2007-2020. Lets put together our data and make two separate data tables for the portfolio of best performing stock in the dROI17_lag7 and the Close52_r data tables. We can subset the Close52_r table by date to see how well any given year of stock information can predict the stock ROI as being low or high.

Change the data types from char to numeric for the stat fields, as this wasn't noticed earlier, and is easier to do this now, then go back to 17 separate coding areas of this script by backtracking.
```{r}
dROI17_lag7$medn_cSum_decr_L7 <- as.numeric(dROI17_lag7$medn_cSum_decr_L7)
dROI17_lag7$Q3_cSum_decr_L7 <- as.numeric(dROI17_lag7$Q3_cSum_decr_L7)
dROI17_lag7$max_cSum_decr_L7 <- as.numeric(dROI17_lag7$max_cSum_decr_L7)
dROI17_lag7$medn_cSum_incr_L7 <- as.numeric(dROI17_lag7$medn_cSum_incr_L7)
dROI17_lag7$Q3_cSum_incr_L7 <- as.numeric(dROI17_lag7$Q3_cSum_incr_L7)
dROI17_lag7$max_cSum_incr_L7 <- as.numeric(dROI17_lag7$max_cSum_incr_L7)

dROI17_lag7$DOW_down_median <- as.factor(dROI17_lag7$DOW_down_median)
dROI17_lag7$ROI_Low_High <- as.factor(dROI17_lag7$ROI_Low_High)

```


This is a mixed data table of numeric and factor features. Lets remove the stockBeatsDow feature.
```{r}
dROI17_lag7_b <- dROI17_lag7[,-7]
dROI17_lag7_b
```


Lets make the row names of the dROI17_lag7_b table the DOW_down_median factor type feature, then remove that field from the table.
```{r, warning=FALSE}
names <- as.character(dROI17_lag7_b$DOW_down_median)
dROI17_lag7_c <- dROI17_lag7_b[,-1]
row.names(dROI17_lag7_c) <- names 

dROI17_lag7_d <- round(dROI17_lag7_c[1:11],2)
row.names(dROI17_lag7_d) <- names
ROI_17 <- cbind(dROI17_lag7_d, dROI17_lag7_c[12])
ROI_17
write.csv(ROI_17, 'ROI_17_ML.csv', row.names=TRUE)
```


We have the machine learning ready table from above for the 17 stocks belonging to the best portfolio of stocks. The other table of the low or high return values on table Close52_r wouldn't be much use to use machine learning on, since the name of the stock is already tied to the class, with the return on investment ratio. The individual stock lags, ratios of today's stock value to the lag value, and the additional stock statistics for cumulative days of increasing and decreasing counts as well as the median, max, and 3rd quantile of each of those cumulative days by lag period to get a bigger picture. This will take twice as many lines of code as already has been produced for these 17, with the 36 other stock in the portfolio of stocks with values between 2007-2020. 

***


Lets get started with testing out some machine learning on this small subset of stocks to see how well it can predict a high or low return on investment from 70% training on the remaining 30% testing set of these stocks as samples. We will keep all the variables even if they are redundant and make it easier for the algorithm to predict the class.

```{r}
set.seed(12356789)

inTrain <- createDataPartition(y=ROI_17$ROI_Low_High, p=0.7, list=FALSE)

trainingSet <- ROI_17[inTrain,]
testingSet <- ROI_17[-inTrain,]


```



```{r}
rfMod <- train(ROI_Low_High~., method='rf', data=(trainingSet), 
               trControl=trainControl(method='cv'), number=5)
plot(rfMod)


```




```{r}
predRF <- predict(rfMod, testingSet)

predDF <- data.frame(predRF, type=testingSet$ROI_Low_High)
predDF

sum <- sum(predRF==testingSet$ROI_Low_High) 
length <- length(testingSet$ROI_Low_High)
accuracy_rfMod <- (sum/length) 
accuracy_rfMod

```


```{r}
results <- c(round(accuracy_rfMod,2), round(100,2))
results <- as.factor(results)
results <- t(data.frame(results))

colnames(results) <- colnames(predDF)
Results <- rbind(predDF, results) 
Results

```


```{r}
knnMod <- train(ROI_Low_High ~ .,
                method='knn', preProcess=c('center','scale'),
                tuneLength=10, trControl=trainControl(method='cv'), data=trainingSet)
plot(knnMod)

```


```{r}
rpartMod <- train(ROI_Low_High ~ ., method='rpart', tuneLength=7, data=trainingSet) 

```

```{r, message=FALSE, warning=FALSE, error=FALSE}
glmMod <- train(ROI_Low_High ~ ., 
                method='glm', data=trainingSet) 
```


```{r}
predKNN <- predict(knnMod, testingSet)
predRPART <- predict(rpartMod, testingSet)
predGLM <- predict(glmMod, testingSet)

```


```{r}
length=length(testingSet$ROI_Low_High)

sumKNN <- sum(predKNN==testingSet$ROI_Low_High)
sumRPart <- sum(predRPART==testingSet$ROI_Low_High)
sumGLM <- sum(predGLM==testingSet$ROI_Low_High)

```

```{r}
accuracy_KNN <- sumKNN/length 
accuracy_RPART <- sumRPart/length 
accuracy_GLM <- sumGLM/length 

```


```{r}
predDF2 <- data.frame(predRF,predKNN,predRPART,predGLM, 
                      TYPE=testingSet$ROI_Low_High)
colnames(predDF2) <- c('RandomForest','KNN','Rpart','GLM','TrueValue')

results <- c(round(accuracy_rfMod,2),  
             round(accuracy_KNN,2), 
             round(accuracy_RPART,2),
             round(accuracy_GLM,2), 
             round(100,2))

results <- as.factor(results)
results <- t(data.frame(results))
colnames(results) <- c('RandomForest','KNN','Rpart','GLM','TrueValue')
Results <- rbind(predDF2, results) 
Results


```

The above algorithms of machine learning using the default settings didn't give very accurate predictions. There were only 13 samples to train on, and 4 to test on and the data fluctuates. There are just as many features as samples in the training set and more so in the testing set. What if we remove some of the features? Lets do this and remove the first five features.


```{r}
set.seed(12356789)

ROI_17b <- ROI_17[,-c(1:5)]
inTrain <- createDataPartition(y=ROI_17b$ROI_Low_High, p=0.7, list=FALSE)

trainingSet <- ROI_17b[inTrain,]
testingSet <- ROI_17b[-inTrain,]


```



```{r}
rfMod <- train(ROI_Low_High~., method='rf', data=(trainingSet), 
               trControl=trainControl(method='cv'), number=5)
plot(rfMod)


```




```{r}
predRF <- predict(rfMod, testingSet)

predDF <- data.frame(predRF, type=testingSet$ROI_Low_High)
predDF

sum <- sum(predRF==testingSet$ROI_Low_High) 
length <- length(testingSet$ROI_Low_High)
accuracy_rfMod <- (sum/length) 
accuracy_rfMod

```


```{r}
results <- c(round(accuracy_rfMod,2), round(100,2))
results <- as.factor(results)
results <- t(data.frame(results))

colnames(results) <- colnames(predDF)
Results <- rbind(predDF, results) 
Results

```


```{r}
knnMod <- train(ROI_Low_High ~ .,
                method='knn', preProcess=c('center','scale'),
                tuneLength=10, trControl=trainControl(method='cv'), data=trainingSet)
plot(knnMod)

```


```{r}
rpartMod <- train(ROI_Low_High ~ ., method='rpart', tuneLength=7, data=trainingSet) 

```

```{r, message=FALSE, warning=FALSE, error=FALSE}
glmMod <- train(ROI_Low_High ~ ., 
                method='glm', data=trainingSet) 
```


```{r}
predKNN <- predict(knnMod, testingSet)
predRPART <- predict(rpartMod, testingSet)
predGLM <- predict(glmMod, testingSet)

```


```{r}
length=length(testingSet$ROI_Low_High)

sumKNN <- sum(predKNN==testingSet$ROI_Low_High)
sumRPart <- sum(predRPART==testingSet$ROI_Low_High)
sumGLM <- sum(predGLM==testingSet$ROI_Low_High)

```

```{r}
accuracy_KNN <- sumKNN/length 
accuracy_RPART <- sumRPart/length 
accuracy_GLM <- sumGLM/length 

```


```{r}
predDF2 <- data.frame(predRF,predKNN,predRPART,predGLM, 
                      TYPE=testingSet$ROI_Low_High)
colnames(predDF2) <- c('RandomForest','KNN','Rpart','GLM','TrueValue')

results <- c(round(accuracy_rfMod,2),  
             round(accuracy_KNN,2), 
             round(accuracy_RPART,2),
             round(accuracy_GLM,2), 
             round(100,2))

results <- as.factor(results)
results <- t(data.frame(results))
colnames(results) <- c('RandomForest','KNN','Rpart','GLM','TrueValue')
Results <- rbind(predDF2, results) 
Results


```

The feature removal was better in accuracy than the original data. Based on the number of times the ratio of today's stock values by date to the value seven days ago as increasing, decreasing, the added statistics of max, median, and 3rd quantile all added more information and got rid of noise so that there was one model that scored 100% accuracy and the others only got half right. In the other set, with the average stock values, DOW ROI, and start and final values for the time span 2007-2020, there was one that scored 1/4 and the others got half right. In this case, the GLM or generalized linear model based on linear and logistic regression performed better than the others and got all predictions of the four samples right.

This could mean having these statistics is powerful in predicting the value of the stock as high or low, or that the GLM notices that there is information in the statistical lag information that was used to classify the stock as a high or low return, or both. 

These questions can be answered if making an app where a person asks what stock to predict, the app pulls the data from the internet, for the specified time. The app then gathers the seven day lag information of the stock, gets the fold change of the daily stock values of the stock to the seven day lag, counts the number of times the stock has cumulative days of increasing and decreasing, gets the median value of that range, compares the number of days the stock was increasing last, compared with the last few days ratios to indicate what the set of increase or decrease count is, then returns whether to buy or sell, based on whether the set of days is reaching the median value of days(or 3rd quartile and/or beyond the previous max cumulative days increasing/decreasing) that increase or decrease for a short run profit, figuratively. 

A way to see of Naive Bayes, a GLM model, algorithm to calculate the probabilities of the stock continuing to increase or decrease based on the previous days increase, possibly the day of the month, quarter of the year, and so on, that could return the best probability for continuing to decrease, or continuing to increase. The features would again have to be limited for the best results, but there could be algorithms for all of these questions inside a stock forecast app.

What remains is to add in the other 36 stock lag information and test this same series of machine learning default setting algorithms on that data to see if results improve. And do this for all the lag information of the 30-60-90-120-150-180 lags. Bunch more coding but the methods are above, with time consuming find and replace carefully done. 

To test how well this works for any given quarter year, month, year, etc., these same steps would have to be done to smaller subsets.
***


Lets start by making a list of those stocks we already have lag values for.
```{r}
colnames(Close52)
```

```{r}
row.names(dROI17_lag7_d)
```

The remaining stocks we need to add lagfields to, and then get the lag7 information for each stock as we did above on our machine learning data set of the 17 stocks in the best performing portfolio of stocks that had positive median daily value changes when the DOW was down and unemployment was up from the previous month.
```{r}
remaining <- colnames(Close52)[c(1:3,5,7:9,11:15,18:22,24:26,28:31,34,40,41,43:46,49:52)]
remaining

```


```{r}
#this is the list of stocks that we need, and we need to drop the 17 we already analyzed
Remaining <- as.data.frame(remaining)
colnames(Remaining) <- 'stockName'

#make all the stock name columns one field of stock names
df36 <- gather(Close52, 'stockName','stockDayValue',1:52)

#merge the names of the remaining stock and the total stocks to keep only the ones needed
DF_36 <- merge(Remaining,df36, by.x='stockName', by.y='stockName')

#spread out the stock names into columns after getting only the stocks needed for adding stats
#from the 52 total, and 17 completed.
remaining36 <- spread(DF_36,'stockName','stockDayValue')

#order by date
remaining36 <- remaining36[order(remaining36$Date),]

```

```{r}
write.csv(remaining36,'remaining36.csv', row.names=FALSE)
```


***
***
***


Add the 7 day lag then add the ratio of each day's stock value to the lag. Then get the counts of cumulative days the ratio increased and decreased. Then add the max, median, and 3rd quantile stats of those cumulative day counts for increased and decreased.

```{r}
remaining36_g <- gather(remaining36, 'stockName','stockDayValue',2:37) 
```

```{r}
remaining36_g <- remaining36_g[with(remaining36_g, order(stockName, Date)),]

Laal <- subset(remaining36_g, remaining36_g$stockName=='AAL')
Larwr <- subset(remaining36_g, remaining36_g$stockName=='ARWR')
Lc <- subset(remaining36_g, remaining36_g$stockName=='C')
Lcvx <- subset(remaining36_g, remaining36_g$stockName=='CVX')
Lepd <- subset(remaining36_g, remaining36_g$stockName=='EPD')
Lf <- subset(remaining36_g, remaining36_g$stockName=='F')
Lftr <- subset(remaining36_g, remaining36_g$stockName=='FTR')
Lhmc <- subset(remaining36_g, remaining36_g$stockName=='HMC')
Lhoft <- subset(remaining36_g, remaining36_g$stockName=='HOFT')
Lhrb <- subset(remaining36_g, remaining36_g$stockName=='HRB')
Lhst <- subset(remaining36_g, remaining36_g$stockName=='HST')
Lino <- subset(remaining36_g, remaining36_g$stockName=='INO')
Ljblu <- subset(remaining36_g, remaining36_g$stockName=='JBLU')
Ljpm <- subset(remaining36_g, remaining36_g$stockName=='JPM')
Ljwn <- subset(remaining36_g, remaining36_g$stockName=='JWN')
Lkgji <- subset(remaining36_g, remaining36_g$stockName=='KGJI')
Lkss <- subset(remaining36_g, remaining36_g$stockName=='KSS')
Lluv <- subset(remaining36_g, remaining36_g$stockName=='LUV')
Lm <- subset(remaining36_g, remaining36_g$stockName=='M')
Lmgm <- subset(remaining36_g, remaining36_g$stockName=='MGM')
Lmsft <- subset(remaining36_g, remaining36_g$stockName=='MSFT')
Lnsany <- subset(remaining36_g, remaining36_g$stockName=='NSANY')
Lnus <- subset(remaining36_g, remaining36_g$stockName=='NUS')
Loncy <- subset(remaining36_g, remaining36_g$stockName=='ONCY')
Lrrgb <- subset(remaining36_g, remaining36_g$stockName=='RRGB')
Ls <- subset(remaining36_g, remaining36_g$stockName=='S')
Lsig <- subset(remaining36_g, remaining36_g$stockName=='SIG')
Lt <- subset(remaining36_g, remaining36_g$stockName=='T')
Ltgt <- subset(remaining36_g, remaining36_g$stockName=='TGT')
Ltm <- subset(remaining36_g, remaining36_g$stockName=='TM')
Lubsi <- subset(remaining36_g, remaining36_g$stockName=='UBSI')
Lvz <- subset(remaining36_g, remaining36_g$stockName=='VZ')
Lwfc <- subset(remaining36_g, remaining36_g$stockName=='WFC')
Lwm <- subset(remaining36_g, remaining36_g$stockName=='WM')
Lwwe <- subset(remaining36_g, remaining36_g$stockName=='WWE')

aalL7 <- lag(Laal$stockDayValue,7)
arwrL7 <- lag(Larwr$stockDayValue,7)
cL7 <- lag(Lc$stockDayValue,7)
cvxL7 <- lag(Lcvx$stockDayValue,7)
epdL7 <- lag(Lepd$stockDayValue,7)
fL7 <- lag(Lf$stockDayValue,7)
ftrL7 <- lag(Lftr$stockDayValue,7)
hmcL7 <- lag(Lhmc$stockDayValue,7)
hoftL7 <- lag(Lhoft$stockDayValue,7)
hrbL7 <- lag(Lhrb$stockDayValue,7)
hstL7 <- lag(Lhst$stockDayValue,7)
inoL7 <- lag(Lino$stockDayValue,7)
jbluL7 <- lag(Ljblu$stockDayValue,7)
jpmL7 <- lag(Ljpm$stockDayValue,7)
jwnL7 <- lag(Ljwn$stockDayValue,7)
kgjiL7 <- lag(Lkgji$stockDayValue,7)
kssL7 <- lag(Lkss$stockDayValue,7)
luvL7 <- lag(Lluv$stockDayValue,7)
mL7 <- lag(Lm$stockDayValue,7)
mgmL7 <- lag(Lmgm$stockDayValue,7)
msftL7 <- lag(Lmsft$stockDayValue,7)
nsanyL7 <- lag(Lnsany$stockDayValue,7)
nusL7 <- lag(Lnus$stockDayValue,7)
oncyL7 <- lag(Loncy$stockDayValue,7)
rrgbL7 <- lag(Lrrgb$stockDayValue,7)
sL7 <- lag(Ls$stockDayValue,7)
sceL7 <- lag(Lsce$stockDayValue,7)
sigL7 <- lag(Lsig$stockDayValue,7)
tL7 <- lag(Lt$stockDayValue,7)
tgtL7 <- lag(Ltgt$stockDayValue,7)
tmL7 <- lag(Ltm$stockDayValue,7)
ubsiL7 <- lag(Lubsi$stockDayValue,7)
vzL7 <- lag(Lvz$stockDayValue,7)
wfcL7 <- lag(Lwfc$stockDayValue,7)
wmL7 <- lag(Lwm$stockDayValue,7)
wweL7 <- lag(Lwwe$stockDayValue,7)

remaining36_g$lag7 <- c(aalL7,arwrL7,cL7,cvxL7,epdL7,fL7,ftrL7,
                                  hmcL7,hoftL7,hrbL7,hstL7,inoL7,jbluL7,jpmL7,
                                  jwnL7,kgjiL7,kssL7,luvL7,mL7,mgmL7,msftL7,nsanyL7,nusL7,oncyL7,
                                  rrgbL7,sL7,sceL7,sigL7,tL7,tgtL7,tmL7,
                                  ubsiL7,vzL7,wfcL7,wmL7,wweL7)
#the dataset is ordered by stock then by date, so this works with matching,
#NAs are present when no data in dataset before that date, and the today2lag7
#will also have NAs in those instances
remaining36_g$today2lag7 <- remaining36_g$lag7/remaining36_g$stockDayValue

```

***

```{r}
AAL <- subset(remaining36_g, remaining36_g$stockName=='AAL')

AAL <- AAL[complete.cases(AAL),]

aal7_a <- ifelse(AAL$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for aal7 <- <- ifelse(AAL$today2lag7>1, 1,0)
aal7_ab <- cumsum(aal7_a)

aal7_abc <- as.data.frame(as.factor(aal7_ab))
colnames(aal7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countAAL <- aal7_abc %>% group_by(cSum) %>% count(n=n())
countAAL <- as.data.frame(countAAL)
countAAL <- countAAL[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countAAL$aal7_decr_Days <- countAAL$n-1
countAAL <- countAAL[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countAAL2 <- subset(countAAL, countAAL$aal7_decr_Days>0)
summary(countAAL2$aal7_decr_Days)


```

```{r}
# this table shows how many sets of cumulative days decreasing there were in lag 7
aal7_decr_Days_grouped <- countAAL2 %>% group_by(aal7_decr_Days) %>% count(n=n())
aal7_decr_Days_grouped <- aal7_decr_Days_grouped[,-3]

aal7_decr_Days_grouped
```


```{r}
median(aal7_decr_Days_grouped$aal7_decr_Days)
median(aal7_decr_Days_grouped$n)
```

```{r}

#assign a 1 to decreasing values
aal7_b1 <- ifelse(AAL$today2lag7>1, 0,1)


aal7_b2 <- cumsum(aal7_b1)

aal7_b3 <- as.data.frame(as.factor(aal7_b2))
colnames(aal7_b3) <- 'cSum'

countAAL1 <- aal7_b3 %>% group_by(cSum) %>% count(n=n())
countAAL1 <- as.data.frame(countAAL1)
countAAL1 <- countAAL1[,-3]

countAAL1$aal7_incr_Days <- countAAL1$n-1
countAAL1 <- countAAL1[,-2]

countAAL3 <- subset(countAAL1, countAAL1$aal7_incr_Days>0)
summary(countAAL3$aal7_incr_Days)

```

```{r}
aal7_incr_Days_grouped <- countAAL3 %>% group_by(aal7_incr_Days) %>% count(n=n())
aal7_incr_Days_grouped <- aal7_incr_Days_grouped[,-3]

aal7_incr_Days_grouped
```

```{r}
median(aal7_incr_Days_grouped$aal7_incr_Days)
```


***



```{r}
ARWR <- subset(remaining36_g, remaining36_g$stockName=='ARWR')

ARWR <- ARWR[complete.cases(ARWR),]

arwr7_a <- ifelse(ARWR$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for arwr7 <- <- ifelse(ARWR$today2lag7>1, 1,0)
arwr7_ab <- cumsum(arwr7_a)

arwr7_abc <- as.data.frame(as.factor(arwr7_ab))
colnames(arwr7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countARWR <- arwr7_abc %>% group_by(cSum) %>% count(n=n())
countARWR <- as.data.frame(countARWR)
countARWR <- countARWR[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countARWR$arwr7_decr_Days <- countARWR$n-1
countARWR <- countARWR[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countARWR2 <- subset(countARWR, countARWR$arwr7_decr_Days>0)
summary(countARWR2$arwr7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
arwr7_decr_Days_grouped <- countARWR2 %>% group_by(arwr7_decr_Days) %>% count(n=n())
arwr7_decr_Days_grouped <- arwr7_decr_Days_grouped[,-3]
```

```{r}
arwr7_decr_Days_grouped
```

```{r}

median(arwr7_decr_Days_grouped$arwr7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
arwr7_b1 <- ifelse(ARWR$today2lag7>1, 0,1)


arwr7_b2 <- cumsum(arwr7_b1)

arwr7_b3 <- as.data.frame(as.factor(arwr7_b2))
colnames(arwr7_b3) <- 'cSum'

countARWR1 <- arwr7_b3 %>% group_by(cSum) %>% count(n=n())
countARWR1 <- as.data.frame(countARWR1)
countARWR1 <- countARWR1[,-3]

countARWR1$arwr7_incr_Days <- countARWR1$n-1
countARWR1 <- countARWR1[,-2]

countARWR3 <- subset(countARWR1, countARWR1$arwr7_incr_Days>0)
summary(countARWR3$arwr7_incr_Days)

arwr7_incr_Days_grouped <- countARWR3 %>% group_by(arwr7_incr_Days) %>% count(n=n())
arwr7_incr_Days_grouped <- arwr7_incr_Days_grouped[,-3]
```

```{r}
arwr7_incr_Days_grouped
```

```{r}
median(arwr7_incr_Days_grouped$arwr7_incr_Days)
```


***
 
```{r}
C <- subset(remaining36_g, remaining36_g$stockName=='C')

C <- C[complete.cases(C),]

c7_a <- ifelse(C$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for c7 <- <- ifelse(C$today2lag7>1, 1,0)
c7_ab <- cumsum(c7_a)

c7_abc <- as.data.frame(as.factor(c7_ab))
colnames(c7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countC <- c7_abc %>% group_by(cSum) %>% count(n=n())
countC <- as.data.frame(countC)
countC <- countC[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countC$c7_decr_Days <- countC$n-1
countC <- countC[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countC2 <- subset(countC, countC$c7_decr_Days>0)
summary(countC2$c7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
c7_decr_Days_grouped <- countC2 %>% group_by(c7_decr_Days) %>% count(n=n())
c7_decr_Days_grouped <- c7_decr_Days_grouped[,-3]
```

```{r}
c7_decr_Days_grouped
```

```{r}

median(c7_decr_Days_grouped$c7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
c7_b1 <- ifelse(C$today2lag7>1, 0,1)


c7_b2 <- cumsum(c7_b1)

c7_b3 <- as.data.frame(as.factor(c7_b2))
colnames(c7_b3) <- 'cSum'

countC1 <- c7_b3 %>% group_by(cSum) %>% count(n=n())
countC1 <- as.data.frame(countC1)
countC1 <- countC1[,-3]

countC1$c7_incr_Days <- countC1$n-1
countC1 <- countC1[,-2]

countC3 <- subset(countC1, countC1$c7_incr_Days>0)
summary(countC3$c7_incr_Days)

c7_incr_Days_grouped <- countC3 %>% group_by(c7_incr_Days) %>% count(n=n())
c7_incr_Days_grouped <- c7_incr_Days_grouped[,-3]
```

```{r}
c7_incr_Days_grouped
```

```{r}
median(c7_incr_Days_grouped$c7_incr_Days)
```
 
***

```{r}
CVX <- subset(remaining36_g, remaining36_g$stockName=='CVX')

CVX <- CVX[complete.cases(CVX),]

cvx7_a <- ifelse(CVX$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for cvx7 <- <- ifelse(CVX$today2lag7>1, 1,0)
cvx7_ab <- cumsum(cvx7_a)

cvx7_abc <- as.data.frame(as.factor(cvx7_ab))
colnames(cvx7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countCVX <- cvx7_abc %>% group_by(cSum) %>% count(n=n())
countCVX <- as.data.frame(countCVX)
countCVX <- countCVX[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countCVX$cvx7_decr_Days <- countCVX$n-1
countCVX <- countCVX[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countCVX2 <- subset(countCVX, countCVX$cvx7_decr_Days>0)
summary(countCVX2$cvx7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
cvx7_decr_Days_grouped <- countCVX2 %>% group_by(cvx7_decr_Days) %>% count(n=n())
cvx7_decr_Days_grouped <- cvx7_decr_Days_grouped[,-3]
```

```{r}
cvx7_decr_Days_grouped
```

```{r}

median(cvx7_decr_Days_grouped$cvx7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
cvx7_b1 <- ifelse(CVX$today2lag7>1, 0,1)


cvx7_b2 <- cumsum(cvx7_b1)

cvx7_b3 <- as.data.frame(as.factor(cvx7_b2))
colnames(cvx7_b3) <- 'cSum'

countCVX1 <- cvx7_b3 %>% group_by(cSum) %>% count(n=n())
countCVX1 <- as.data.frame(countCVX1)
countCVX1 <- countCVX1[,-3]

countCVX1$cvx7_incr_Days <- countCVX1$n-1
countCVX1 <- countCVX1[,-2]

countCVX3 <- subset(countCVX1, countCVX1$cvx7_incr_Days>0)
summary(countCVX3$cvx7_incr_Days)

cvx7_incr_Days_grouped <- countCVX3 %>% group_by(cvx7_incr_Days) %>% count(n=n())
cvx7_incr_Days_grouped <- cvx7_incr_Days_grouped[,-3]
```

```{r}
cvx7_incr_Days_grouped
```

```{r}
median(cvx7_incr_Days_grouped$cvx7_incr_Days)
```

***


```{r}
EPD <- subset(remaining36_g, remaining36_g$stockName=='EPD')

EPD <- EPD[complete.cases(EPD),]

epd7_a <- ifelse(EPD$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for epd7 <- <- ifelse(EPD$today2lag7>1, 1,0)
epd7_ab <- cumsum(epd7_a)

epd7_abc <- as.data.frame(as.factor(epd7_ab))
colnames(epd7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countEPD <- epd7_abc %>% group_by(cSum) %>% count(n=n())
countEPD <- as.data.frame(countEPD)
countEPD <- countEPD[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countEPD$epd7_decr_Days <- countEPD$n-1
countEPD <- countEPD[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countEPD2 <- subset(countEPD, countEPD$epd7_decr_Days>0)
summary(countEPD2$epd7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
epd7_decr_Days_grouped <- countEPD2 %>% group_by(epd7_decr_Days) %>% count(n=n())
epd7_decr_Days_grouped <- epd7_decr_Days_grouped[,-3]
```

```{r}
epd7_decr_Days_grouped
```

```{r}

median(epd7_decr_Days_grouped$epd7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
epd7_b1 <- ifelse(EPD$today2lag7>1, 0,1)


epd7_b2 <- cumsum(epd7_b1)

epd7_b3 <- as.data.frame(as.factor(epd7_b2))
colnames(epd7_b3) <- 'cSum'

countEPD1 <- epd7_b3 %>% group_by(cSum) %>% count(n=n())
countEPD1 <- as.data.frame(countEPD1)
countEPD1 <- countEPD1[,-3]

countEPD1$epd7_incr_Days <- countEPD1$n-1
countEPD1 <- countEPD1[,-2]

countEPD3 <- subset(countEPD1, countEPD1$epd7_incr_Days>0)
summary(countEPD3$epd7_incr_Days)

epd7_incr_Days_grouped <- countEPD3 %>% group_by(epd7_incr_Days) %>% count(n=n())
epd7_incr_Days_grouped <- epd7_incr_Days_grouped[,-3]
```

```{r}
epd7_incr_Days_grouped
```

```{r}
median(epd7_incr_Days_grouped$epd7_incr_Days)
```


***


```{r}
F <- subset(remaining36_g, remaining36_g$stockName=='F')

F <- F[complete.cases(F),]

f7_a <- ifelse(F$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for f7 <- <- ifelse(F$today2lag7>1, 1,0)
f7_ab <- cumsum(f7_a)

f7_abc <- as.data.frame(as.factor(f7_ab))
colnames(f7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countF <- f7_abc %>% group_by(cSum) %>% count(n=n())
countF <- as.data.frame(countF)
countF <- countF[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countF$f7_decr_Days <- countF$n-1
countF <- countF[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countF2 <- subset(countF, countF$f7_decr_Days>0)
summary(countF2$f7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
f7_decr_Days_grouped <- countF2 %>% group_by(f7_decr_Days) %>% count(n=n())
f7_decr_Days_grouped <- f7_decr_Days_grouped[,-3]
```

```{r}
f7_decr_Days_grouped
```

```{r}

median(f7_decr_Days_grouped$f7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
f7_b1 <- ifelse(F$today2lag7>1, 0,1)


f7_b2 <- cumsum(f7_b1)

f7_b3 <- as.data.frame(as.factor(f7_b2))
colnames(f7_b3) <- 'cSum'

countF1 <- f7_b3 %>% group_by(cSum) %>% count(n=n())
countF1 <- as.data.frame(countF1)
countF1 <- countF1[,-3]

countF1$f7_incr_Days <- countF1$n-1
countF1 <- countF1[,-2]

countF3 <- subset(countF1, countF1$f7_incr_Days>0)
summary(countF3$f7_incr_Days)

f7_incr_Days_grouped <- countF3 %>% group_by(f7_incr_Days) %>% count(n=n())
f7_incr_Days_grouped <- f7_incr_Days_grouped[,-3]
```

```{r}
f7_incr_Days_grouped
```

```{r}
median(f7_incr_Days_grouped$f7_incr_Days)
```


***


```{r}
FTR <- subset(remaining36_g, remaining36_g$stockName=='FTR')

FTR <- FTR[complete.cases(FTR),]

ftr7_a <- ifelse(FTR$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for ftr7 <- <- ifelse(FTR$today2lag7>1, 1,0)
ftr7_ab <- cumsum(ftr7_a)

ftr7_abc <- as.data.frame(as.factor(ftr7_ab))
colnames(ftr7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countFTR <- ftr7_abc %>% group_by(cSum) %>% count(n=n())
countFTR <- as.data.frame(countFTR)
countFTR <- countFTR[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countFTR$ftr7_decr_Days <- countFTR$n-1
countFTR <- countFTR[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countFTR2 <- subset(countFTR, countFTR$ftr7_decr_Days>0)
summary(countFTR2$ftr7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
ftr7_decr_Days_grouped <- countFTR2 %>% group_by(ftr7_decr_Days) %>% count(n=n())
ftr7_decr_Days_grouped <- ftr7_decr_Days_grouped[,-3]
```

```{r}
ftr7_decr_Days_grouped
```

```{r}

median(ftr7_decr_Days_grouped$ftr7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
ftr7_b1 <- ifelse(FTR$today2lag7>1, 0,1)


ftr7_b2 <- cumsum(ftr7_b1)

ftr7_b3 <- as.data.frame(as.factor(ftr7_b2))
colnames(ftr7_b3) <- 'cSum'

countFTR1 <- ftr7_b3 %>% group_by(cSum) %>% count(n=n())
countFTR1 <- as.data.frame(countFTR1)
countFTR1 <- countFTR1[,-3]

countFTR1$ftr7_incr_Days <- countFTR1$n-1
countFTR1 <- countFTR1[,-2]

countFTR3 <- subset(countFTR1, countFTR1$ftr7_incr_Days>0)
summary(countFTR3$ftr7_incr_Days)

ftr7_incr_Days_grouped <- countFTR3 %>% group_by(ftr7_incr_Days) %>% count(n=n())
ftr7_incr_Days_grouped <- ftr7_incr_Days_grouped[,-3]
```

```{r}
ftr7_incr_Days_grouped
```

```{r}
median(ftr7_incr_Days_grouped$ftr7_incr_Days)
```


***

```{r}
HMC <- subset(remaining36_g, remaining36_g$stockName=='HMC')

HMC <- HMC[complete.cases(HMC),]

hmc7_a <- ifelse(HMC$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for hmc7 <- <- ifelse(HMC$today2lag7>1, 1,0)
hmc7_ab <- cumsum(hmc7_a)

hmc7_abc <- as.data.frame(as.factor(hmc7_ab))
colnames(hmc7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countHMC <- hmc7_abc %>% group_by(cSum) %>% count(n=n())
countHMC <- as.data.frame(countHMC)
countHMC <- countHMC[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countHMC$hmc7_decr_Days <- countHMC$n-1
countHMC <- countHMC[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countHMC2 <- subset(countHMC, countHMC$hmc7_decr_Days>0)
summary(countHMC2$hmc7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
hmc7_decr_Days_grouped <- countHMC2 %>% group_by(hmc7_decr_Days) %>% count(n=n())
hmc7_decr_Days_grouped <- hmc7_decr_Days_grouped[,-3]
```

```{r}
hmc7_decr_Days_grouped
```

```{r}

median(hmc7_decr_Days_grouped$hmc7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
hmc7_b1 <- ifelse(HMC$today2lag7>1, 0,1)


hmc7_b2 <- cumsum(hmc7_b1)

hmc7_b3 <- as.data.frame(as.factor(hmc7_b2))
colnames(hmc7_b3) <- 'cSum'

countHMC1 <- hmc7_b3 %>% group_by(cSum) %>% count(n=n())
countHMC1 <- as.data.frame(countHMC1)
countHMC1 <- countHMC1[,-3]

countHMC1$hmc7_incr_Days <- countHMC1$n-1
countHMC1 <- countHMC1[,-2]

countHMC3 <- subset(countHMC1, countHMC1$hmc7_incr_Days>0)
summary(countHMC3$hmc7_incr_Days)

hmc7_incr_Days_grouped <- countHMC3 %>% group_by(hmc7_incr_Days) %>% count(n=n())
hmc7_incr_Days_grouped <- hmc7_incr_Days_grouped[,-3]
```

```{r}
hmc7_incr_Days_grouped
```

```{r}
median(hmc7_incr_Days_grouped$hmc7_incr_Days)
```

***


```{r}
HOFT <- subset(remaining36_g, remaining36_g$stockName=='HOFT')

HOFT <- HOFT[complete.cases(HOFT),]

hoft7_a <- ifelse(HOFT$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for hoft7 <- <- ifelse(HOFT$today2lag7>1, 1,0)
hoft7_ab <- cumsum(hoft7_a)

hoft7_abc <- as.data.frame(as.factor(hoft7_ab))
colnames(hoft7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countHOFT <- hoft7_abc %>% group_by(cSum) %>% count(n=n())
countHOFT <- as.data.frame(countHOFT)
countHOFT <- countHOFT[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countHOFT$hoft7_decr_Days <- countHOFT$n-1
countHOFT <- countHOFT[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countHOFT2 <- subset(countHOFT, countHOFT$hoft7_decr_Days>0)
summary(countHOFT2$hoft7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
hoft7_decr_Days_grouped <- countHOFT2 %>% group_by(hoft7_decr_Days) %>% count(n=n())
hoft7_decr_Days_grouped <- hoft7_decr_Days_grouped[,-3]
```

```{r}
hoft7_decr_Days_grouped
```

```{r}

median(hoft7_decr_Days_grouped$hoft7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
hoft7_b1 <- ifelse(HOFT$today2lag7>1, 0,1)


hoft7_b2 <- cumsum(hoft7_b1)

hoft7_b3 <- as.data.frame(as.factor(hoft7_b2))
colnames(hoft7_b3) <- 'cSum'

countHOFT1 <- hoft7_b3 %>% group_by(cSum) %>% count(n=n())
countHOFT1 <- as.data.frame(countHOFT1)
countHOFT1 <- countHOFT1[,-3]

countHOFT1$hoft7_incr_Days <- countHOFT1$n-1
countHOFT1 <- countHOFT1[,-2]

countHOFT3 <- subset(countHOFT1, countHOFT1$hoft7_incr_Days>0)
summary(countHOFT3$hoft7_incr_Days)

hoft7_incr_Days_grouped <- countHOFT3 %>% group_by(hoft7_incr_Days) %>% count(n=n())
hoft7_incr_Days_grouped <- hoft7_incr_Days_grouped[,-3]
```

```{r}
hoft7_incr_Days_grouped
```

```{r}
median(hoft7_incr_Days_grouped$hoft7_incr_Days)
```

***


```{r}
HRB <- subset(remaining36_g, remaining36_g$stockName=='HRB')

HRB <- HRB[complete.cases(HRB),]

hrb7_a <- ifelse(HRB$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for hrb7 <- <- ifelse(HRB$today2lag7>1, 1,0)
hrb7_ab <- cumsum(hrb7_a)

hrb7_abc <- as.data.frame(as.factor(hrb7_ab))
colnames(hrb7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countHRB <- hrb7_abc %>% group_by(cSum) %>% count(n=n())
countHRB <- as.data.frame(countHRB)
countHRB <- countHRB[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countHRB$hrb7_decr_Days <- countHRB$n-1
countHRB <- countHRB[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countHRB2 <- subset(countHRB, countHRB$hrb7_decr_Days>0)
summary(countHRB2$hrb7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
hrb7_decr_Days_grouped <- countHRB2 %>% group_by(hrb7_decr_Days) %>% count(n=n())
hrb7_decr_Days_grouped <- hrb7_decr_Days_grouped[,-3]
```

```{r}
hrb7_decr_Days_grouped
```

```{r}

median(hrb7_decr_Days_grouped$hrb7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
hrb7_b1 <- ifelse(HRB$today2lag7>1, 0,1)


hrb7_b2 <- cumsum(hrb7_b1)

hrb7_b3 <- as.data.frame(as.factor(hrb7_b2))
colnames(hrb7_b3) <- 'cSum'

countHRB1 <- hrb7_b3 %>% group_by(cSum) %>% count(n=n())
countHRB1 <- as.data.frame(countHRB1)
countHRB1 <- countHRB1[,-3]

countHRB1$hrb7_incr_Days <- countHRB1$n-1
countHRB1 <- countHRB1[,-2]

countHRB3 <- subset(countHRB1, countHRB1$hrb7_incr_Days>0)
summary(countHRB3$hrb7_incr_Days)

hrb7_incr_Days_grouped <- countHRB3 %>% group_by(hrb7_incr_Days) %>% count(n=n())
hrb7_incr_Days_grouped <- hrb7_incr_Days_grouped[,-3]
```

```{r}
hrb7_incr_Days_grouped
```

```{r}
median(hrb7_incr_Days_grouped$hrb7_incr_Days)
```


***

```{r}
HST <- subset(remaining36_g, remaining36_g$stockName=='HST')

HST <- HST[complete.cases(HST),]

hst7_a <- ifelse(HST$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for hst7 <- <- ifelse(HST$today2lag7>1, 1,0)
hst7_ab <- cumsum(hst7_a)

hst7_abc <- as.data.frame(as.factor(hst7_ab))
colnames(hst7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countHST <- hst7_abc %>% group_by(cSum) %>% count(n=n())
countHST <- as.data.frame(countHST)
countHST <- countHST[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countHST$hst7_decr_Days <- countHST$n-1
countHST <- countHST[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countHST2 <- subset(countHST, countHST$hst7_decr_Days>0)
summary(countHST2$hst7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
hst7_decr_Days_grouped <- countHST2 %>% group_by(hst7_decr_Days) %>% count(n=n())
hst7_decr_Days_grouped <- hst7_decr_Days_grouped[,-3]
```

```{r}
hst7_decr_Days_grouped
```

```{r}

median(hst7_decr_Days_grouped$hst7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
hst7_b1 <- ifelse(HST$today2lag7>1, 0,1)


hst7_b2 <- cumsum(hst7_b1)

hst7_b3 <- as.data.frame(as.factor(hst7_b2))
colnames(hst7_b3) <- 'cSum'

countHST1 <- hst7_b3 %>% group_by(cSum) %>% count(n=n())
countHST1 <- as.data.frame(countHST1)
countHST1 <- countHST1[,-3]

countHST1$hst7_incr_Days <- countHST1$n-1
countHST1 <- countHST1[,-2]

countHST3 <- subset(countHST1, countHST1$hst7_incr_Days>0)
summary(countHST3$hst7_incr_Days)

hst7_incr_Days_grouped <- countHST3 %>% group_by(hst7_incr_Days) %>% count(n=n())
hst7_incr_Days_grouped <- hst7_incr_Days_grouped[,-3]
```

```{r}
hst7_incr_Days_grouped
```

```{r}
median(hst7_incr_Days_grouped$hst7_incr_Days)
```

***


```{r}
INO <- subset(remaining36_g, remaining36_g$stockName=='INO')

INO <- INO[complete.cases(INO),]

ino7_a <- ifelse(INO$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for ino7 <- <- ifelse(INO$today2lag7>1, 1,0)
ino7_ab <- cumsum(ino7_a)

ino7_abc <- as.data.frame(as.factor(ino7_ab))
colnames(ino7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countINO <- ino7_abc %>% group_by(cSum) %>% count(n=n())
countINO <- as.data.frame(countINO)
countINO <- countINO[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countINO$ino7_decr_Days <- countINO$n-1
countINO <- countINO[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countINO2 <- subset(countINO, countINO$ino7_decr_Days>0)
summary(countINO2$ino7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
ino7_decr_Days_grouped <- countINO2 %>% group_by(ino7_decr_Days) %>% count(n=n())
ino7_decr_Days_grouped <- ino7_decr_Days_grouped[,-3]
```

```{r}
ino7_decr_Days_grouped
```

```{r}

median(ino7_decr_Days_grouped$ino7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
ino7_b1 <- ifelse(INO$today2lag7>1, 0,1)


ino7_b2 <- cumsum(ino7_b1)

ino7_b3 <- as.data.frame(as.factor(ino7_b2))
colnames(ino7_b3) <- 'cSum'

countINO1 <- ino7_b3 %>% group_by(cSum) %>% count(n=n())
countINO1 <- as.data.frame(countINO1)
countINO1 <- countINO1[,-3]

countINO1$ino7_incr_Days <- countINO1$n-1
countINO1 <- countINO1[,-2]

countINO3 <- subset(countINO1, countINO1$ino7_incr_Days>0)
summary(countINO3$ino7_incr_Days)

ino7_incr_Days_grouped <- countINO3 %>% group_by(ino7_incr_Days) %>% count(n=n())
ino7_incr_Days_grouped <- ino7_incr_Days_grouped[,-3]
```

```{r}
ino7_incr_Days_grouped
```

```{r}
median(ino7_incr_Days_grouped$ino7_incr_Days)
```

***

```{r}
JBLU <- subset(remaining36_g, remaining36_g$stockName=='JBLU')

JBLU <- JBLU[complete.cases(JBLU),]

jblu7_a <- ifelse(JBLU$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for jblu7 <- <- ifelse(JBLU$today2lag7>1, 1,0)
jblu7_ab <- cumsum(jblu7_a)

jblu7_abc <- as.data.frame(as.factor(jblu7_ab))
colnames(jblu7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countJBLU <- jblu7_abc %>% group_by(cSum) %>% count(n=n())
countJBLU <- as.data.frame(countJBLU)
countJBLU <- countJBLU[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countJBLU$jblu7_decr_Days <- countJBLU$n-1
countJBLU <- countJBLU[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countJBLU2 <- subset(countJBLU, countJBLU$jblu7_decr_Days>0)
summary(countJBLU2$jblu7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
jblu7_decr_Days_grouped <- countJBLU2 %>% group_by(jblu7_decr_Days) %>% count(n=n())
jblu7_decr_Days_grouped <- jblu7_decr_Days_grouped[,-3]
```

```{r}
jblu7_decr_Days_grouped
```

```{r}

median(jblu7_decr_Days_grouped$jblu7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
jblu7_b1 <- ifelse(JBLU$today2lag7>1, 0,1)


jblu7_b2 <- cumsum(jblu7_b1)

jblu7_b3 <- as.data.frame(as.factor(jblu7_b2))
colnames(jblu7_b3) <- 'cSum'

countJBLU1 <- jblu7_b3 %>% group_by(cSum) %>% count(n=n())
countJBLU1 <- as.data.frame(countJBLU1)
countJBLU1 <- countJBLU1[,-3]

countJBLU1$jblu7_incr_Days <- countJBLU1$n-1
countJBLU1 <- countJBLU1[,-2]

countJBLU3 <- subset(countJBLU1, countJBLU1$jblu7_incr_Days>0)
summary(countJBLU3$jblu7_incr_Days)

jblu7_incr_Days_grouped <- countJBLU3 %>% group_by(jblu7_incr_Days) %>% count(n=n())
jblu7_incr_Days_grouped <- jblu7_incr_Days_grouped[,-3]
```

```{r}
jblu7_incr_Days_grouped
```

```{r}
median(jblu7_incr_Days_grouped$jblu7_incr_Days)
```

***

```{r}
JPM <- subset(remaining36_g, remaining36_g$stockName=='JPM')

JPM <- JPM[complete.cases(JPM),]

jpm7_a <- ifelse(JPM$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for jpm7 <- <- ifelse(JPM$today2lag7>1, 1,0)
jpm7_ab <- cumsum(jpm7_a)

jpm7_abc <- as.data.frame(as.factor(jpm7_ab))
colnames(jpm7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countJPM <- jpm7_abc %>% group_by(cSum) %>% count(n=n())
countJPM <- as.data.frame(countJPM)
countJPM <- countJPM[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countJPM$jpm7_decr_Days <- countJPM$n-1
countJPM <- countJPM[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countJPM2 <- subset(countJPM, countJPM$jpm7_decr_Days>0)
summary(countJPM2$jpm7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
jpm7_decr_Days_grouped <- countJPM2 %>% group_by(jpm7_decr_Days) %>% count(n=n())
jpm7_decr_Days_grouped <- jpm7_decr_Days_grouped[,-3]
```

```{r}
jpm7_decr_Days_grouped
```

```{r}

median(jpm7_decr_Days_grouped$jpm7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
jpm7_b1 <- ifelse(JPM$today2lag7>1, 0,1)


jpm7_b2 <- cumsum(jpm7_b1)

jpm7_b3 <- as.data.frame(as.factor(jpm7_b2))
colnames(jpm7_b3) <- 'cSum'

countJPM1 <- jpm7_b3 %>% group_by(cSum) %>% count(n=n())
countJPM1 <- as.data.frame(countJPM1)
countJPM1 <- countJPM1[,-3]

countJPM1$jpm7_incr_Days <- countJPM1$n-1
countJPM1 <- countJPM1[,-2]

countJPM3 <- subset(countJPM1, countJPM1$jpm7_incr_Days>0)
summary(countJPM3$jpm7_incr_Days)

jpm7_incr_Days_grouped <- countJPM3 %>% group_by(jpm7_incr_Days) %>% count(n=n())
jpm7_incr_Days_grouped <- jpm7_incr_Days_grouped[,-3]
```

```{r}
jpm7_incr_Days_grouped
```

```{r}
median(jpm7_incr_Days_grouped$jpm7_incr_Days)
```

***


```{r}
JWN <- subset(remaining36_g, remaining36_g$stockName=='JWN')

JWN <- JWN[complete.cases(JWN),]

jwn7_a <- ifelse(JWN$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for jwn7 <- <- ifelse(JWN$today2lag7>1, 1,0)
jwn7_ab <- cumsum(jwn7_a)

jwn7_abc <- as.data.frame(as.factor(jwn7_ab))
colnames(jwn7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countJWN <- jwn7_abc %>% group_by(cSum) %>% count(n=n())
countJWN <- as.data.frame(countJWN)
countJWN <- countJWN[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countJWN$jwn7_decr_Days <- countJWN$n-1
countJWN <- countJWN[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countJWN2 <- subset(countJWN, countJWN$jwn7_decr_Days>0)
summary(countJWN2$jwn7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
jwn7_decr_Days_grouped <- countJWN2 %>% group_by(jwn7_decr_Days) %>% count(n=n())
jwn7_decr_Days_grouped <- jwn7_decr_Days_grouped[,-3]
```

```{r}
jwn7_decr_Days_grouped
```

```{r}

median(jwn7_decr_Days_grouped$jwn7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
jwn7_b1 <- ifelse(JWN$today2lag7>1, 0,1)


jwn7_b2 <- cumsum(jwn7_b1)

jwn7_b3 <- as.data.frame(as.factor(jwn7_b2))
colnames(jwn7_b3) <- 'cSum'

countJWN1 <- jwn7_b3 %>% group_by(cSum) %>% count(n=n())
countJWN1 <- as.data.frame(countJWN1)
countJWN1 <- countJWN1[,-3]

countJWN1$jwn7_incr_Days <- countJWN1$n-1
countJWN1 <- countJWN1[,-2]

countJWN3 <- subset(countJWN1, countJWN1$jwn7_incr_Days>0)
summary(countJWN3$jwn7_incr_Days)

jwn7_incr_Days_grouped <- countJWN3 %>% group_by(jwn7_incr_Days) %>% count(n=n())
jwn7_incr_Days_grouped <- jwn7_incr_Days_grouped[,-3]
```

```{r}
jwn7_incr_Days_grouped
```

```{r}
median(jwn7_incr_Days_grouped$jwn7_incr_Days)
```

***


```{r}
KGJI <- subset(remaining36_g, remaining36_g$stockName=='KGJI')

KGJI <- KGJI[complete.cases(KGJI),]

kgji7_a <- ifelse(KGJI$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for kgji7 <- <- ifelse(KGJI$today2lag7>1, 1,0)
kgji7_ab <- cumsum(kgji7_a)

kgji7_abc <- as.data.frame(as.factor(kgji7_ab))
colnames(kgji7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countKGJI <- kgji7_abc %>% group_by(cSum) %>% count(n=n())
countKGJI <- as.data.frame(countKGJI)
countKGJI <- countKGJI[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countKGJI$kgji7_decr_Days <- countKGJI$n-1
countKGJI <- countKGJI[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countKGJI2 <- subset(countKGJI, countKGJI$kgji7_decr_Days>0)
summary(countKGJI2$kgji7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
kgji7_decr_Days_grouped <- countKGJI2 %>% group_by(kgji7_decr_Days) %>% count(n=n())
kgji7_decr_Days_grouped <- kgji7_decr_Days_grouped[,-3]
```

```{r}
kgji7_decr_Days_grouped
```

```{r}

median(kgji7_decr_Days_grouped$kgji7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
kgji7_b1 <- ifelse(KGJI$today2lag7>1, 0,1)


kgji7_b2 <- cumsum(kgji7_b1)

kgji7_b3 <- as.data.frame(as.factor(kgji7_b2))
colnames(kgji7_b3) <- 'cSum'

countKGJI1 <- kgji7_b3 %>% group_by(cSum) %>% count(n=n())
countKGJI1 <- as.data.frame(countKGJI1)
countKGJI1 <- countKGJI1[,-3]

countKGJI1$kgji7_incr_Days <- countKGJI1$n-1
countKGJI1 <- countKGJI1[,-2]

countKGJI3 <- subset(countKGJI1, countKGJI1$kgji7_incr_Days>0)
summary(countKGJI3$kgji7_incr_Days)

kgji7_incr_Days_grouped <- countKGJI3 %>% group_by(kgji7_incr_Days) %>% count(n=n())
kgji7_incr_Days_grouped <- kgji7_incr_Days_grouped[,-3]
```

```{r}
kgji7_incr_Days_grouped
```

```{r}
median(kgji7_incr_Days_grouped$kgji7_incr_Days)
```

***

```{r}
KSS <- subset(remaining36_g, remaining36_g$stockName=='KSS')

KSS <- KSS[complete.cases(KSS),]

kss7_a <- ifelse(KSS$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for kss7 <- <- ifelse(KSS$today2lag7>1, 1,0)
kss7_ab <- cumsum(kss7_a)

kss7_abc <- as.data.frame(as.factor(kss7_ab))
colnames(kss7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countKSS <- kss7_abc %>% group_by(cSum) %>% count(n=n())
countKSS <- as.data.frame(countKSS)
countKSS <- countKSS[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countKSS$kss7_decr_Days <- countKSS$n-1
countKSS <- countKSS[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countKSS2 <- subset(countKSS, countKSS$kss7_decr_Days>0)
summary(countKSS2$kss7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
kss7_decr_Days_grouped <- countKSS2 %>% group_by(kss7_decr_Days) %>% count(n=n())
kss7_decr_Days_grouped <- kss7_decr_Days_grouped[,-3]
```

```{r}
kss7_decr_Days_grouped
```

```{r}

median(kss7_decr_Days_grouped$kss7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
kss7_b1 <- ifelse(KSS$today2lag7>1, 0,1)


kss7_b2 <- cumsum(kss7_b1)

kss7_b3 <- as.data.frame(as.factor(kss7_b2))
colnames(kss7_b3) <- 'cSum'

countKSS1 <- kss7_b3 %>% group_by(cSum) %>% count(n=n())
countKSS1 <- as.data.frame(countKSS1)
countKSS1 <- countKSS1[,-3]

countKSS1$kss7_incr_Days <- countKSS1$n-1
countKSS1 <- countKSS1[,-2]

countKSS3 <- subset(countKSS1, countKSS1$kss7_incr_Days>0)
summary(countKSS3$kss7_incr_Days)

kss7_incr_Days_grouped <- countKSS3 %>% group_by(kss7_incr_Days) %>% count(n=n())
kss7_incr_Days_grouped <- kss7_incr_Days_grouped[,-3]
```

```{r}
kss7_incr_Days_grouped
```

```{r}
median(kss7_incr_Days_grouped$kss7_incr_Days)
```


***


```{r}
LUV <- subset(remaining36_g, remaining36_g$stockName=='LUV')

LUV <- LUV[complete.cases(LUV),]

luv7_a <- ifelse(LUV$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for luv7 <- <- ifelse(LUV$today2lag7>1, 1,0)
luv7_ab <- cumsum(luv7_a)

luv7_abc <- as.data.frame(as.factor(luv7_ab))
colnames(luv7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countLUV <- luv7_abc %>% group_by(cSum) %>% count(n=n())
countLUV <- as.data.frame(countLUV)
countLUV <- countLUV[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countLUV$luv7_decr_Days <- countLUV$n-1
countLUV <- countLUV[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countLUV2 <- subset(countLUV, countLUV$luv7_decr_Days>0)
summary(countLUV2$luv7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
luv7_decr_Days_grouped <- countLUV2 %>% group_by(luv7_decr_Days) %>% count(n=n())
luv7_decr_Days_grouped <- luv7_decr_Days_grouped[,-3]
```

```{r}
luv7_decr_Days_grouped
```

```{r}

median(luv7_decr_Days_grouped$luv7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
luv7_b1 <- ifelse(LUV$today2lag7>1, 0,1)


luv7_b2 <- cumsum(luv7_b1)

luv7_b3 <- as.data.frame(as.factor(luv7_b2))
colnames(luv7_b3) <- 'cSum'

countLUV1 <- luv7_b3 %>% group_by(cSum) %>% count(n=n())
countLUV1 <- as.data.frame(countLUV1)
countLUV1 <- countLUV1[,-3]

countLUV1$luv7_incr_Days <- countLUV1$n-1
countLUV1 <- countLUV1[,-2]

countLUV3 <- subset(countLUV1, countLUV1$luv7_incr_Days>0)
summary(countLUV3$luv7_incr_Days)

luv7_incr_Days_grouped <- countLUV3 %>% group_by(luv7_incr_Days) %>% count(n=n())
luv7_incr_Days_grouped <- luv7_incr_Days_grouped[,-3]
```

```{r}
luv7_incr_Days_grouped
```

```{r}
median(luv7_incr_Days_grouped$luv7_incr_Days)
```

***

```{r}
M <- subset(remaining36_g, remaining36_g$stockName=='M')

M <- M[complete.cases(M),]

m7_a <- ifelse(M$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for m7 <- <- ifelse(M$today2lag7>1, 1,0)
m7_ab <- cumsum(m7_a)

m7_abc <- as.data.frame(as.factor(m7_ab))
colnames(m7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countM <- m7_abc %>% group_by(cSum) %>% count(n=n())
countM <- as.data.frame(countM)
countM <- countM[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countM$m7_decr_Days <- countM$n-1
countM <- countM[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countM2 <- subset(countM, countM$m7_decr_Days>0)
summary(countM2$m7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
m7_decr_Days_grouped <- countM2 %>% group_by(m7_decr_Days) %>% count(n=n())
m7_decr_Days_grouped <- m7_decr_Days_grouped[,-3]
```

```{r}
m7_decr_Days_grouped
```

```{r}

median(m7_decr_Days_grouped$m7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
m7_b1 <- ifelse(M$today2lag7>1, 0,1)


m7_b2 <- cumsum(m7_b1)

m7_b3 <- as.data.frame(as.factor(m7_b2))
colnames(m7_b3) <- 'cSum'

countM1 <- m7_b3 %>% group_by(cSum) %>% count(n=n())
countM1 <- as.data.frame(countM1)
countM1 <- countM1[,-3]

countM1$m7_incr_Days <- countM1$n-1
countM1 <- countM1[,-2]

countM3 <- subset(countM1, countM1$m7_incr_Days>0)
summary(countM3$m7_incr_Days)

m7_incr_Days_grouped <- countM3 %>% group_by(m7_incr_Days) %>% count(n=n())
m7_incr_Days_grouped <- m7_incr_Days_grouped[,-3]
```

```{r}
m7_incr_Days_grouped
```

```{r}
median(m7_incr_Days_grouped$m7_incr_Days)
```


***


```{r}
MGM <- subset(remaining36_g, remaining36_g$stockName=='MGM')

MGM <- MGM[complete.cases(MGM),]

mgm7_a <- ifelse(MGM$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for mgm7 <- <- ifelse(MGM$today2lag7>1, 1,0)
mgm7_ab <- cumsum(mgm7_a)

mgm7_abc <- as.data.frame(as.factor(mgm7_ab))
colnames(mgm7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countMGM <- mgm7_abc %>% group_by(cSum) %>% count(n=n())
countMGM <- as.data.frame(countMGM)
countMGM <- countMGM[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countMGM$mgm7_decr_Days <- countMGM$n-1
countMGM <- countMGM[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countMGM2 <- subset(countMGM, countMGM$mgm7_decr_Days>0)
summary(countMGM2$mgm7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
mgm7_decr_Days_grouped <- countMGM2 %>% group_by(mgm7_decr_Days) %>% count(n=n())
mgm7_decr_Days_grouped <- mgm7_decr_Days_grouped[,-3]
```

```{r}
mgm7_decr_Days_grouped
```

```{r}

median(mgm7_decr_Days_grouped$mgm7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
mgm7_b1 <- ifelse(MGM$today2lag7>1, 0,1)


mgm7_b2 <- cumsum(mgm7_b1)

mgm7_b3 <- as.data.frame(as.factor(mgm7_b2))
colnames(mgm7_b3) <- 'cSum'

countMGM1 <- mgm7_b3 %>% group_by(cSum) %>% count(n=n())
countMGM1 <- as.data.frame(countMGM1)
countMGM1 <- countMGM1[,-3]

countMGM1$mgm7_incr_Days <- countMGM1$n-1
countMGM1 <- countMGM1[,-2]

countMGM3 <- subset(countMGM1, countMGM1$mgm7_incr_Days>0)
summary(countMGM3$mgm7_incr_Days)

mgm7_incr_Days_grouped <- countMGM3 %>% group_by(mgm7_incr_Days) %>% count(n=n())
mgm7_incr_Days_grouped <- mgm7_incr_Days_grouped[,-3]
```

```{r}
mgm7_incr_Days_grouped
```

```{r}
median(mgm7_incr_Days_grouped$mgm7_incr_Days)
```

***


```{r}
MSFT <- subset(remaining36_g, remaining36_g$stockName=='MSFT')

MSFT <- MSFT[complete.cases(MSFT),]

msft7_a <- ifelse(MSFT$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for msft7 <- <- ifelse(MSFT$today2lag7>1, 1,0)
msft7_ab <- cumsum(msft7_a)

msft7_abc <- as.data.frame(as.factor(msft7_ab))
colnames(msft7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countMSFT <- msft7_abc %>% group_by(cSum) %>% count(n=n())
countMSFT <- as.data.frame(countMSFT)
countMSFT <- countMSFT[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countMSFT$msft7_decr_Days <- countMSFT$n-1
countMSFT <- countMSFT[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countMSFT2 <- subset(countMSFT, countMSFT$msft7_decr_Days>0)
summary(countMSFT2$msft7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
msft7_decr_Days_grouped <- countMSFT2 %>% group_by(msft7_decr_Days) %>% count(n=n())
msft7_decr_Days_grouped <- msft7_decr_Days_grouped[,-3]
```

```{r}
msft7_decr_Days_grouped
```

```{r}

median(msft7_decr_Days_grouped$msft7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
msft7_b1 <- ifelse(MSFT$today2lag7>1, 0,1)


msft7_b2 <- cumsum(msft7_b1)

msft7_b3 <- as.data.frame(as.factor(msft7_b2))
colnames(msft7_b3) <- 'cSum'

countMSFT1 <- msft7_b3 %>% group_by(cSum) %>% count(n=n())
countMSFT1 <- as.data.frame(countMSFT1)
countMSFT1 <- countMSFT1[,-3]

countMSFT1$msft7_incr_Days <- countMSFT1$n-1
countMSFT1 <- countMSFT1[,-2]

countMSFT3 <- subset(countMSFT1, countMSFT1$msft7_incr_Days>0)
summary(countMSFT3$msft7_incr_Days)

msft7_incr_Days_grouped <- countMSFT3 %>% group_by(msft7_incr_Days) %>% count(n=n())
msft7_incr_Days_grouped <- msft7_incr_Days_grouped[,-3]
```

```{r}
msft7_incr_Days_grouped
```

```{r}
median(msft7_incr_Days_grouped$msft7_incr_Days)
```

***


```{r}
NSANY <- subset(remaining36_g, remaining36_g$stockName=='NSANY')

NSANY <- NSANY[complete.cases(NSANY),]

nsany7_a <- ifelse(NSANY$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for nsany7 <- <- ifelse(NSANY$today2lag7>1, 1,0)
nsany7_ab <- cumsum(nsany7_a)

nsany7_abc <- as.data.frame(as.factor(nsany7_ab))
colnames(nsany7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countNSANY <- nsany7_abc %>% group_by(cSum) %>% count(n=n())
countNSANY <- as.data.frame(countNSANY)
countNSANY <- countNSANY[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countNSANY$nsany7_decr_Days <- countNSANY$n-1
countNSANY <- countNSANY[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countNSANY2 <- subset(countNSANY, countNSANY$nsany7_decr_Days>0)
summary(countNSANY2$nsany7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
nsany7_decr_Days_grouped <- countNSANY2 %>% group_by(nsany7_decr_Days) %>% count(n=n())
nsany7_decr_Days_grouped <- nsany7_decr_Days_grouped[,-3]
```

```{r}
nsany7_decr_Days_grouped
```

```{r}

median(nsany7_decr_Days_grouped$nsany7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
nsany7_b1 <- ifelse(NSANY$today2lag7>1, 0,1)


nsany7_b2 <- cumsum(nsany7_b1)

nsany7_b3 <- as.data.frame(as.factor(nsany7_b2))
colnames(nsany7_b3) <- 'cSum'

countNSANY1 <- nsany7_b3 %>% group_by(cSum) %>% count(n=n())
countNSANY1 <- as.data.frame(countNSANY1)
countNSANY1 <- countNSANY1[,-3]

countNSANY1$nsany7_incr_Days <- countNSANY1$n-1
countNSANY1 <- countNSANY1[,-2]

countNSANY3 <- subset(countNSANY1, countNSANY1$nsany7_incr_Days>0)
summary(countNSANY3$nsany7_incr_Days)

nsany7_incr_Days_grouped <- countNSANY3 %>% group_by(nsany7_incr_Days) %>% count(n=n())
nsany7_incr_Days_grouped <- nsany7_incr_Days_grouped[,-3]
```

```{r}
nsany7_incr_Days_grouped
```

```{r}
median(nsany7_incr_Days_grouped$nsany7_incr_Days)
```

***


```{r}
NUS <- subset(remaining36_g, remaining36_g$stockName=='NUS')

NUS <- NUS[complete.cases(NUS),]

nus7_a <- ifelse(NUS$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for nus7 <- <- ifelse(NUS$today2lag7>1, 1,0)
nus7_ab <- cumsum(nus7_a)

nus7_abc <- as.data.frame(as.factor(nus7_ab))
colnames(nus7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countNUS <- nus7_abc %>% group_by(cSum) %>% count(n=n())
countNUS <- as.data.frame(countNUS)
countNUS <- countNUS[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countNUS$nus7_decr_Days <- countNUS$n-1
countNUS <- countNUS[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countNUS2 <- subset(countNUS, countNUS$nus7_decr_Days>0)
summary(countNUS2$nus7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
nus7_decr_Days_grouped <- countNUS2 %>% group_by(nus7_decr_Days) %>% count(n=n())
nus7_decr_Days_grouped <- nus7_decr_Days_grouped[,-3]
```

```{r}
nus7_decr_Days_grouped
```

```{r}

median(nus7_decr_Days_grouped$nus7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
nus7_b1 <- ifelse(NUS$today2lag7>1, 0,1)


nus7_b2 <- cumsum(nus7_b1)

nus7_b3 <- as.data.frame(as.factor(nus7_b2))
colnames(nus7_b3) <- 'cSum'

countNUS1 <- nus7_b3 %>% group_by(cSum) %>% count(n=n())
countNUS1 <- as.data.frame(countNUS1)
countNUS1 <- countNUS1[,-3]

countNUS1$nus7_incr_Days <- countNUS1$n-1
countNUS1 <- countNUS1[,-2]

countNUS3 <- subset(countNUS1, countNUS1$nus7_incr_Days>0)
summary(countNUS3$nus7_incr_Days)

nus7_incr_Days_grouped <- countNUS3 %>% group_by(nus7_incr_Days) %>% count(n=n())
nus7_incr_Days_grouped <- nus7_incr_Days_grouped[,-3]
```

```{r}
nus7_incr_Days_grouped
```

```{r}
median(nus7_incr_Days_grouped$nus7_incr_Days)
```


***


```{r}
ONCY <- subset(remaining36_g, remaining36_g$stockName=='ONCY')

ONCY <- ONCY[complete.cases(ONCY),]

oncy7_a <- ifelse(ONCY$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for oncy7 <- <- ifelse(ONCY$today2lag7>1, 1,0)
oncy7_ab <- cumsum(oncy7_a)

oncy7_abc <- as.data.frame(as.factor(oncy7_ab))
colnames(oncy7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countONCY <- oncy7_abc %>% group_by(cSum) %>% count(n=n())
countONCY <- as.data.frame(countONCY)
countONCY <- countONCY[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countONCY$oncy7_decr_Days <- countONCY$n-1
countONCY <- countONCY[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countONCY2 <- subset(countONCY, countONCY$oncy7_decr_Days>0)
summary(countONCY2$oncy7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
oncy7_decr_Days_grouped <- countONCY2 %>% group_by(oncy7_decr_Days) %>% count(n=n())
oncy7_decr_Days_grouped <- oncy7_decr_Days_grouped[,-3]
```

```{r}
oncy7_decr_Days_grouped
```

```{r}

median(oncy7_decr_Days_grouped$oncy7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
oncy7_b1 <- ifelse(ONCY$today2lag7>1, 0,1)


oncy7_b2 <- cumsum(oncy7_b1)

oncy7_b3 <- as.data.frame(as.factor(oncy7_b2))
colnames(oncy7_b3) <- 'cSum'

countONCY1 <- oncy7_b3 %>% group_by(cSum) %>% count(n=n())
countONCY1 <- as.data.frame(countONCY1)
countONCY1 <- countONCY1[,-3]

countONCY1$oncy7_incr_Days <- countONCY1$n-1
countONCY1 <- countONCY1[,-2]

countONCY3 <- subset(countONCY1, countONCY1$oncy7_incr_Days>0)
summary(countONCY3$oncy7_incr_Days)

oncy7_incr_Days_grouped <- countONCY3 %>% group_by(oncy7_incr_Days) %>% count(n=n())
oncy7_incr_Days_grouped <- oncy7_incr_Days_grouped[,-3]
```

```{r}
oncy7_incr_Days_grouped
```

```{r}
median(oncy7_incr_Days_grouped$oncy7_incr_Days)
```

***


```{r}
RRGB <- subset(remaining36_g, remaining36_g$stockName=='RRGB')

RRGB <- RRGB[complete.cases(RRGB),]

rrgb7_a <- ifelse(RRGB$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for rrgb7 <- <- ifelse(RRGB$today2lag7>1, 1,0)
rrgb7_ab <- cumsum(rrgb7_a)

rrgb7_abc <- as.data.frame(as.factor(rrgb7_ab))
colnames(rrgb7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countRRGB <- rrgb7_abc %>% group_by(cSum) %>% count(n=n())
countRRGB <- as.data.frame(countRRGB)
countRRGB <- countRRGB[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countRRGB$rrgb7_decr_Days <- countRRGB$n-1
countRRGB <- countRRGB[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countRRGB2 <- subset(countRRGB, countRRGB$rrgb7_decr_Days>0)
summary(countRRGB2$rrgb7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
rrgb7_decr_Days_grouped <- countRRGB2 %>% group_by(rrgb7_decr_Days) %>% count(n=n())
rrgb7_decr_Days_grouped <- rrgb7_decr_Days_grouped[,-3]
```

```{r}
rrgb7_decr_Days_grouped
```

```{r}

median(rrgb7_decr_Days_grouped$rrgb7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
rrgb7_b1 <- ifelse(RRGB$today2lag7>1, 0,1)


rrgb7_b2 <- cumsum(rrgb7_b1)

rrgb7_b3 <- as.data.frame(as.factor(rrgb7_b2))
colnames(rrgb7_b3) <- 'cSum'

countRRGB1 <- rrgb7_b3 %>% group_by(cSum) %>% count(n=n())
countRRGB1 <- as.data.frame(countRRGB1)
countRRGB1 <- countRRGB1[,-3]

countRRGB1$rrgb7_incr_Days <- countRRGB1$n-1
countRRGB1 <- countRRGB1[,-2]

countRRGB3 <- subset(countRRGB1, countRRGB1$rrgb7_incr_Days>0)
summary(countRRGB3$rrgb7_incr_Days)

rrgb7_incr_Days_grouped <- countRRGB3 %>% group_by(rrgb7_incr_Days) %>% count(n=n())
rrgb7_incr_Days_grouped <- rrgb7_incr_Days_grouped[,-3]
```

```{r}
rrgb7_incr_Days_grouped
```

```{r}
median(rrgb7_incr_Days_grouped$rrgb7_incr_Days)
```


***


```{r}
S <- subset(remaining36_g, remaining36_g$stockName=='S')

S <- S[complete.cases(S),]

s7_a <- ifelse(S$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for s7 <- <- ifelse(S$today2lag7>1, 1,0)
s7_ab <- cumsum(s7_a)

s7_abc <- as.data.frame(as.factor(s7_ab))
colnames(s7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countS <- s7_abc %>% group_by(cSum) %>% count(n=n())
countS <- as.data.frame(countS)
countS <- countS[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countS$s7_decr_Days <- countS$n-1
countS <- countS[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countS2 <- subset(countS, countS$s7_decr_Days>0)
summary(countS2$s7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
s7_decr_Days_grouped <- countS2 %>% group_by(s7_decr_Days) %>% count(n=n())
s7_decr_Days_grouped <- s7_decr_Days_grouped[,-3]
```

```{r}
s7_decr_Days_grouped
```

```{r}

median(s7_decr_Days_grouped$s7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
s7_b1 <- ifelse(S$today2lag7>1, 0,1)


s7_b2 <- cumsum(s7_b1)

s7_b3 <- as.data.frame(as.factor(s7_b2))
colnames(s7_b3) <- 'cSum'

countS1 <- s7_b3 %>% group_by(cSum) %>% count(n=n())
countS1 <- as.data.frame(countS1)
countS1 <- countS1[,-3]

countS1$s7_incr_Days <- countS1$n-1
countS1 <- countS1[,-2]

countS3 <- subset(countS1, countS1$s7_incr_Days>0)
summary(countS3$s7_incr_Days)

s7_incr_Days_grouped <- countS3 %>% group_by(s7_incr_Days) %>% count(n=n())
s7_incr_Days_grouped <- s7_incr_Days_grouped[,-3]
```

```{r}
s7_incr_Days_grouped
```

```{r}
median(s7_incr_Days_grouped$s7_incr_Days)
```


***

```{r}
SIG <- subset(remaining36_g, remaining36_g$stockName=='SIG')

SIG <- SIG[complete.cases(SIG),]

sig7_a <- ifelse(SIG$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for sig7 <- <- ifelse(SIG$today2lag7>1, 1,0)
sig7_ab <- cumsum(sig7_a)

sig7_abc <- as.data.frame(as.factor(sig7_ab))
colnames(sig7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countSIG <- sig7_abc %>% group_by(cSum) %>% count(n=n())
countSIG <- as.data.frame(countSIG)
countSIG <- countSIG[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countSIG$sig7_decr_Days <- countSIG$n-1
countSIG <- countSIG[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countSIG2 <- subset(countSIG, countSIG$sig7_decr_Days>0)
summary(countSIG2$sig7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
sig7_decr_Days_grouped <- countSIG2 %>% group_by(sig7_decr_Days) %>% count(n=n())
sig7_decr_Days_grouped <- sig7_decr_Days_grouped[,-3]
```

```{r}
sig7_decr_Days_grouped
```

```{r}

median(sig7_decr_Days_grouped$sig7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
sig7_b1 <- ifelse(SIG$today2lag7>1, 0,1)


sig7_b2 <- cumsum(sig7_b1)

sig7_b3 <- as.data.frame(as.factor(sig7_b2))
colnames(sig7_b3) <- 'cSum'

countSIG1 <- sig7_b3 %>% group_by(cSum) %>% count(n=n())
countSIG1 <- as.data.frame(countSIG1)
countSIG1 <- countSIG1[,-3]

countSIG1$sig7_incr_Days <- countSIG1$n-1
countSIG1 <- countSIG1[,-2]

countSIG3 <- subset(countSIG1, countSIG1$sig7_incr_Days>0)
summary(countSIG3$sig7_incr_Days)

sig7_incr_Days_grouped <- countSIG3 %>% group_by(sig7_incr_Days) %>% count(n=n())
sig7_incr_Days_grouped <- sig7_incr_Days_grouped[,-3]
```

```{r}
sig7_incr_Days_grouped
```

```{r}
median(sig7_incr_Days_grouped$sig7_incr_Days)
```


***

```{r}
T <- subset(remaining36_g, remaining36_g$stockName=='T')

T <- T[complete.cases(T),]

t7_a <- ifelse(T$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for t7 <- <- ifelse(T$today2lag7>1, 1,0)
t7_ab <- cumsum(t7_a)

t7_abc <- as.data.frame(as.factor(t7_ab))
colnames(t7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countT <- t7_abc %>% group_by(cSum) %>% count(n=n())
countT <- as.data.frame(countT)
countT <- countT[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countT$t7_decr_Days <- countT$n-1
countT <- countT[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countT2 <- subset(countT, countT$t7_decr_Days>0)
summary(countT2$t7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
t7_decr_Days_grouped <- countT2 %>% group_by(t7_decr_Days) %>% count(n=n())
t7_decr_Days_grouped <- t7_decr_Days_grouped[,-3]
```

```{r}
t7_decr_Days_grouped
```

```{r}

median(t7_decr_Days_grouped$t7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
t7_b1 <- ifelse(T$today2lag7>1, 0,1)


t7_b2 <- cumsum(t7_b1)

t7_b3 <- as.data.frame(as.factor(t7_b2))
colnames(t7_b3) <- 'cSum'

countT1 <- t7_b3 %>% group_by(cSum) %>% count(n=n())
countT1 <- as.data.frame(countT1)
countT1 <- countT1[,-3]

countT1$t7_incr_Days <- countT1$n-1
countT1 <- countT1[,-2]

countT3 <- subset(countT1, countT1$t7_incr_Days>0)
summary(countT3$t7_incr_Days)

t7_incr_Days_grouped <- countT3 %>% group_by(t7_incr_Days) %>% count(n=n())
t7_incr_Days_grouped <- t7_incr_Days_grouped[,-3]
```

```{r}
t7_incr_Days_grouped
```

```{r}
median(t7_incr_Days_grouped$t7_incr_Days)
```


***


```{r}
TGT <- subset(remaining36_g, remaining36_g$stockName=='TGT')

TGT <- TGT[complete.cases(TGT),]

tgt7_a <- ifelse(TGT$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for tgt7 <- <- ifelse(TGT$today2lag7>1, 1,0)
tgt7_ab <- cumsum(tgt7_a)

tgt7_abc <- as.data.frame(as.factor(tgt7_ab))
colnames(tgt7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countTGT <- tgt7_abc %>% group_by(cSum) %>% count(n=n())
countTGT <- as.data.frame(countTGT)
countTGT <- countTGT[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countTGT$tgt7_decr_Days <- countTGT$n-1
countTGT <- countTGT[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countTGT2 <- subset(countTGT, countTGT$tgt7_decr_Days>0)
summary(countTGT2$tgt7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
tgt7_decr_Days_grouped <- countTGT2 %>% group_by(tgt7_decr_Days) %>% count(n=n())
tgt7_decr_Days_grouped <- tgt7_decr_Days_grouped[,-3]
```

```{r}
tgt7_decr_Days_grouped
```

```{r}

median(tgt7_decr_Days_grouped$tgt7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
tgt7_b1 <- ifelse(TGT$today2lag7>1, 0,1)


tgt7_b2 <- cumsum(tgt7_b1)

tgt7_b3 <- as.data.frame(as.factor(tgt7_b2))
colnames(tgt7_b3) <- 'cSum'

countTGT1 <- tgt7_b3 %>% group_by(cSum) %>% count(n=n())
countTGT1 <- as.data.frame(countTGT1)
countTGT1 <- countTGT1[,-3]

countTGT1$tgt7_incr_Days <- countTGT1$n-1
countTGT1 <- countTGT1[,-2]

countTGT3 <- subset(countTGT1, countTGT1$tgt7_incr_Days>0)
summary(countTGT3$tgt7_incr_Days)

tgt7_incr_Days_grouped <- countTGT3 %>% group_by(tgt7_incr_Days) %>% count(n=n())
tgt7_incr_Days_grouped <- tgt7_incr_Days_grouped[,-3]
```

```{r}
tgt7_incr_Days_grouped
```

```{r}
median(tgt7_incr_Days_grouped$tgt7_incr_Days)
```


***


```{r}
TM <- subset(remaining36_g, remaining36_g$stockName=='TM')

TM <- TM[complete.cases(TM),]

tm7_a <- ifelse(TM$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for tm7 <- <- ifelse(TM$today2lag7>1, 1,0)
tm7_ab <- cumsum(tm7_a)

tm7_abc <- as.data.frame(as.factor(tm7_ab))
colnames(tm7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countTM <- tm7_abc %>% group_by(cSum) %>% count(n=n())
countTM <- as.data.frame(countTM)
countTM <- countTM[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countTM$tm7_decr_Days <- countTM$n-1
countTM <- countTM[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countTM2 <- subset(countTM, countTM$tm7_decr_Days>0)
summary(countTM2$tm7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
tm7_decr_Days_grouped <- countTM2 %>% group_by(tm7_decr_Days) %>% count(n=n())
tm7_decr_Days_grouped <- tm7_decr_Days_grouped[,-3]
```

```{r}
tm7_decr_Days_grouped
```

```{r}

median(tm7_decr_Days_grouped$tm7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
tm7_b1 <- ifelse(TM$today2lag7>1, 0,1)


tm7_b2 <- cumsum(tm7_b1)

tm7_b3 <- as.data.frame(as.factor(tm7_b2))
colnames(tm7_b3) <- 'cSum'

countTM1 <- tm7_b3 %>% group_by(cSum) %>% count(n=n())
countTM1 <- as.data.frame(countTM1)
countTM1 <- countTM1[,-3]

countTM1$tm7_incr_Days <- countTM1$n-1
countTM1 <- countTM1[,-2]

countTM3 <- subset(countTM1, countTM1$tm7_incr_Days>0)
summary(countTM3$tm7_incr_Days)

tm7_incr_Days_grouped <- countTM3 %>% group_by(tm7_incr_Days) %>% count(n=n())
tm7_incr_Days_grouped <- tm7_incr_Days_grouped[,-3]
```

```{r}
tm7_incr_Days_grouped
```

```{r}
median(tm7_incr_Days_grouped$tm7_incr_Days)
```


***


```{r}
UBSI <- subset(remaining36_g, remaining36_g$stockName=='UBSI')

UBSI <- UBSI[complete.cases(UBSI),]

ubsi7_a <- ifelse(UBSI$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for ubsi7 <- <- ifelse(UBSI$today2lag7>1, 1,0)
ubsi7_ab <- cumsum(ubsi7_a)

ubsi7_abc <- as.data.frame(as.factor(ubsi7_ab))
colnames(ubsi7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countUBSI <- ubsi7_abc %>% group_by(cSum) %>% count(n=n())
countUBSI <- as.data.frame(countUBSI)
countUBSI <- countUBSI[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countUBSI$ubsi7_decr_Days <- countUBSI$n-1
countUBSI <- countUBSI[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countUBSI2 <- subset(countUBSI, countUBSI$ubsi7_decr_Days>0)
summary(countUBSI2$ubsi7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
ubsi7_decr_Days_grouped <- countUBSI2 %>% group_by(ubsi7_decr_Days) %>% count(n=n())
ubsi7_decr_Days_grouped <- ubsi7_decr_Days_grouped[,-3]
```

```{r}
ubsi7_decr_Days_grouped
```

```{r}

median(ubsi7_decr_Days_grouped$ubsi7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
ubsi7_b1 <- ifelse(UBSI$today2lag7>1, 0,1)


ubsi7_b2 <- cumsum(ubsi7_b1)

ubsi7_b3 <- as.data.frame(as.factor(ubsi7_b2))
colnames(ubsi7_b3) <- 'cSum'

countUBSI1 <- ubsi7_b3 %>% group_by(cSum) %>% count(n=n())
countUBSI1 <- as.data.frame(countUBSI1)
countUBSI1 <- countUBSI1[,-3]

countUBSI1$ubsi7_incr_Days <- countUBSI1$n-1
countUBSI1 <- countUBSI1[,-2]

countUBSI3 <- subset(countUBSI1, countUBSI1$ubsi7_incr_Days>0)
summary(countUBSI3$ubsi7_incr_Days)

ubsi7_incr_Days_grouped <- countUBSI3 %>% group_by(ubsi7_incr_Days) %>% count(n=n())
ubsi7_incr_Days_grouped <- ubsi7_incr_Days_grouped[,-3]
```

```{r}
ubsi7_incr_Days_grouped
```

```{r}
median(ubsi7_incr_Days_grouped$ubsi7_incr_Days)
```

***




```{r}
VZ <- subset(remaining36_g, remaining36_g$stockName=='VZ')

VZ <- VZ[complete.cases(VZ),]

vz7_a <- ifelse(VZ$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for vz7 <- <- ifelse(VZ$today2lag7>1, 1,0)
vz7_ab <- cumsum(vz7_a)

vz7_abc <- as.data.frame(as.factor(vz7_ab))
colnames(vz7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countVZ <- vz7_abc %>% group_by(cSum) %>% count(n=n())
countVZ <- as.data.frame(countVZ)
countVZ <- countVZ[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countVZ$vz7_decr_Days <- countVZ$n-1
countVZ <- countVZ[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countVZ2 <- subset(countVZ, countVZ$vz7_decr_Days>0)
summary(countVZ2$vz7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
vz7_decr_Days_grouped <- countVZ2 %>% group_by(vz7_decr_Days) %>% count(n=n())
vz7_decr_Days_grouped <- vz7_decr_Days_grouped[,-3]
```

```{r}
vz7_decr_Days_grouped
```

```{r}

median(vz7_decr_Days_grouped$vz7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
vz7_b1 <- ifelse(VZ$today2lag7>1, 0,1)


vz7_b2 <- cumsum(vz7_b1)

vz7_b3 <- as.data.frame(as.factor(vz7_b2))
colnames(vz7_b3) <- 'cSum'

countVZ1 <- vz7_b3 %>% group_by(cSum) %>% count(n=n())
countVZ1 <- as.data.frame(countVZ1)
countVZ1 <- countVZ1[,-3]

countVZ1$vz7_incr_Days <- countVZ1$n-1
countVZ1 <- countVZ1[,-2]

countVZ3 <- subset(countVZ1, countVZ1$vz7_incr_Days>0)
summary(countVZ3$vz7_incr_Days)

vz7_incr_Days_grouped <- countVZ3 %>% group_by(vz7_incr_Days) %>% count(n=n())
vz7_incr_Days_grouped <- vz7_incr_Days_grouped[,-3]
```

```{r}
vz7_incr_Days_grouped
```

```{r}
median(vz7_incr_Days_grouped$vz7_incr_Days)
```


***




```{r}
WFC <- subset(remaining36_g, remaining36_g$stockName=='WFC')

WFC <- WFC[complete.cases(WFC),]

wfc7_a <- ifelse(WFC$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for wfc7 <- <- ifelse(WFC$today2lag7>1, 1,0)
wfc7_ab <- cumsum(wfc7_a)

wfc7_abc <- as.data.frame(as.factor(wfc7_ab))
colnames(wfc7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countWFC <- wfc7_abc %>% group_by(cSum) %>% count(n=n())
countWFC <- as.data.frame(countWFC)
countWFC <- countWFC[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countWFC$wfc7_decr_Days <- countWFC$n-1
countWFC <- countWFC[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countWFC2 <- subset(countWFC, countWFC$wfc7_decr_Days>0)
summary(countWFC2$wfc7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
wfc7_decr_Days_grouped <- countWFC2 %>% group_by(wfc7_decr_Days) %>% count(n=n())
wfc7_decr_Days_grouped <- wfc7_decr_Days_grouped[,-3]
```

```{r}
wfc7_decr_Days_grouped
```

```{r}

median(wfc7_decr_Days_grouped$wfc7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
wfc7_b1 <- ifelse(WFC$today2lag7>1, 0,1)


wfc7_b2 <- cumsum(wfc7_b1)

wfc7_b3 <- as.data.frame(as.factor(wfc7_b2))
colnames(wfc7_b3) <- 'cSum'

countWFC1 <- wfc7_b3 %>% group_by(cSum) %>% count(n=n())
countWFC1 <- as.data.frame(countWFC1)
countWFC1 <- countWFC1[,-3]

countWFC1$wfc7_incr_Days <- countWFC1$n-1
countWFC1 <- countWFC1[,-2]

countWFC3 <- subset(countWFC1, countWFC1$wfc7_incr_Days>0)
summary(countWFC3$wfc7_incr_Days)

wfc7_incr_Days_grouped <- countWFC3 %>% group_by(wfc7_incr_Days) %>% count(n=n())
wfc7_incr_Days_grouped <- wfc7_incr_Days_grouped[,-3]
```

```{r}
wfc7_incr_Days_grouped
```

```{r}
median(wfc7_incr_Days_grouped$wfc7_incr_Days)
```


***




```{r}
WM <- subset(remaining36_g, remaining36_g$stockName=='WM')

WM <- WM[complete.cases(WM),]

wm7_a <- ifelse(WM$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for wm7 <- <- ifelse(WM$today2lag7>1, 1,0)
wm7_ab <- cumsum(wm7_a)

wm7_abc <- as.data.frame(as.factor(wm7_ab))
colnames(wm7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countWM <- wm7_abc %>% group_by(cSum) %>% count(n=n())
countWM <- as.data.frame(countWM)
countWM <- countWM[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countWM$wm7_decr_Days <- countWM$n-1
countWM <- countWM[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countWM2 <- subset(countWM, countWM$wm7_decr_Days>0)
summary(countWM2$wm7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
wm7_decr_Days_grouped <- countWM2 %>% group_by(wm7_decr_Days) %>% count(n=n())
wm7_decr_Days_grouped <- wm7_decr_Days_grouped[,-3]
```

```{r}
wm7_decr_Days_grouped
```

```{r}

median(wm7_decr_Days_grouped$wm7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
wm7_b1 <- ifelse(WM$today2lag7>1, 0,1)


wm7_b2 <- cumsum(wm7_b1)

wm7_b3 <- as.data.frame(as.factor(wm7_b2))
colnames(wm7_b3) <- 'cSum'

countWM1 <- wm7_b3 %>% group_by(cSum) %>% count(n=n())
countWM1 <- as.data.frame(countWM1)
countWM1 <- countWM1[,-3]

countWM1$wm7_incr_Days <- countWM1$n-1
countWM1 <- countWM1[,-2]

countWM3 <- subset(countWM1, countWM1$wm7_incr_Days>0)
summary(countWM3$wm7_incr_Days)

wm7_incr_Days_grouped <- countWM3 %>% group_by(wm7_incr_Days) %>% count(n=n())
wm7_incr_Days_grouped <- wm7_incr_Days_grouped[,-3]
```

```{r}
wm7_incr_Days_grouped
```

```{r}
median(wm7_incr_Days_grouped$wm7_incr_Days)
```

***




```{r}
WWE <- subset(remaining36_g, remaining36_g$stockName=='WWE')

WWE <- WWE[complete.cases(WWE),]

wwe7_a <- ifelse(WWE$today2lag7>1, 1,0)

# get cumulative sum of the number of times today's stock increased from 7 days ago,
# the day will be repeated if it didn't increase. For example '10' is repeated 21 times, this 
# counts the number of times the value decreased when setting the variable in the previous 
# code block for wwe7 <- <- ifelse(WWE$today2lag7>1, 1,0)
wwe7_ab <- cumsum(wwe7_a)

wwe7_abc <- as.data.frame(as.factor(wwe7_ab))
colnames(wwe7_abc) <- 'cSum'

# get the count of how many instances or days there are, the more counts, the more 
# days that were decreasing stock values for today's value to 7 days prior value.
countWWE <- wwe7_abc %>% group_by(cSum) %>% count(n=n())
countWWE <- as.data.frame(countWWE)
countWWE <- countWWE[,-3]

# remove this additional day, so that the number of days in a row decreasing is measured
countWWE$wwe7_decr_Days <- countWWE$n-1
countWWE <- countWWE[,-2]

#this is a set of only those days decreasing at least one day in the lag 7 comparison
countWWE2 <- subset(countWWE, countWWE$wwe7_decr_Days>0)
summary(countWWE2$wwe7_decr_Days)

# this table shows how many sets of cumulative days decreasing there were in lag 7
wwe7_decr_Days_grouped <- countWWE2 %>% group_by(wwe7_decr_Days) %>% count(n=n())
wwe7_decr_Days_grouped <- wwe7_decr_Days_grouped[,-3]
```

```{r}
wwe7_decr_Days_grouped
```

```{r}

median(wwe7_decr_Days_grouped$wwe7_decr_Days)
```

```{r}

#assign a 1 to decreasing values
wwe7_b1 <- ifelse(WWE$today2lag7>1, 0,1)


wwe7_b2 <- cumsum(wwe7_b1)

wwe7_b3 <- as.data.frame(as.factor(wwe7_b2))
colnames(wwe7_b3) <- 'cSum'

countWWE1 <- wwe7_b3 %>% group_by(cSum) %>% count(n=n())
countWWE1 <- as.data.frame(countWWE1)
countWWE1 <- countWWE1[,-3]

countWWE1$wwe7_incr_Days <- countWWE1$n-1
countWWE1 <- countWWE1[,-2]

countWWE3 <- subset(countWWE1, countWWE1$wwe7_incr_Days>0)
summary(countWWE3$wwe7_incr_Days)

wwe7_incr_Days_grouped <- countWWE3 %>% group_by(wwe7_incr_Days) %>% count(n=n())
wwe7_incr_Days_grouped <- wwe7_incr_Days_grouped[,-3]
```

```{r}
wwe7_incr_Days_grouped
```

```{r}
median(wwe7_incr_Days_grouped$wwe7_incr_Days)
```

***
***
***
***

Start making the table of statistics for the remaining 36 stocks, using the first set of 17 that were in the best performing portfolio compared to the DOW.

This gets the average and the median stock values from the start and end of this time series from Jan 3, 2007 to Feb 14, 2020.
```{r}
close52_avg <- Close52_g %>% group_by(stockName) %>% summarise_at(vars(stockDayValue),
                                                                  mean)
close52_median <- Close52_g %>% group_by(stockName) %>% summarise_at(vars(stockDayValue),
                                                                  median)
colnames(close52_avg)[2] <- 'avgStockValue'
colnames(close52_median)[2] <- 'medianStockValue'

```



```{r, error=FALSE, message=FALSE, warning=FALSE}
first17 <- dROI17_lag7_d[,-c(1,4)]
row.names(first17) <- row.names(dROI17_lag7_d)

Remaining36 <- remaining36[order(remaining36$Date),]

remaining36_st_fi <- Remaining36[c(1,length(remaining36$Date)),]
remaining36_st_fi_t <- as.data.frame(t(remaining36_st_fi))
colnames(remaining36_st_fi_t) <- c('startValue', 'finalValue')

remaining36_st_fi_t <- remaining36_st_fi_t[-1,]
last36 <- remaining36_st_fi_t

last36$startValue <- as.numeric(as.character(last36$startValue))
last36$finalValue <- as.numeric(as.character(last36$finalValue))

last36$stock_ROI <- last36$finalValue/last36$startValue

last36$medn_cSum_decr_L7 <- 'median cSum down L7'
last36$Q3_cSum_decr_L7 <- '3rd Qntl cSum down L7'
last36$max_cSum_decr_L7 <- 'max cSum down L7'
last36$medn_cSum_incr_L7 <- 'median cSum up L7'
last36$Q3_cSum_incr_L7 <- '3rd Qntl cSun up L7'
last36$max_cSum_incr_L7 <- 'max cSum up L7'

all52 <- rbind(first17, last36)

all52$stockName <- row.names(all52)

all_52 <- merge(close52_avg, all52, by.x='stockName', by.y='stockName')
All52 <- merge(close52_median, all_52, by.x='stockName', by.y='stockName')
head(All52)
```


Add these statistics to their respective stock instance in the All52 table now that we have the table, there are 36 stock statistics on the number of times the stock increases and decreases in this time span that need to be filled in. Carefully find and replace the names of each of the remaining 36 stock for the lower and upper instances in the block below. Then after running each chunk of code, the All52 table will be filled in.

AAL-American Airlines:
```{r}
mdnaal_d <- median(countAAL2$aal7_decr_Days)
q3aal_d <- as.numeric(as.character(summary(countAAL2$aal7_decr_Days)["3rd Qu."]))
mxaal_d <- max(countAAL2$aal7_decr_Days)

mdnaal_i <- median(countAAL3$aal7_incr_Days)
q3aal_i <- as.numeric(as.character(summary(countAAL3$aal7_incr_Days)["3rd Qu."]))
mxaal_i <- max(countAAL3$aal7_incr_Days)

aal_g <- grep('AAL', All52$stockName )

All52[aal_g,7:12] <- c(mdnaal_d,q3aal_d,mxaal_d,mdnaal_i,q3aal_i,mxaal_i)

```

The above code chunk filled in the AAL stock statistical information.
```{r}
head(All52)

```

Now to fill in the other 35 stocks for our completed ML table of stats (for now).

ARWR-Arrowhead Pharmaceuticals:
```{r}
mdnarwr_d <- median(countARWR2$arwr7_decr_Days)
q3arwr_d <- as.numeric(as.character(summary(countARWR2$arwr7_decr_Days)["3rd Qu."]))
mxarwr_d <- max(countARWR2$arwr7_decr_Days)

mdnarwr_i <- median(countARWR3$arwr7_incr_Days)
q3arwr_i <- as.numeric(as.character(summary(countARWR3$arwr7_incr_Days)["3rd Qu."]))
mxarwr_i <- max(countARWR3$arwr7_incr_Days)

arwr_g <- grep('ARWR', All52$stockName )

All52[arwr_g,7:12] <- c(mdnarwr_d,q3arwr_d,mxarwr_d,mdnarwr_i,q3arwr_i,mxarwr_i)

```

C-Citigroup:
```{r}
mdnc_d <- median(countC2$c7_decr_Days)
q3c_d <- as.numeric(as.character(summary(countC2$c7_decr_Days)["3rd Qu."]))
mxc_d <- max(countC2$c7_decr_Days)

mdnc_i <- median(countC3$c7_incr_Days)
q3c_i <- as.numeric(as.character(summary(countC3$c7_incr_Days)["3rd Qu."]))
mxc_i <- max(countC3$c7_incr_Days)

c_g <- grep('C', All52$stockName )

All52[c_g,7:12] <- c(mdnc_d,q3c_d,mxc_d,mdnc_i,q3c_i,mxc_i)

```

EPD-Enterprise Products Partners:
```{r}
mdnepd_d <- median(countEPD2$epd7_decr_Days)
q3epd_d <- as.numeric(as.character(summary(countEPD2$epd7_decr_Days)["3rd Qu."]))
mxepd_d <- max(countEPD2$epd7_decr_Days)

mdnepd_i <- median(countEPD3$epd7_incr_Days)
q3epd_i <- as.numeric(as.character(summary(countEPD3$epd7_incr_Days)["3rd Qu."]))
mxepd_i <- max(countEPD3$epd7_incr_Days)

epd_g <- grep('EPD', All52$stockName )

All52[epd_g,7:12] <- c(mdnepd_d,q3epd_d,mxepd_d,mdnepd_i,q3epd_i,mxepd_i)

```

F-Ford:
```{r}
mdnf_d <- median(countF2$f7_decr_Days)
q3f_d <- as.numeric(as.character(summary(countF2$f7_decr_Days)["3rd Qu."]))
mxf_d <- max(countF2$f7_decr_Days)

mdnf_i <- median(countF3$f7_incr_Days)
q3f_i <- as.numeric(as.character(summary(countF3$f7_incr_Days)["3rd Qu."]))
mxf_i <- max(countF3$f7_incr_Days)

f_g <- grep('F', All52$stockName )

All52[f_g,7:12] <- c(mdnf_d,q3f_d,mxf_d,mdnf_i,q3f_i,mxf_i)

```

HRB-H&R Block:
```{r}
mdnhrb_d <- median(countHRB2$hrb7_decr_Days)
q3hrb_d <- as.numeric(as.character(summary(countHRB2$hrb7_decr_Days)["3rd Qu."]))
mxhrb_d <- max(countHRB2$hrb7_decr_Days)

mdnhrb_i <- median(countHRB3$hrb7_incr_Days)
q3hrb_i <- as.numeric(as.character(summary(countHRB3$hrb7_incr_Days)["3rd Qu."]))
mxhrb_i <- max(countHRB3$hrb7_incr_Days)

hrb_g <- grep('HRB', All52$stockName )

All52[hrb_g,7:12] <- c(mdnhrb_d,q3hrb_d,mxhrb_d,mdnhrb_i,q3hrb_i,mxhrb_i)

```

HST-Host Hotels & Resorts:
```{r}
mdnhst_d <- median(countHST2$hst7_decr_Days)
q3hst_d <- as.numeric(as.character(summary(countHST2$hst7_decr_Days)["3rd Qu."]))
mxhst_d <- max(countHST2$hst7_decr_Days)

mdnhst_i <- median(countHST3$hst7_incr_Days)
q3hst_i <- as.numeric(as.character(summary(countHST3$hst7_incr_Days)["3rd Qu."]))
mxhst_i <- max(countHST3$hst7_incr_Days)

hst_g <- grep('HST', All52$stockName )

All52[hst_g,7:12] <- c(mdnhst_d,q3hst_d,mxhst_d,mdnhst_i,q3hst_i,mxhst_i)

```

INO-Inovio Pharmaceuticals:
```{r}
mdnino_d <- median(countINO2$ino7_decr_Days)
q3ino_d <- as.numeric(as.character(summary(countINO2$ino7_decr_Days)["3rd Qu."]))
mxino_d <- max(countINO2$ino7_decr_Days)

mdnino_i <- median(countINO3$ino7_incr_Days)
q3ino_i <- as.numeric(as.character(summary(countINO3$ino7_incr_Days)["3rd Qu."]))
mxino_i <- max(countINO3$ino7_incr_Days)

ino_g <- grep('INO', All52$stockName )

All52[ino_g,7:12] <- c(mdnino_d,q3ino_d,mxino_d,mdnino_i,q3ino_i,mxino_i)

```

JBLU-Jet Blue Airways:
```{r}
mdnjblu_d <- median(countJBLU2$jblu7_decr_Days)
q3jblu_d <- as.numeric(as.character(summary(countJBLU2$jblu7_decr_Days)["3rd Qu."]))
mxjblu_d <- max(countJBLU2$jblu7_decr_Days)

mdnjblu_i <- median(countJBLU3$jblu7_incr_Days)
q3jblu_i <- as.numeric(as.character(summary(countJBLU3$jblu7_incr_Days)["3rd Qu."]))
mxjblu_i <- max(countJBLU3$jblu7_incr_Days)

jblu_g <- grep('JBLU', All52$stockName )

All52[jblu_g,7:12] <- c(mdnjblu_d,q3jblu_d,mxjblu_d,mdnjblu_i,q3jblu_i,mxjblu_i)

```

JPM-JP Morgan Chase & Co.:
```{r}
mdnjpm_d <- median(countJPM2$jpm7_decr_Days)
q3jpm_d <- as.numeric(as.character(summary(countJPM2$jpm7_decr_Days)["3rd Qu."]))
mxjpm_d <- max(countJPM2$jpm7_decr_Days)

mdnjpm_i <- median(countJPM3$jpm7_incr_Days)
q3jpm_i <- as.numeric(as.character(summary(countJPM3$jpm7_incr_Days)["3rd Qu."]))
mxjpm_i <- max(countJPM3$jpm7_incr_Days)

jpm_g <- grep('JPM', All52$stockName )

All52[jpm_g,7:12] <- c(mdnjpm_d,q3jpm_d,mxjpm_d,mdnjpm_i,q3jpm_i,mxjpm_i)


```

JWN-Nordstrom:
```{r}
mdnjwn_d <- median(countJWN2$jwn7_decr_Days)
q3jwn_d <- as.numeric(as.character(summary(countJWN2$jwn7_decr_Days)["3rd Qu."]))
mxjwn_d <- max(countJWN2$jwn7_decr_Days)

mdnjwn_i <- median(countJWN3$jwn7_incr_Days)
q3jwn_i <- as.numeric(as.character(summary(countJWN3$jwn7_incr_Days)["3rd Qu."]))
mxjwn_i <- max(countJWN3$jwn7_incr_Days)

jwn_g <- grep('JWN', All52$stockName )

All52[jwn_g,7:12] <- c(mdnjwn_d,q3jwn_d,mxjwn_d,mdnjwn_i,q3jwn_i,mxjwn_i)


```

KGJI-Kingold Jewelry,Inc:
```{r}
mdnkgji_d <- median(countKGJI2$kgji7_decr_Days)
q3kgji_d <- as.numeric(as.character(summary(countKGJI2$kgji7_decr_Days)["3rd Qu."]))
mxkgji_d <- max(countKGJI2$kgji7_decr_Days)

mdnkgji_i <- median(countKGJI3$kgji7_incr_Days)
q3kgji_i <- as.numeric(as.character(summary(countKGJI3$kgji7_incr_Days)["3rd Qu."]))
mxkgji_i <- max(countKGJI3$kgji7_incr_Days)

kgji_g <- grep('KGJI', All52$stockName )

All52[kgji_g,7:12] <- c(mdnkgji_d,q3kgji_d,mxkgji_d,mdnkgji_i,q3kgji_i,mxkgji_i)


```

KSS-Kohls Corporation:
```{r}
mdnkss_d <- median(countKSS2$kss7_decr_Days)
q3kss_d <- as.numeric(as.character(summary(countKSS2$kss7_decr_Days)["3rd Qu."]))
mxkss_d <- max(countKSS2$kss7_decr_Days)

mdnkss_i <- median(countKSS3$kss7_incr_Days)
q3kss_i <- as.numeric(as.character(summary(countKSS3$kss7_incr_Days)["3rd Qu."]))
mxkss_i <- max(countKSS3$kss7_incr_Days)

kss_g <- grep('KSS', All52$stockName )

All52[kss_g,7:12] <- c(mdnkss_d,q3kss_d,mxkss_d,mdnkss_i,q3kss_i,mxkss_i)


```

LUV-Southwest Airlines:
```{r}
mdnluv_d <- median(countLUV2$luv7_decr_Days)
q3luv_d <- as.numeric(as.character(summary(countLUV2$luv7_decr_Days)["3rd Qu."]))
mxluv_d <- max(countLUV2$luv7_decr_Days)

mdnluv_i <- median(countLUV3$luv7_incr_Days)
q3luv_i <- as.numeric(as.character(summary(countLUV3$luv7_incr_Days)["3rd Qu."]))
mxluv_i <- max(countLUV3$luv7_incr_Days)

luv_g <- grep('LUV', All52$stockName )

All52[luv_g,7:12] <- c(mdnluv_d,q3luv_d,mxluv_d,mdnluv_i,q3luv_i,mxluv_i)


```

M-Macys:
```{r}
mdnm_d <- median(countM2$m7_decr_Days)
q3m_d <- as.numeric(as.character(summary(countM2$m7_decr_Days)["3rd Qu."]))
mxm_d <- max(countM2$m7_decr_Days)

mdnm_i <- median(countM3$m7_incr_Days)
q3m_i <- as.numeric(as.character(summary(countM3$m7_incr_Days)["3rd Qu."]))
mxm_i <- max(countM3$m7_incr_Days)

m_g <- grep('M', All52$stockName )

All52[m_g,7:12] <- c(mdnm_d,q3m_d,mxm_d,mdnm_i,q3m_i,mxm_i)


```

NSANY-Nissan Motor Co.:
```{r}
mdnnsany_d <- median(countNSANY2$nsany7_decr_Days)
q3nsany_d <- as.numeric(as.character(summary(countNSANY2$nsany7_decr_Days)["3rd Qu."]))
mxnsany_d <- max(countNSANY2$nsany7_decr_Days)

mdnnsany_i <- median(countNSANY3$nsany7_incr_Days)
q3nsany_i <- as.numeric(as.character(summary(countNSANY3$nsany7_incr_Days)["3rd Qu."]))
mxnsany_i <- max(countNSANY3$nsany7_incr_Days)

nsany_g <- grep('NSANY', All52$stockName )

All52[nsany_g,7:12] <- c(mdnnsany_d,q3nsany_d,mxnsany_d,mdnnsany_i,q3nsany_i,mxnsany_i)


```

NUS-Nu Skin Enterprises:
```{r}
mdnnus_d <- median(countNUS2$nus7_decr_Days)
q3nus_d <- as.numeric(as.character(summary(countNUS2$nus7_decr_Days)["3rd Qu."]))
mxnus_d <- max(countNUS2$nus7_decr_Days)

mdnnus_i <- median(countNUS3$nus7_incr_Days)
q3nus_i <- as.numeric(as.character(summary(countNUS3$nus7_incr_Days)["3rd Qu."]))
mxnus_i <- max(countNUS3$nus7_incr_Days)

nus_g <- grep('NUS', All52$stockName )

All52[nus_g,7:12] <- c(mdnnus_d,q3nus_d,mxnus_d,mdnnus_i,q3nus_i,mxnus_i)


```

RRGB-Red Robin Gourmet Burgers:
```{r}
mdnrrgb_d <- median(countRRGB2$rrgb7_decr_Days)
q3rrgb_d <- as.numeric(as.character(summary(countRRGB2$rrgb7_decr_Days)["3rd Qu."]))
mxrrgb_d <- max(countRRGB2$rrgb7_decr_Days)

mdnrrgb_i <- median(countRRGB3$rrgb7_incr_Days)
q3rrgb_i <- as.numeric(as.character(summary(countRRGB3$rrgb7_incr_Days)["3rd Qu."]))
mxrrgb_i <- max(countRRGB3$rrgb7_incr_Days)

rrgb_g <- grep('RRGB', All52$stockName )

All52[rrgb_g,7:12] <- c(mdnrrgb_d,q3rrgb_d,mxrrgb_d,mdnrrgb_i,q3rrgb_i,mxrrgb_i)


```

S-Sprint Corporation:
```{r}
mdns_d <- median(countS2$s7_decr_Days)
q3s_d <- as.numeric(as.character(summary(countS2$s7_decr_Days)["3rd Qu."]))
mxs_d <- max(countS2$s7_decr_Days)

mdns_i <- median(countS3$s7_incr_Days)
q3s_i <- as.numeric(as.character(summary(countS3$s7_incr_Days)["3rd Qu."]))
mxs_i <- max(countS3$s7_incr_Days)

s_g <- grep('S', All52$stockName )

All52[s_g,7:12] <- c(mdns_d,q3s_d,mxs_d,mdns_i,q3s_i,mxs_i)


```

T-AT&T Inc:
```{r}
mdnt_d <- median(countT2$t7_decr_Days)
q3t_d <- as.numeric(as.character(summary(countT2$t7_decr_Days)["3rd Qu."]))
mxt_d <- max(countT2$t7_decr_Days)

mdnt_i <- median(countT3$t7_incr_Days)
q3t_i <- as.numeric(as.character(summary(countT3$t7_incr_Days)["3rd Qu."]))
mxt_i <- max(countT3$t7_incr_Days)

t_g <- grep('T', All52$stockName )

All52[t_g,7:12] <- c(mdnt_d,q3t_d,mxt_d,mdnt_i,q3t_i,mxt_i)


```

VZ-Verizon:
```{r}
mdnvz_d <- median(countVZ2$vz7_decr_Days)
q3vz_d <- as.numeric(as.character(summary(countVZ2$vz7_decr_Days)["3rd Qu."]))
mxvz_d <- max(countVZ2$vz7_decr_Days)

mdnvz_i <- median(countVZ3$vz7_incr_Days)
q3vz_i <- as.numeric(as.character(summary(countVZ3$vz7_incr_Days)["3rd Qu."]))
mxvz_i <- max(countVZ3$vz7_incr_Days)

vz_g <- grep('VZ', All52$stockName )

All52[vz_g,7:12] <- c(mdnvz_d,q3vz_d,mxvz_d,mdnvz_i,q3vz_i,mxvz_i)


```

WWE-World Wrestling Entertainment:
```{r}
mdnwwe_d <- median(countWWE2$wwe7_decr_Days)
q3wwe_d <- as.numeric(as.character(summary(countWWE2$wwe7_decr_Days)["3rd Qu."]))
mxwwe_d <- max(countWWE2$wwe7_decr_Days)

mdnwwe_i <- median(countWWE3$wwe7_incr_Days)
q3wwe_i <- as.numeric(as.character(summary(countWWE3$wwe7_incr_Days)["3rd Qu."]))
mxwwe_i <- max(countWWE3$wwe7_incr_Days)

wwe_g <- grep('WWE', All52$stockName )

All52[wwe_g,7:12] <- c(mdnwwe_d,q3wwe_d,mxwwe_d,mdnwwe_i,q3wwe_i,mxwwe_i)

```

***

Now, lets look at the columns to see they are the right data types.
```{r}
str(All52)

```

We need to change the stat columns in the All52 table from char to numeric. So lets do that.
```{r}
All52$medn_cSum_decr_L7 <- as.numeric(All52$medn_cSum_decr_L7)
All52$Q3_cSum_decr_L7 <- as.numeric(All52$Q3_cSum_decr_L7)
All52$max_cSum_decr_L7 <- as.numeric(All52$max_cSum_decr_L7)
All52$medn_cSum_incr_L7 <- as.numeric(All52$medn_cSum_incr_L7)
All52$Q3_cSum_incr_L7 <- as.numeric(All52$Q3_cSum_incr_L7)
All52$max_cSum_incr_L7 <- as.numeric(All52$max_cSum_incr_L7)

str(All52)
```

Lets also add the name of the stock to the stock name. We will also make a table of the total stocks in the hand picked portfolio of 65 that had many missing observations in the yahoo finance grab of stock information from 2007-2020 to start with.
```{r}
names52 <- stockNames[,1:2]
names52$stock <- gsub('.PB','', names52$stock)
names52$stock <- as.factor(names52$stock)

ALL52 <- merge(names52, All52, by.x='stock', by.y='stockName')
ALL65 <- merge(names52, All52, by.x='stock', by.y='stockName', all.x=TRUE)

ALL65 <- ALL65[order(ALL65$medn_cSum_decr_L7, na.last=TRUE),]
na13stocks <- ALL65[54:65,]
```

Before we write these to file, lets also categorize these stocks by type of stock. Such as cell phone, airlines, restaurants, etc. To get a category measure of each stock stats within their category or business category.
```{r}
businessType <- as.data.frame(c('airTravel','autoParts','athleticShoes','cloudComputing',
                  'genotypePharmaceuticals',
                  'bank','retail','fuel','discountRetail','fuel','automotive','bank',
                  'communications','cloudComputing','homeRepair','automotive',
                  'furniture','taxService', 'hotelTravel','immunoPharmaceuticals', 'airTravel',
                  'healthCarePharmaceuticals', 'bank','retail', 'jewelry', 
                  'retail', 'airTravel', 'retail',
                  'hotelTravel', 'CloudComputing', 'subsriptionEntertainment', 'athleticShoes',
                  'automotive','beautyProducts','cancerPharmaceuticals', 'energyUtility',
                  'discountRetail','restaurant','mobileCommunications','energyUtility',
                  'jewelry', 'communications','genericPharmaceuticals','retail','discountRetail',
                  'automotive','bank','mobileCommunications', 'bank','wasteUtility',
                  'discountRetail', 'sportsEntertainment','fuel'))
colnames(businessType) <- 'businessType'

businessType2 <- as.data.frame(c('movieEntertainment','athleticShoes','movieEntertainment',
                                 'automotive','automotive','immunoPharmaceuticals',
                                 'couponDeals','cancerPharmaceuticals',
                                 'fastFoodRestaurant','dentalBioTech','mobileCommunications',
                                 'businessSocialMedia'))
colnames(businessType2) <- 'businessType'
other13 <- cbind(businessType2,na13stocks)
other13 <- other13[,c(2,3,1,4:14)]
```

```{r}
ALL_52 <- cbind(businessType,ALL52)
ALL_52 <- ALL_52[,c(2,3,1,4:14)]

ALL_65 <- rbind(ALL_52,other13)

write.csv(ALL_52, 'ALL_52.csv', row.names=FALSE)
write.csv(ALL_65, 'ALL_65.csv', row.names=FALSE)

```


```{r}
other13_b <- other13_dailyClose
colnames(other13_b) <- gsub('.Close', '', colnames(other13_b))

```

